{
  "best_global_step": 38012,
  "best_metric": 7.296446323394775,
  "best_model_checkpoint": "./gpt2-shakespeare-results/checkpoint-38012",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 38012,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0013153740923918763,
      "grad_norm": 7.928862571716309,
      "learning_rate": 2.45e-05,
      "loss": 4.3667,
      "step": 50
    },
    {
      "epoch": 0.0026307481847837526,
      "grad_norm": 8.35387134552002,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.8824,
      "step": 100
    },
    {
      "epoch": 0.003946122277175629,
      "grad_norm": 7.884564399719238,
      "learning_rate": 4.99784966999017e-05,
      "loss": 3.7378,
      "step": 150
    },
    {
      "epoch": 0.005261496369567505,
      "grad_norm": 7.377553939819336,
      "learning_rate": 4.995655455694425e-05,
      "loss": 3.5954,
      "step": 200
    },
    {
      "epoch": 0.006576870461959382,
      "grad_norm": 6.887958526611328,
      "learning_rate": 4.9934612413986805e-05,
      "loss": 3.5354,
      "step": 250
    },
    {
      "epoch": 0.007892244554351257,
      "grad_norm": 6.980103969573975,
      "learning_rate": 4.991267027102935e-05,
      "loss": 3.5043,
      "step": 300
    },
    {
      "epoch": 0.009207618646743134,
      "grad_norm": 6.705517768859863,
      "learning_rate": 4.98907281280719e-05,
      "loss": 3.4942,
      "step": 350
    },
    {
      "epoch": 0.01052299273913501,
      "grad_norm": 5.854396820068359,
      "learning_rate": 4.9868785985114454e-05,
      "loss": 3.4188,
      "step": 400
    },
    {
      "epoch": 0.011838366831526887,
      "grad_norm": 6.6587395668029785,
      "learning_rate": 4.9846843842157e-05,
      "loss": 3.4018,
      "step": 450
    },
    {
      "epoch": 0.013153740923918763,
      "grad_norm": 5.207996368408203,
      "learning_rate": 4.9824901699199556e-05,
      "loss": 3.3904,
      "step": 500
    },
    {
      "epoch": 0.014469115016310638,
      "grad_norm": 5.716810703277588,
      "learning_rate": 4.98029595562421e-05,
      "loss": 3.3451,
      "step": 550
    },
    {
      "epoch": 0.015784489108702515,
      "grad_norm": 6.076563835144043,
      "learning_rate": 4.978101741328465e-05,
      "loss": 3.3517,
      "step": 600
    },
    {
      "epoch": 0.01709986320109439,
      "grad_norm": 5.174357891082764,
      "learning_rate": 4.9759075270327205e-05,
      "loss": 3.3234,
      "step": 650
    },
    {
      "epoch": 0.018415237293486268,
      "grad_norm": 5.308799743652344,
      "learning_rate": 4.973713312736976e-05,
      "loss": 3.2533,
      "step": 700
    },
    {
      "epoch": 0.019730611385878144,
      "grad_norm": 5.732443332672119,
      "learning_rate": 4.97151909844123e-05,
      "loss": 3.2649,
      "step": 750
    },
    {
      "epoch": 0.02104598547827002,
      "grad_norm": 4.812621116638184,
      "learning_rate": 4.9693248841454854e-05,
      "loss": 3.2652,
      "step": 800
    },
    {
      "epoch": 0.022361359570661897,
      "grad_norm": 4.481085300445557,
      "learning_rate": 4.96713066984974e-05,
      "loss": 3.181,
      "step": 850
    },
    {
      "epoch": 0.023676733663053773,
      "grad_norm": 4.627078056335449,
      "learning_rate": 4.9649364555539956e-05,
      "loss": 3.1709,
      "step": 900
    },
    {
      "epoch": 0.02499210775544565,
      "grad_norm": 4.521010398864746,
      "learning_rate": 4.9627422412582504e-05,
      "loss": 3.1655,
      "step": 950
    },
    {
      "epoch": 0.026307481847837526,
      "grad_norm": 4.143497943878174,
      "learning_rate": 4.960548026962505e-05,
      "loss": 3.1399,
      "step": 1000
    },
    {
      "epoch": 0.0276228559402294,
      "grad_norm": 4.366379737854004,
      "learning_rate": 4.9583538126667605e-05,
      "loss": 3.1083,
      "step": 1050
    },
    {
      "epoch": 0.028938230032621276,
      "grad_norm": 4.8006978034973145,
      "learning_rate": 4.956159598371016e-05,
      "loss": 3.137,
      "step": 1100
    },
    {
      "epoch": 0.030253604125013153,
      "grad_norm": 4.457635402679443,
      "learning_rate": 4.95396538407527e-05,
      "loss": 3.1145,
      "step": 1150
    },
    {
      "epoch": 0.03156897821740503,
      "grad_norm": 4.645639419555664,
      "learning_rate": 4.9517711697795254e-05,
      "loss": 3.0531,
      "step": 1200
    },
    {
      "epoch": 0.03288435230979691,
      "grad_norm": 4.2459611892700195,
      "learning_rate": 4.949576955483781e-05,
      "loss": 2.9847,
      "step": 1250
    },
    {
      "epoch": 0.03419972640218878,
      "grad_norm": 4.164949893951416,
      "learning_rate": 4.9473827411880356e-05,
      "loss": 3.06,
      "step": 1300
    },
    {
      "epoch": 0.03551510049458066,
      "grad_norm": 3.9387176036834717,
      "learning_rate": 4.9451885268922904e-05,
      "loss": 3.0451,
      "step": 1350
    },
    {
      "epoch": 0.036830474586972535,
      "grad_norm": 4.140332221984863,
      "learning_rate": 4.942994312596546e-05,
      "loss": 2.9632,
      "step": 1400
    },
    {
      "epoch": 0.03814584867936441,
      "grad_norm": 3.912034034729004,
      "learning_rate": 4.9408000983008005e-05,
      "loss": 2.992,
      "step": 1450
    },
    {
      "epoch": 0.03946122277175629,
      "grad_norm": 4.060060501098633,
      "learning_rate": 4.938605884005056e-05,
      "loss": 2.9542,
      "step": 1500
    },
    {
      "epoch": 0.04077659686414816,
      "grad_norm": 3.7688229084014893,
      "learning_rate": 4.936411669709311e-05,
      "loss": 2.9729,
      "step": 1550
    },
    {
      "epoch": 0.04209197095654004,
      "grad_norm": 3.912684917449951,
      "learning_rate": 4.9342174554135655e-05,
      "loss": 2.9122,
      "step": 1600
    },
    {
      "epoch": 0.043407345048931914,
      "grad_norm": 3.926635503768921,
      "learning_rate": 4.932023241117821e-05,
      "loss": 2.8848,
      "step": 1650
    },
    {
      "epoch": 0.044722719141323794,
      "grad_norm": 3.7508904933929443,
      "learning_rate": 4.9298290268220756e-05,
      "loss": 2.8326,
      "step": 1700
    },
    {
      "epoch": 0.04603809323371567,
      "grad_norm": 3.6149775981903076,
      "learning_rate": 4.927634812526331e-05,
      "loss": 2.8757,
      "step": 1750
    },
    {
      "epoch": 0.04735346732610755,
      "grad_norm": 3.5737292766571045,
      "learning_rate": 4.925440598230586e-05,
      "loss": 2.8518,
      "step": 1800
    },
    {
      "epoch": 0.04866884141849942,
      "grad_norm": 3.5663764476776123,
      "learning_rate": 4.9232463839348406e-05,
      "loss": 2.803,
      "step": 1850
    },
    {
      "epoch": 0.0499842155108913,
      "grad_norm": 3.6550686359405518,
      "learning_rate": 4.921052169639096e-05,
      "loss": 2.7856,
      "step": 1900
    },
    {
      "epoch": 0.05129958960328317,
      "grad_norm": 3.404341459274292,
      "learning_rate": 4.9188579553433514e-05,
      "loss": 2.8256,
      "step": 1950
    },
    {
      "epoch": 0.05261496369567505,
      "grad_norm": 3.6926426887512207,
      "learning_rate": 4.9166637410476055e-05,
      "loss": 2.7853,
      "step": 2000
    },
    {
      "epoch": 0.053930337788066926,
      "grad_norm": 3.9886672496795654,
      "learning_rate": 4.914469526751861e-05,
      "loss": 2.7507,
      "step": 2050
    },
    {
      "epoch": 0.0552457118804588,
      "grad_norm": 3.5916130542755127,
      "learning_rate": 4.912275312456116e-05,
      "loss": 2.7331,
      "step": 2100
    },
    {
      "epoch": 0.05656108597285068,
      "grad_norm": 3.516690969467163,
      "learning_rate": 4.910081098160371e-05,
      "loss": 2.7415,
      "step": 2150
    },
    {
      "epoch": 0.05787646006524255,
      "grad_norm": 3.710052251815796,
      "learning_rate": 4.907886883864626e-05,
      "loss": 2.7296,
      "step": 2200
    },
    {
      "epoch": 0.05919183415763443,
      "grad_norm": 3.7253050804138184,
      "learning_rate": 4.905692669568881e-05,
      "loss": 2.7056,
      "step": 2250
    },
    {
      "epoch": 0.060507208250026305,
      "grad_norm": 3.393331527709961,
      "learning_rate": 4.903498455273136e-05,
      "loss": 2.7219,
      "step": 2300
    },
    {
      "epoch": 0.061822582342418185,
      "grad_norm": 3.439713716506958,
      "learning_rate": 4.9013042409773914e-05,
      "loss": 2.6136,
      "step": 2350
    },
    {
      "epoch": 0.06313795643481006,
      "grad_norm": 3.531374931335449,
      "learning_rate": 4.899110026681646e-05,
      "loss": 2.6214,
      "step": 2400
    },
    {
      "epoch": 0.06445333052720194,
      "grad_norm": 3.528536558151245,
      "learning_rate": 4.896915812385901e-05,
      "loss": 2.5735,
      "step": 2450
    },
    {
      "epoch": 0.06576870461959382,
      "grad_norm": 3.499691963195801,
      "learning_rate": 4.8947215980901564e-05,
      "loss": 2.5654,
      "step": 2500
    },
    {
      "epoch": 0.06708407871198568,
      "grad_norm": 3.9494006633758545,
      "learning_rate": 4.892527383794411e-05,
      "loss": 2.6022,
      "step": 2550
    },
    {
      "epoch": 0.06839945280437756,
      "grad_norm": 3.260120153427124,
      "learning_rate": 4.890333169498666e-05,
      "loss": 2.5475,
      "step": 2600
    },
    {
      "epoch": 0.06971482689676944,
      "grad_norm": 3.5896267890930176,
      "learning_rate": 4.888138955202921e-05,
      "loss": 2.5623,
      "step": 2650
    },
    {
      "epoch": 0.07103020098916132,
      "grad_norm": 3.59356427192688,
      "learning_rate": 4.885944740907176e-05,
      "loss": 2.5548,
      "step": 2700
    },
    {
      "epoch": 0.07234557508155319,
      "grad_norm": 3.6232950687408447,
      "learning_rate": 4.8837505266114315e-05,
      "loss": 2.5556,
      "step": 2750
    },
    {
      "epoch": 0.07366094917394507,
      "grad_norm": 3.538086175918579,
      "learning_rate": 4.881556312315686e-05,
      "loss": 2.4868,
      "step": 2800
    },
    {
      "epoch": 0.07497632326633695,
      "grad_norm": 3.6372792720794678,
      "learning_rate": 4.879362098019941e-05,
      "loss": 2.4982,
      "step": 2850
    },
    {
      "epoch": 0.07629169735872882,
      "grad_norm": 3.437744617462158,
      "learning_rate": 4.8771678837241964e-05,
      "loss": 2.4534,
      "step": 2900
    },
    {
      "epoch": 0.0776070714511207,
      "grad_norm": 3.473422050476074,
      "learning_rate": 4.874973669428451e-05,
      "loss": 2.4596,
      "step": 2950
    },
    {
      "epoch": 0.07892244554351258,
      "grad_norm": 3.682365894317627,
      "learning_rate": 4.872779455132706e-05,
      "loss": 2.4622,
      "step": 3000
    },
    {
      "epoch": 0.08023781963590446,
      "grad_norm": 3.8403143882751465,
      "learning_rate": 4.870585240836961e-05,
      "loss": 2.4407,
      "step": 3050
    },
    {
      "epoch": 0.08155319372829632,
      "grad_norm": 3.7377207279205322,
      "learning_rate": 4.868391026541216e-05,
      "loss": 2.4332,
      "step": 3100
    },
    {
      "epoch": 0.0828685678206882,
      "grad_norm": 3.6815052032470703,
      "learning_rate": 4.8661968122454715e-05,
      "loss": 2.4308,
      "step": 3150
    },
    {
      "epoch": 0.08418394191308008,
      "grad_norm": 3.5947234630584717,
      "learning_rate": 4.864002597949726e-05,
      "loss": 2.3685,
      "step": 3200
    },
    {
      "epoch": 0.08549931600547196,
      "grad_norm": 3.4938981533050537,
      "learning_rate": 4.861808383653981e-05,
      "loss": 2.3689,
      "step": 3250
    },
    {
      "epoch": 0.08681469009786383,
      "grad_norm": 3.753218412399292,
      "learning_rate": 4.8596141693582364e-05,
      "loss": 2.3835,
      "step": 3300
    },
    {
      "epoch": 0.08813006419025571,
      "grad_norm": 3.5779364109039307,
      "learning_rate": 4.857419955062492e-05,
      "loss": 2.3033,
      "step": 3350
    },
    {
      "epoch": 0.08944543828264759,
      "grad_norm": 3.35483980178833,
      "learning_rate": 4.8552257407667466e-05,
      "loss": 2.3503,
      "step": 3400
    },
    {
      "epoch": 0.09076081237503947,
      "grad_norm": 3.662656545639038,
      "learning_rate": 4.853031526471001e-05,
      "loss": 2.3076,
      "step": 3450
    },
    {
      "epoch": 0.09207618646743133,
      "grad_norm": 3.527604818344116,
      "learning_rate": 4.850837312175257e-05,
      "loss": 2.2586,
      "step": 3500
    },
    {
      "epoch": 0.09339156055982321,
      "grad_norm": 3.635446310043335,
      "learning_rate": 4.8486430978795115e-05,
      "loss": 2.2511,
      "step": 3550
    },
    {
      "epoch": 0.0947069346522151,
      "grad_norm": 3.4657187461853027,
      "learning_rate": 4.846448883583767e-05,
      "loss": 2.2606,
      "step": 3600
    },
    {
      "epoch": 0.09602230874460696,
      "grad_norm": 3.622511148452759,
      "learning_rate": 4.844254669288022e-05,
      "loss": 2.2173,
      "step": 3650
    },
    {
      "epoch": 0.09733768283699884,
      "grad_norm": 3.5834832191467285,
      "learning_rate": 4.8420604549922764e-05,
      "loss": 2.2259,
      "step": 3700
    },
    {
      "epoch": 0.09865305692939072,
      "grad_norm": 3.779200553894043,
      "learning_rate": 4.839866240696532e-05,
      "loss": 2.2525,
      "step": 3750
    },
    {
      "epoch": 0.0999684310217826,
      "grad_norm": 3.5496299266815186,
      "learning_rate": 4.8376720264007866e-05,
      "loss": 2.2126,
      "step": 3800
    },
    {
      "epoch": 0.10128380511417447,
      "grad_norm": 3.735586404800415,
      "learning_rate": 4.835477812105041e-05,
      "loss": 2.169,
      "step": 3850
    },
    {
      "epoch": 0.10259917920656635,
      "grad_norm": 3.8019607067108154,
      "learning_rate": 4.833283597809297e-05,
      "loss": 2.1902,
      "step": 3900
    },
    {
      "epoch": 0.10391455329895823,
      "grad_norm": 3.694018602371216,
      "learning_rate": 4.8310893835135515e-05,
      "loss": 2.1462,
      "step": 3950
    },
    {
      "epoch": 0.1052299273913501,
      "grad_norm": 3.6843111515045166,
      "learning_rate": 4.828895169217807e-05,
      "loss": 2.1652,
      "step": 4000
    },
    {
      "epoch": 0.10654530148374197,
      "grad_norm": 4.06701135635376,
      "learning_rate": 4.826700954922062e-05,
      "loss": 2.1193,
      "step": 4050
    },
    {
      "epoch": 0.10786067557613385,
      "grad_norm": 3.8372323513031006,
      "learning_rate": 4.8245067406263164e-05,
      "loss": 2.0927,
      "step": 4100
    },
    {
      "epoch": 0.10917604966852573,
      "grad_norm": 3.82944655418396,
      "learning_rate": 4.822312526330572e-05,
      "loss": 2.0595,
      "step": 4150
    },
    {
      "epoch": 0.1104914237609176,
      "grad_norm": 3.9085335731506348,
      "learning_rate": 4.820118312034827e-05,
      "loss": 2.0883,
      "step": 4200
    },
    {
      "epoch": 0.11180679785330948,
      "grad_norm": 4.022552490234375,
      "learning_rate": 4.8179240977390814e-05,
      "loss": 2.0197,
      "step": 4250
    },
    {
      "epoch": 0.11312217194570136,
      "grad_norm": 3.7517001628875732,
      "learning_rate": 4.815729883443337e-05,
      "loss": 2.055,
      "step": 4300
    },
    {
      "epoch": 0.11443754603809324,
      "grad_norm": 3.823434352874756,
      "learning_rate": 4.813535669147592e-05,
      "loss": 2.0422,
      "step": 4350
    },
    {
      "epoch": 0.1157529201304851,
      "grad_norm": 3.76379132270813,
      "learning_rate": 4.811341454851847e-05,
      "loss": 2.0322,
      "step": 4400
    },
    {
      "epoch": 0.11706829422287698,
      "grad_norm": 3.727142333984375,
      "learning_rate": 4.809147240556102e-05,
      "loss": 1.9907,
      "step": 4450
    },
    {
      "epoch": 0.11838366831526886,
      "grad_norm": 3.817352056503296,
      "learning_rate": 4.806953026260357e-05,
      "loss": 1.9718,
      "step": 4500
    },
    {
      "epoch": 0.11969904240766074,
      "grad_norm": 3.5675930976867676,
      "learning_rate": 4.804758811964612e-05,
      "loss": 1.9428,
      "step": 4550
    },
    {
      "epoch": 0.12101441650005261,
      "grad_norm": 3.9215779304504395,
      "learning_rate": 4.802564597668867e-05,
      "loss": 2.0269,
      "step": 4600
    },
    {
      "epoch": 0.12232979059244449,
      "grad_norm": 3.868548631668091,
      "learning_rate": 4.800370383373122e-05,
      "loss": 1.9371,
      "step": 4650
    },
    {
      "epoch": 0.12364516468483637,
      "grad_norm": 4.0765180587768555,
      "learning_rate": 4.798176169077377e-05,
      "loss": 1.9603,
      "step": 4700
    },
    {
      "epoch": 0.12496053877722825,
      "grad_norm": 3.7478644847869873,
      "learning_rate": 4.795981954781632e-05,
      "loss": 1.9355,
      "step": 4750
    },
    {
      "epoch": 0.12627591286962012,
      "grad_norm": 3.381047010421753,
      "learning_rate": 4.793787740485887e-05,
      "loss": 1.922,
      "step": 4800
    },
    {
      "epoch": 0.127591286962012,
      "grad_norm": 3.800903081893921,
      "learning_rate": 4.791593526190142e-05,
      "loss": 1.9486,
      "step": 4850
    },
    {
      "epoch": 0.12890666105440388,
      "grad_norm": 3.712846517562866,
      "learning_rate": 4.789399311894397e-05,
      "loss": 1.8799,
      "step": 4900
    },
    {
      "epoch": 0.13022203514679576,
      "grad_norm": 3.567807674407959,
      "learning_rate": 4.787205097598652e-05,
      "loss": 1.9152,
      "step": 4950
    },
    {
      "epoch": 0.13153740923918764,
      "grad_norm": 3.8524787425994873,
      "learning_rate": 4.785010883302907e-05,
      "loss": 1.846,
      "step": 5000
    },
    {
      "epoch": 0.1328527833315795,
      "grad_norm": 3.691301107406616,
      "learning_rate": 4.782816669007163e-05,
      "loss": 1.854,
      "step": 5050
    },
    {
      "epoch": 0.13416815742397137,
      "grad_norm": 3.628784418106079,
      "learning_rate": 4.780622454711417e-05,
      "loss": 1.8486,
      "step": 5100
    },
    {
      "epoch": 0.13548353151636325,
      "grad_norm": 3.802617073059082,
      "learning_rate": 4.778428240415672e-05,
      "loss": 1.8074,
      "step": 5150
    },
    {
      "epoch": 0.13679890560875513,
      "grad_norm": 3.6810762882232666,
      "learning_rate": 4.776234026119927e-05,
      "loss": 1.8398,
      "step": 5200
    },
    {
      "epoch": 0.138114279701147,
      "grad_norm": 3.6902554035186768,
      "learning_rate": 4.7740398118241824e-05,
      "loss": 1.8145,
      "step": 5250
    },
    {
      "epoch": 0.1394296537935389,
      "grad_norm": 3.6626811027526855,
      "learning_rate": 4.771845597528437e-05,
      "loss": 1.8058,
      "step": 5300
    },
    {
      "epoch": 0.14074502788593077,
      "grad_norm": 4.146917819976807,
      "learning_rate": 4.769651383232692e-05,
      "loss": 1.7824,
      "step": 5350
    },
    {
      "epoch": 0.14206040197832265,
      "grad_norm": 4.075908184051514,
      "learning_rate": 4.7674571689369473e-05,
      "loss": 1.7595,
      "step": 5400
    },
    {
      "epoch": 0.1433757760707145,
      "grad_norm": 4.705069541931152,
      "learning_rate": 4.765262954641203e-05,
      "loss": 1.7479,
      "step": 5450
    },
    {
      "epoch": 0.14469115016310638,
      "grad_norm": 3.9182751178741455,
      "learning_rate": 4.763068740345457e-05,
      "loss": 1.7428,
      "step": 5500
    },
    {
      "epoch": 0.14600652425549826,
      "grad_norm": 3.950749635696411,
      "learning_rate": 4.760874526049712e-05,
      "loss": 1.7652,
      "step": 5550
    },
    {
      "epoch": 0.14732189834789014,
      "grad_norm": 3.8378541469573975,
      "learning_rate": 4.758680311753968e-05,
      "loss": 1.7204,
      "step": 5600
    },
    {
      "epoch": 0.14863727244028202,
      "grad_norm": 4.005204677581787,
      "learning_rate": 4.7564860974582224e-05,
      "loss": 1.7031,
      "step": 5650
    },
    {
      "epoch": 0.1499526465326739,
      "grad_norm": 3.9221715927124023,
      "learning_rate": 4.754291883162477e-05,
      "loss": 1.6787,
      "step": 5700
    },
    {
      "epoch": 0.15126802062506578,
      "grad_norm": 3.8911564350128174,
      "learning_rate": 4.7520976688667326e-05,
      "loss": 1.6771,
      "step": 5750
    },
    {
      "epoch": 0.15258339471745763,
      "grad_norm": 3.839562177658081,
      "learning_rate": 4.7499034545709874e-05,
      "loss": 1.6658,
      "step": 5800
    },
    {
      "epoch": 0.1538987688098495,
      "grad_norm": 3.637214183807373,
      "learning_rate": 4.747709240275243e-05,
      "loss": 1.6714,
      "step": 5850
    },
    {
      "epoch": 0.1552141429022414,
      "grad_norm": 3.6993391513824463,
      "learning_rate": 4.7455150259794975e-05,
      "loss": 1.6594,
      "step": 5900
    },
    {
      "epoch": 0.15652951699463327,
      "grad_norm": 3.794693946838379,
      "learning_rate": 4.743320811683752e-05,
      "loss": 1.6188,
      "step": 5950
    },
    {
      "epoch": 0.15784489108702515,
      "grad_norm": 3.5773661136627197,
      "learning_rate": 4.741126597388008e-05,
      "loss": 1.607,
      "step": 6000
    },
    {
      "epoch": 0.15916026517941703,
      "grad_norm": 3.844616413116455,
      "learning_rate": 4.7389323830922625e-05,
      "loss": 1.6251,
      "step": 6050
    },
    {
      "epoch": 0.1604756392718089,
      "grad_norm": 3.7326931953430176,
      "learning_rate": 4.736738168796517e-05,
      "loss": 1.5865,
      "step": 6100
    },
    {
      "epoch": 0.1617910133642008,
      "grad_norm": 3.732696533203125,
      "learning_rate": 4.7345439545007726e-05,
      "loss": 1.57,
      "step": 6150
    },
    {
      "epoch": 0.16310638745659264,
      "grad_norm": 3.7096824645996094,
      "learning_rate": 4.7323497402050274e-05,
      "loss": 1.6151,
      "step": 6200
    },
    {
      "epoch": 0.16442176154898452,
      "grad_norm": 3.4991278648376465,
      "learning_rate": 4.730155525909283e-05,
      "loss": 1.5879,
      "step": 6250
    },
    {
      "epoch": 0.1657371356413764,
      "grad_norm": 3.5851821899414062,
      "learning_rate": 4.7279613116135376e-05,
      "loss": 1.5705,
      "step": 6300
    },
    {
      "epoch": 0.16705250973376828,
      "grad_norm": 3.6867311000823975,
      "learning_rate": 4.725767097317792e-05,
      "loss": 1.5719,
      "step": 6350
    },
    {
      "epoch": 0.16836788382616016,
      "grad_norm": 3.909468173980713,
      "learning_rate": 4.723572883022048e-05,
      "loss": 1.5266,
      "step": 6400
    },
    {
      "epoch": 0.16968325791855204,
      "grad_norm": 3.6597445011138916,
      "learning_rate": 4.721378668726303e-05,
      "loss": 1.513,
      "step": 6450
    },
    {
      "epoch": 0.17099863201094392,
      "grad_norm": 3.4932639598846436,
      "learning_rate": 4.719184454430557e-05,
      "loss": 1.5081,
      "step": 6500
    },
    {
      "epoch": 0.17231400610333578,
      "grad_norm": 3.959824562072754,
      "learning_rate": 4.7169902401348126e-05,
      "loss": 1.5124,
      "step": 6550
    },
    {
      "epoch": 0.17362938019572766,
      "grad_norm": 3.7129294872283936,
      "learning_rate": 4.714796025839068e-05,
      "loss": 1.4906,
      "step": 6600
    },
    {
      "epoch": 0.17494475428811954,
      "grad_norm": 3.463050127029419,
      "learning_rate": 4.712601811543323e-05,
      "loss": 1.4994,
      "step": 6650
    },
    {
      "epoch": 0.17626012838051142,
      "grad_norm": 3.6359970569610596,
      "learning_rate": 4.710407597247578e-05,
      "loss": 1.4671,
      "step": 6700
    },
    {
      "epoch": 0.1775755024729033,
      "grad_norm": 4.196108818054199,
      "learning_rate": 4.708213382951833e-05,
      "loss": 1.4752,
      "step": 6750
    },
    {
      "epoch": 0.17889087656529518,
      "grad_norm": 3.853898763656616,
      "learning_rate": 4.706019168656088e-05,
      "loss": 1.4515,
      "step": 6800
    },
    {
      "epoch": 0.18020625065768706,
      "grad_norm": 3.7030718326568604,
      "learning_rate": 4.703824954360343e-05,
      "loss": 1.4069,
      "step": 6850
    },
    {
      "epoch": 0.18152162475007894,
      "grad_norm": 3.563126564025879,
      "learning_rate": 4.701630740064598e-05,
      "loss": 1.4574,
      "step": 6900
    },
    {
      "epoch": 0.1828369988424708,
      "grad_norm": 4.239049434661865,
      "learning_rate": 4.699436525768853e-05,
      "loss": 1.4589,
      "step": 6950
    },
    {
      "epoch": 0.18415237293486267,
      "grad_norm": 3.819837808609009,
      "learning_rate": 4.697242311473108e-05,
      "loss": 1.3907,
      "step": 7000
    },
    {
      "epoch": 0.18546774702725455,
      "grad_norm": 3.7029905319213867,
      "learning_rate": 4.695048097177363e-05,
      "loss": 1.3885,
      "step": 7050
    },
    {
      "epoch": 0.18678312111964643,
      "grad_norm": 3.8869221210479736,
      "learning_rate": 4.692853882881618e-05,
      "loss": 1.4102,
      "step": 7100
    },
    {
      "epoch": 0.1880984952120383,
      "grad_norm": 4.0819172859191895,
      "learning_rate": 4.690659668585873e-05,
      "loss": 1.4131,
      "step": 7150
    },
    {
      "epoch": 0.1894138693044302,
      "grad_norm": 3.8263983726501465,
      "learning_rate": 4.688465454290128e-05,
      "loss": 1.3745,
      "step": 7200
    },
    {
      "epoch": 0.19072924339682207,
      "grad_norm": 3.665156602859497,
      "learning_rate": 4.686271239994383e-05,
      "loss": 1.3827,
      "step": 7250
    },
    {
      "epoch": 0.19204461748921392,
      "grad_norm": 3.75203275680542,
      "learning_rate": 4.684077025698638e-05,
      "loss": 1.3619,
      "step": 7300
    },
    {
      "epoch": 0.1933599915816058,
      "grad_norm": 3.593564748764038,
      "learning_rate": 4.681882811402893e-05,
      "loss": 1.3505,
      "step": 7350
    },
    {
      "epoch": 0.19467536567399768,
      "grad_norm": 3.7101950645446777,
      "learning_rate": 4.679688597107148e-05,
      "loss": 1.3356,
      "step": 7400
    },
    {
      "epoch": 0.19599073976638956,
      "grad_norm": 3.4601266384124756,
      "learning_rate": 4.677494382811403e-05,
      "loss": 1.3542,
      "step": 7450
    },
    {
      "epoch": 0.19730611385878144,
      "grad_norm": 3.885892868041992,
      "learning_rate": 4.675300168515658e-05,
      "loss": 1.3528,
      "step": 7500
    },
    {
      "epoch": 0.19862148795117332,
      "grad_norm": 3.7246696949005127,
      "learning_rate": 4.673105954219913e-05,
      "loss": 1.3045,
      "step": 7550
    },
    {
      "epoch": 0.1999368620435652,
      "grad_norm": 3.375638246536255,
      "learning_rate": 4.670911739924168e-05,
      "loss": 1.3057,
      "step": 7600
    },
    {
      "epoch": 0.20125223613595708,
      "grad_norm": 3.618948221206665,
      "learning_rate": 4.668717525628423e-05,
      "loss": 1.3381,
      "step": 7650
    },
    {
      "epoch": 0.20256761022834893,
      "grad_norm": 3.548267126083374,
      "learning_rate": 4.6665233113326786e-05,
      "loss": 1.2762,
      "step": 7700
    },
    {
      "epoch": 0.2038829843207408,
      "grad_norm": 3.7376480102539062,
      "learning_rate": 4.664329097036933e-05,
      "loss": 1.2748,
      "step": 7750
    },
    {
      "epoch": 0.2051983584131327,
      "grad_norm": 3.2393016815185547,
      "learning_rate": 4.662134882741188e-05,
      "loss": 1.3048,
      "step": 7800
    },
    {
      "epoch": 0.20651373250552457,
      "grad_norm": 3.762183427810669,
      "learning_rate": 4.6599406684454436e-05,
      "loss": 1.2847,
      "step": 7850
    },
    {
      "epoch": 0.20782910659791645,
      "grad_norm": 3.4829180240631104,
      "learning_rate": 4.657746454149698e-05,
      "loss": 1.2529,
      "step": 7900
    },
    {
      "epoch": 0.20914448069030833,
      "grad_norm": 3.4270777702331543,
      "learning_rate": 4.655552239853953e-05,
      "loss": 1.2186,
      "step": 7950
    },
    {
      "epoch": 0.2104598547827002,
      "grad_norm": 3.0711357593536377,
      "learning_rate": 4.6533580255582085e-05,
      "loss": 1.2375,
      "step": 8000
    },
    {
      "epoch": 0.21177522887509206,
      "grad_norm": 3.5724921226501465,
      "learning_rate": 4.651163811262463e-05,
      "loss": 1.226,
      "step": 8050
    },
    {
      "epoch": 0.21309060296748394,
      "grad_norm": 3.8929495811462402,
      "learning_rate": 4.6489695969667187e-05,
      "loss": 1.2317,
      "step": 8100
    },
    {
      "epoch": 0.21440597705987582,
      "grad_norm": 3.6373775005340576,
      "learning_rate": 4.6467753826709734e-05,
      "loss": 1.213,
      "step": 8150
    },
    {
      "epoch": 0.2157213511522677,
      "grad_norm": 3.3798668384552,
      "learning_rate": 4.644581168375228e-05,
      "loss": 1.2042,
      "step": 8200
    },
    {
      "epoch": 0.21703672524465958,
      "grad_norm": 3.4051513671875,
      "learning_rate": 4.6423869540794836e-05,
      "loss": 1.1793,
      "step": 8250
    },
    {
      "epoch": 0.21835209933705146,
      "grad_norm": 3.480412006378174,
      "learning_rate": 4.640192739783738e-05,
      "loss": 1.1785,
      "step": 8300
    },
    {
      "epoch": 0.21966747342944334,
      "grad_norm": 3.6101315021514893,
      "learning_rate": 4.637998525487994e-05,
      "loss": 1.1828,
      "step": 8350
    },
    {
      "epoch": 0.2209828475218352,
      "grad_norm": 3.6551015377044678,
      "learning_rate": 4.6358043111922485e-05,
      "loss": 1.1579,
      "step": 8400
    },
    {
      "epoch": 0.22229822161422708,
      "grad_norm": 3.4503331184387207,
      "learning_rate": 4.633610096896503e-05,
      "loss": 1.1299,
      "step": 8450
    },
    {
      "epoch": 0.22361359570661896,
      "grad_norm": 3.5262672901153564,
      "learning_rate": 4.631415882600759e-05,
      "loss": 1.1659,
      "step": 8500
    },
    {
      "epoch": 0.22492896979901084,
      "grad_norm": 3.8064424991607666,
      "learning_rate": 4.629221668305014e-05,
      "loss": 1.1765,
      "step": 8550
    },
    {
      "epoch": 0.22624434389140272,
      "grad_norm": 3.5359644889831543,
      "learning_rate": 4.627027454009268e-05,
      "loss": 1.1507,
      "step": 8600
    },
    {
      "epoch": 0.2275597179837946,
      "grad_norm": 3.370638847351074,
      "learning_rate": 4.6248332397135236e-05,
      "loss": 1.1343,
      "step": 8650
    },
    {
      "epoch": 0.22887509207618648,
      "grad_norm": 3.4958245754241943,
      "learning_rate": 4.622639025417779e-05,
      "loss": 1.113,
      "step": 8700
    },
    {
      "epoch": 0.23019046616857836,
      "grad_norm": 3.226184844970703,
      "learning_rate": 4.620444811122034e-05,
      "loss": 1.084,
      "step": 8750
    },
    {
      "epoch": 0.2315058402609702,
      "grad_norm": 3.5963146686553955,
      "learning_rate": 4.6182505968262885e-05,
      "loss": 1.082,
      "step": 8800
    },
    {
      "epoch": 0.2328212143533621,
      "grad_norm": 3.373671770095825,
      "learning_rate": 4.616056382530544e-05,
      "loss": 1.0979,
      "step": 8850
    },
    {
      "epoch": 0.23413658844575397,
      "grad_norm": 3.5425708293914795,
      "learning_rate": 4.613862168234799e-05,
      "loss": 1.1099,
      "step": 8900
    },
    {
      "epoch": 0.23545196253814585,
      "grad_norm": 3.440082550048828,
      "learning_rate": 4.611667953939054e-05,
      "loss": 1.0861,
      "step": 8950
    },
    {
      "epoch": 0.23676733663053773,
      "grad_norm": 3.4458281993865967,
      "learning_rate": 4.609473739643309e-05,
      "loss": 1.0689,
      "step": 9000
    },
    {
      "epoch": 0.2380827107229296,
      "grad_norm": 3.2051799297332764,
      "learning_rate": 4.6072795253475636e-05,
      "loss": 1.0822,
      "step": 9050
    },
    {
      "epoch": 0.2393980848153215,
      "grad_norm": 3.7254574298858643,
      "learning_rate": 4.605085311051819e-05,
      "loss": 1.0632,
      "step": 9100
    },
    {
      "epoch": 0.24071345890771334,
      "grad_norm": 3.5449750423431396,
      "learning_rate": 4.602891096756074e-05,
      "loss": 1.0654,
      "step": 9150
    },
    {
      "epoch": 0.24202883300010522,
      "grad_norm": 3.5466675758361816,
      "learning_rate": 4.6006968824603285e-05,
      "loss": 1.0586,
      "step": 9200
    },
    {
      "epoch": 0.2433442070924971,
      "grad_norm": 3.0237770080566406,
      "learning_rate": 4.598502668164584e-05,
      "loss": 1.0352,
      "step": 9250
    },
    {
      "epoch": 0.24465958118488898,
      "grad_norm": 3.4985313415527344,
      "learning_rate": 4.596308453868839e-05,
      "loss": 1.0287,
      "step": 9300
    },
    {
      "epoch": 0.24597495527728086,
      "grad_norm": 3.1623334884643555,
      "learning_rate": 4.594114239573094e-05,
      "loss": 1.0087,
      "step": 9350
    },
    {
      "epoch": 0.24729032936967274,
      "grad_norm": 3.3031067848205566,
      "learning_rate": 4.591920025277349e-05,
      "loss": 1.0316,
      "step": 9400
    },
    {
      "epoch": 0.24860570346206462,
      "grad_norm": 2.7166216373443604,
      "learning_rate": 4.5897258109816036e-05,
      "loss": 1.0401,
      "step": 9450
    },
    {
      "epoch": 0.2499210775544565,
      "grad_norm": 3.2653353214263916,
      "learning_rate": 4.587531596685859e-05,
      "loss": 1.023,
      "step": 9500
    },
    {
      "epoch": 0.2512364516468484,
      "grad_norm": 3.227163076400757,
      "learning_rate": 4.585337382390114e-05,
      "loss": 1.0006,
      "step": 9550
    },
    {
      "epoch": 0.25255182573924023,
      "grad_norm": 3.293539047241211,
      "learning_rate": 4.5831431680943686e-05,
      "loss": 1.0037,
      "step": 9600
    },
    {
      "epoch": 0.25386719983163214,
      "grad_norm": 3.1043334007263184,
      "learning_rate": 4.580948953798624e-05,
      "loss": 0.9992,
      "step": 9650
    },
    {
      "epoch": 0.255182573924024,
      "grad_norm": 3.4505693912506104,
      "learning_rate": 4.578754739502879e-05,
      "loss": 0.9658,
      "step": 9700
    },
    {
      "epoch": 0.25649794801641584,
      "grad_norm": 3.0007901191711426,
      "learning_rate": 4.576560525207134e-05,
      "loss": 0.9706,
      "step": 9750
    },
    {
      "epoch": 0.25781332210880775,
      "grad_norm": 3.3313891887664795,
      "learning_rate": 4.5743663109113896e-05,
      "loss": 0.9598,
      "step": 9800
    },
    {
      "epoch": 0.2591286962011996,
      "grad_norm": 3.2076072692871094,
      "learning_rate": 4.5721720966156437e-05,
      "loss": 0.9682,
      "step": 9850
    },
    {
      "epoch": 0.2604440702935915,
      "grad_norm": 3.260403633117676,
      "learning_rate": 4.569977882319899e-05,
      "loss": 0.9568,
      "step": 9900
    },
    {
      "epoch": 0.26175944438598336,
      "grad_norm": 3.230219841003418,
      "learning_rate": 4.5677836680241545e-05,
      "loss": 0.9537,
      "step": 9950
    },
    {
      "epoch": 0.26307481847837527,
      "grad_norm": 3.1810789108276367,
      "learning_rate": 4.565589453728409e-05,
      "loss": 0.9444,
      "step": 10000
    },
    {
      "epoch": 0.2643901925707671,
      "grad_norm": 3.494575023651123,
      "learning_rate": 4.563395239432664e-05,
      "loss": 0.9122,
      "step": 10050
    },
    {
      "epoch": 0.265705566663159,
      "grad_norm": 3.653334379196167,
      "learning_rate": 4.5612010251369194e-05,
      "loss": 0.905,
      "step": 10100
    },
    {
      "epoch": 0.2670209407555509,
      "grad_norm": 2.9708564281463623,
      "learning_rate": 4.559006810841174e-05,
      "loss": 0.9137,
      "step": 10150
    },
    {
      "epoch": 0.26833631484794274,
      "grad_norm": 3.0757315158843994,
      "learning_rate": 4.5568125965454296e-05,
      "loss": 0.9038,
      "step": 10200
    },
    {
      "epoch": 0.26965168894033464,
      "grad_norm": 3.2796518802642822,
      "learning_rate": 4.5546183822496843e-05,
      "loss": 0.893,
      "step": 10250
    },
    {
      "epoch": 0.2709670630327265,
      "grad_norm": 3.2860803604125977,
      "learning_rate": 4.552424167953939e-05,
      "loss": 0.9261,
      "step": 10300
    },
    {
      "epoch": 0.2722824371251184,
      "grad_norm": 3.781313419342041,
      "learning_rate": 4.5502299536581945e-05,
      "loss": 0.8905,
      "step": 10350
    },
    {
      "epoch": 0.27359781121751026,
      "grad_norm": 2.8962879180908203,
      "learning_rate": 4.548035739362449e-05,
      "loss": 0.8942,
      "step": 10400
    },
    {
      "epoch": 0.27491318530990216,
      "grad_norm": 3.1563656330108643,
      "learning_rate": 4.545841525066704e-05,
      "loss": 0.8808,
      "step": 10450
    },
    {
      "epoch": 0.276228559402294,
      "grad_norm": 3.503777265548706,
      "learning_rate": 4.5436473107709594e-05,
      "loss": 0.8736,
      "step": 10500
    },
    {
      "epoch": 0.27754393349468587,
      "grad_norm": 3.2380638122558594,
      "learning_rate": 4.541453096475214e-05,
      "loss": 0.8567,
      "step": 10550
    },
    {
      "epoch": 0.2788593075870778,
      "grad_norm": 3.213435173034668,
      "learning_rate": 4.5392588821794696e-05,
      "loss": 0.8587,
      "step": 10600
    },
    {
      "epoch": 0.28017468167946963,
      "grad_norm": 3.0643270015716553,
      "learning_rate": 4.5370646678837244e-05,
      "loss": 0.8684,
      "step": 10650
    },
    {
      "epoch": 0.28149005577186154,
      "grad_norm": 3.014063596725464,
      "learning_rate": 4.534870453587979e-05,
      "loss": 0.8467,
      "step": 10700
    },
    {
      "epoch": 0.2828054298642534,
      "grad_norm": 3.0326268672943115,
      "learning_rate": 4.5326762392922345e-05,
      "loss": 0.8426,
      "step": 10750
    },
    {
      "epoch": 0.2841208039566453,
      "grad_norm": 2.934464931488037,
      "learning_rate": 4.53048202499649e-05,
      "loss": 0.838,
      "step": 10800
    },
    {
      "epoch": 0.28543617804903715,
      "grad_norm": 3.30582594871521,
      "learning_rate": 4.528287810700744e-05,
      "loss": 0.8397,
      "step": 10850
    },
    {
      "epoch": 0.286751552141429,
      "grad_norm": 3.0838534832000732,
      "learning_rate": 4.5260935964049995e-05,
      "loss": 0.8289,
      "step": 10900
    },
    {
      "epoch": 0.2880669262338209,
      "grad_norm": 3.064761161804199,
      "learning_rate": 4.523899382109255e-05,
      "loss": 0.8151,
      "step": 10950
    },
    {
      "epoch": 0.28938230032621276,
      "grad_norm": 3.2611160278320312,
      "learning_rate": 4.5217051678135096e-05,
      "loss": 0.8316,
      "step": 11000
    },
    {
      "epoch": 0.29069767441860467,
      "grad_norm": 3.057140350341797,
      "learning_rate": 4.5195109535177644e-05,
      "loss": 0.8093,
      "step": 11050
    },
    {
      "epoch": 0.2920130485109965,
      "grad_norm": 2.962185859680176,
      "learning_rate": 4.51731673922202e-05,
      "loss": 0.8248,
      "step": 11100
    },
    {
      "epoch": 0.29332842260338843,
      "grad_norm": 3.0366640090942383,
      "learning_rate": 4.5151225249262746e-05,
      "loss": 0.7997,
      "step": 11150
    },
    {
      "epoch": 0.2946437966957803,
      "grad_norm": 3.1724936962127686,
      "learning_rate": 4.51292831063053e-05,
      "loss": 0.807,
      "step": 11200
    },
    {
      "epoch": 0.29595917078817213,
      "grad_norm": 2.7166125774383545,
      "learning_rate": 4.510734096334784e-05,
      "loss": 0.7909,
      "step": 11250
    },
    {
      "epoch": 0.29727454488056404,
      "grad_norm": 2.9784135818481445,
      "learning_rate": 4.5085398820390395e-05,
      "loss": 0.8188,
      "step": 11300
    },
    {
      "epoch": 0.2985899189729559,
      "grad_norm": 2.9838805198669434,
      "learning_rate": 4.506345667743295e-05,
      "loss": 0.7882,
      "step": 11350
    },
    {
      "epoch": 0.2999052930653478,
      "grad_norm": 3.1872074604034424,
      "learning_rate": 4.5041514534475497e-05,
      "loss": 0.7947,
      "step": 11400
    },
    {
      "epoch": 0.30122066715773965,
      "grad_norm": 2.776980400085449,
      "learning_rate": 4.501957239151805e-05,
      "loss": 0.7865,
      "step": 11450
    },
    {
      "epoch": 0.30253604125013156,
      "grad_norm": 3.322749376296997,
      "learning_rate": 4.49976302485606e-05,
      "loss": 0.7702,
      "step": 11500
    },
    {
      "epoch": 0.3038514153425234,
      "grad_norm": 3.234407663345337,
      "learning_rate": 4.4975688105603146e-05,
      "loss": 0.7881,
      "step": 11550
    },
    {
      "epoch": 0.30516678943491526,
      "grad_norm": 2.940218448638916,
      "learning_rate": 4.49537459626457e-05,
      "loss": 0.7684,
      "step": 11600
    },
    {
      "epoch": 0.30648216352730717,
      "grad_norm": 2.8729984760284424,
      "learning_rate": 4.493180381968825e-05,
      "loss": 0.7576,
      "step": 11650
    },
    {
      "epoch": 0.307797537619699,
      "grad_norm": 3.138914108276367,
      "learning_rate": 4.4909861676730795e-05,
      "loss": 0.7442,
      "step": 11700
    },
    {
      "epoch": 0.30911291171209093,
      "grad_norm": 2.705392837524414,
      "learning_rate": 4.488791953377335e-05,
      "loss": 0.7487,
      "step": 11750
    },
    {
      "epoch": 0.3104282858044828,
      "grad_norm": 2.935662269592285,
      "learning_rate": 4.48659773908159e-05,
      "loss": 0.7519,
      "step": 11800
    },
    {
      "epoch": 0.3117436598968747,
      "grad_norm": 2.73587703704834,
      "learning_rate": 4.484403524785845e-05,
      "loss": 0.7354,
      "step": 11850
    },
    {
      "epoch": 0.31305903398926654,
      "grad_norm": 3.1390371322631836,
      "learning_rate": 4.4822093104901e-05,
      "loss": 0.7363,
      "step": 11900
    },
    {
      "epoch": 0.3143744080816584,
      "grad_norm": 2.904305934906006,
      "learning_rate": 4.4800150961943546e-05,
      "loss": 0.7295,
      "step": 11950
    },
    {
      "epoch": 0.3156897821740503,
      "grad_norm": 2.815061092376709,
      "learning_rate": 4.47782088189861e-05,
      "loss": 0.7263,
      "step": 12000
    },
    {
      "epoch": 0.31700515626644216,
      "grad_norm": 2.6257686614990234,
      "learning_rate": 4.4756266676028655e-05,
      "loss": 0.7286,
      "step": 12050
    },
    {
      "epoch": 0.31832053035883406,
      "grad_norm": 2.583008050918579,
      "learning_rate": 4.4734324533071195e-05,
      "loss": 0.7187,
      "step": 12100
    },
    {
      "epoch": 0.3196359044512259,
      "grad_norm": 3.060189962387085,
      "learning_rate": 4.471238239011375e-05,
      "loss": 0.7143,
      "step": 12150
    },
    {
      "epoch": 0.3209512785436178,
      "grad_norm": 3.110095977783203,
      "learning_rate": 4.4690440247156304e-05,
      "loss": 0.7162,
      "step": 12200
    },
    {
      "epoch": 0.3222666526360097,
      "grad_norm": 2.943249225616455,
      "learning_rate": 4.466849810419885e-05,
      "loss": 0.6994,
      "step": 12250
    },
    {
      "epoch": 0.3235820267284016,
      "grad_norm": 2.7117364406585693,
      "learning_rate": 4.46465559612414e-05,
      "loss": 0.689,
      "step": 12300
    },
    {
      "epoch": 0.32489740082079344,
      "grad_norm": 3.070216655731201,
      "learning_rate": 4.462461381828395e-05,
      "loss": 0.6984,
      "step": 12350
    },
    {
      "epoch": 0.3262127749131853,
      "grad_norm": 2.931431293487549,
      "learning_rate": 4.46026716753265e-05,
      "loss": 0.6989,
      "step": 12400
    },
    {
      "epoch": 0.3275281490055772,
      "grad_norm": 2.6515653133392334,
      "learning_rate": 4.4580729532369055e-05,
      "loss": 0.6885,
      "step": 12450
    },
    {
      "epoch": 0.32884352309796905,
      "grad_norm": 3.064366340637207,
      "learning_rate": 4.45587873894116e-05,
      "loss": 0.6711,
      "step": 12500
    },
    {
      "epoch": 0.33015889719036096,
      "grad_norm": 2.869436502456665,
      "learning_rate": 4.453684524645415e-05,
      "loss": 0.662,
      "step": 12550
    },
    {
      "epoch": 0.3314742712827528,
      "grad_norm": 2.773674726486206,
      "learning_rate": 4.4514903103496704e-05,
      "loss": 0.6685,
      "step": 12600
    },
    {
      "epoch": 0.3327896453751447,
      "grad_norm": 2.77616286277771,
      "learning_rate": 4.449296096053925e-05,
      "loss": 0.6639,
      "step": 12650
    },
    {
      "epoch": 0.33410501946753657,
      "grad_norm": 2.909740447998047,
      "learning_rate": 4.44710188175818e-05,
      "loss": 0.6612,
      "step": 12700
    },
    {
      "epoch": 0.3354203935599284,
      "grad_norm": 2.940307140350342,
      "learning_rate": 4.444907667462435e-05,
      "loss": 0.6542,
      "step": 12750
    },
    {
      "epoch": 0.33673576765232033,
      "grad_norm": 2.9244985580444336,
      "learning_rate": 4.44271345316669e-05,
      "loss": 0.6657,
      "step": 12800
    },
    {
      "epoch": 0.3380511417447122,
      "grad_norm": 2.8674862384796143,
      "learning_rate": 4.4405192388709455e-05,
      "loss": 0.6478,
      "step": 12850
    },
    {
      "epoch": 0.3393665158371041,
      "grad_norm": 2.9744865894317627,
      "learning_rate": 4.4383250245752e-05,
      "loss": 0.658,
      "step": 12900
    },
    {
      "epoch": 0.34068188992949594,
      "grad_norm": 2.990710735321045,
      "learning_rate": 4.436130810279455e-05,
      "loss": 0.6392,
      "step": 12950
    },
    {
      "epoch": 0.34199726402188785,
      "grad_norm": 2.699868679046631,
      "learning_rate": 4.4339365959837104e-05,
      "loss": 0.6515,
      "step": 13000
    },
    {
      "epoch": 0.3433126381142797,
      "grad_norm": 2.740922212600708,
      "learning_rate": 4.431742381687966e-05,
      "loss": 0.6535,
      "step": 13050
    },
    {
      "epoch": 0.34462801220667155,
      "grad_norm": 2.973483085632324,
      "learning_rate": 4.4295481673922206e-05,
      "loss": 0.6341,
      "step": 13100
    },
    {
      "epoch": 0.34594338629906346,
      "grad_norm": 2.4955503940582275,
      "learning_rate": 4.427353953096475e-05,
      "loss": 0.6315,
      "step": 13150
    },
    {
      "epoch": 0.3472587603914553,
      "grad_norm": 2.520702838897705,
      "learning_rate": 4.425159738800731e-05,
      "loss": 0.6253,
      "step": 13200
    },
    {
      "epoch": 0.3485741344838472,
      "grad_norm": 2.706864356994629,
      "learning_rate": 4.4229655245049855e-05,
      "loss": 0.6242,
      "step": 13250
    },
    {
      "epoch": 0.34988950857623907,
      "grad_norm": 2.8329126834869385,
      "learning_rate": 4.420771310209241e-05,
      "loss": 0.6236,
      "step": 13300
    },
    {
      "epoch": 0.351204882668631,
      "grad_norm": 2.675360918045044,
      "learning_rate": 4.418577095913495e-05,
      "loss": 0.6098,
      "step": 13350
    },
    {
      "epoch": 0.35252025676102283,
      "grad_norm": 2.8619494438171387,
      "learning_rate": 4.4163828816177504e-05,
      "loss": 0.5916,
      "step": 13400
    },
    {
      "epoch": 0.3538356308534147,
      "grad_norm": 3.000617027282715,
      "learning_rate": 4.414188667322006e-05,
      "loss": 0.616,
      "step": 13450
    },
    {
      "epoch": 0.3551510049458066,
      "grad_norm": 2.789241313934326,
      "learning_rate": 4.4119944530262606e-05,
      "loss": 0.6116,
      "step": 13500
    },
    {
      "epoch": 0.35646637903819844,
      "grad_norm": 2.6547443866729736,
      "learning_rate": 4.4098002387305154e-05,
      "loss": 0.5908,
      "step": 13550
    },
    {
      "epoch": 0.35778175313059035,
      "grad_norm": 2.4766688346862793,
      "learning_rate": 4.407606024434771e-05,
      "loss": 0.5986,
      "step": 13600
    },
    {
      "epoch": 0.3590971272229822,
      "grad_norm": 2.6894354820251465,
      "learning_rate": 4.4054118101390255e-05,
      "loss": 0.5979,
      "step": 13650
    },
    {
      "epoch": 0.3604125013153741,
      "grad_norm": 2.8115947246551514,
      "learning_rate": 4.403217595843281e-05,
      "loss": 0.5783,
      "step": 13700
    },
    {
      "epoch": 0.36172787540776596,
      "grad_norm": 2.5773770809173584,
      "learning_rate": 4.401023381547536e-05,
      "loss": 0.5859,
      "step": 13750
    },
    {
      "epoch": 0.36304324950015787,
      "grad_norm": 2.727440595626831,
      "learning_rate": 4.3988291672517904e-05,
      "loss": 0.5864,
      "step": 13800
    },
    {
      "epoch": 0.3643586235925497,
      "grad_norm": 2.6812055110931396,
      "learning_rate": 4.396634952956046e-05,
      "loss": 0.5894,
      "step": 13850
    },
    {
      "epoch": 0.3656739976849416,
      "grad_norm": 2.7384026050567627,
      "learning_rate": 4.3944407386603006e-05,
      "loss": 0.5853,
      "step": 13900
    },
    {
      "epoch": 0.3669893717773335,
      "grad_norm": 2.936875343322754,
      "learning_rate": 4.3922465243645554e-05,
      "loss": 0.5833,
      "step": 13950
    },
    {
      "epoch": 0.36830474586972534,
      "grad_norm": 2.8788137435913086,
      "learning_rate": 4.390052310068811e-05,
      "loss": 0.5744,
      "step": 14000
    },
    {
      "epoch": 0.36962011996211724,
      "grad_norm": 2.592273712158203,
      "learning_rate": 4.3878580957730655e-05,
      "loss": 0.5683,
      "step": 14050
    },
    {
      "epoch": 0.3709354940545091,
      "grad_norm": 2.562497138977051,
      "learning_rate": 4.385663881477321e-05,
      "loss": 0.5661,
      "step": 14100
    },
    {
      "epoch": 0.372250868146901,
      "grad_norm": 2.4759182929992676,
      "learning_rate": 4.383469667181576e-05,
      "loss": 0.5516,
      "step": 14150
    },
    {
      "epoch": 0.37356624223929286,
      "grad_norm": 2.499873638153076,
      "learning_rate": 4.3812754528858305e-05,
      "loss": 0.5569,
      "step": 14200
    },
    {
      "epoch": 0.3748816163316847,
      "grad_norm": 2.603523015975952,
      "learning_rate": 4.379081238590086e-05,
      "loss": 0.5588,
      "step": 14250
    },
    {
      "epoch": 0.3761969904240766,
      "grad_norm": 2.606407880783081,
      "learning_rate": 4.376887024294341e-05,
      "loss": 0.5579,
      "step": 14300
    },
    {
      "epoch": 0.37751236451646847,
      "grad_norm": 2.543240785598755,
      "learning_rate": 4.3746928099985954e-05,
      "loss": 0.5519,
      "step": 14350
    },
    {
      "epoch": 0.3788277386088604,
      "grad_norm": 2.586846113204956,
      "learning_rate": 4.372498595702851e-05,
      "loss": 0.5411,
      "step": 14400
    },
    {
      "epoch": 0.38014311270125223,
      "grad_norm": 2.7681398391723633,
      "learning_rate": 4.370304381407106e-05,
      "loss": 0.5423,
      "step": 14450
    },
    {
      "epoch": 0.38145848679364414,
      "grad_norm": 2.4719860553741455,
      "learning_rate": 4.368110167111361e-05,
      "loss": 0.5426,
      "step": 14500
    },
    {
      "epoch": 0.382773860886036,
      "grad_norm": 2.4519734382629395,
      "learning_rate": 4.365915952815616e-05,
      "loss": 0.5372,
      "step": 14550
    },
    {
      "epoch": 0.38408923497842784,
      "grad_norm": 2.5911545753479004,
      "learning_rate": 4.363721738519871e-05,
      "loss": 0.5299,
      "step": 14600
    },
    {
      "epoch": 0.38540460907081975,
      "grad_norm": 2.719980478286743,
      "learning_rate": 4.361527524224126e-05,
      "loss": 0.532,
      "step": 14650
    },
    {
      "epoch": 0.3867199831632116,
      "grad_norm": 2.3516337871551514,
      "learning_rate": 4.359333309928381e-05,
      "loss": 0.524,
      "step": 14700
    },
    {
      "epoch": 0.3880353572556035,
      "grad_norm": 2.357236862182617,
      "learning_rate": 4.357139095632636e-05,
      "loss": 0.5305,
      "step": 14750
    },
    {
      "epoch": 0.38935073134799536,
      "grad_norm": 2.386638879776001,
      "learning_rate": 4.354944881336891e-05,
      "loss": 0.5273,
      "step": 14800
    },
    {
      "epoch": 0.39066610544038727,
      "grad_norm": 2.4769434928894043,
      "learning_rate": 4.352750667041146e-05,
      "loss": 0.5269,
      "step": 14850
    },
    {
      "epoch": 0.3919814795327791,
      "grad_norm": 2.2444844245910645,
      "learning_rate": 4.350556452745401e-05,
      "loss": 0.5151,
      "step": 14900
    },
    {
      "epoch": 0.393296853625171,
      "grad_norm": 2.4094343185424805,
      "learning_rate": 4.3483622384496564e-05,
      "loss": 0.508,
      "step": 14950
    },
    {
      "epoch": 0.3946122277175629,
      "grad_norm": 2.4472122192382812,
      "learning_rate": 4.346168024153911e-05,
      "loss": 0.5057,
      "step": 15000
    },
    {
      "epoch": 0.39592760180995473,
      "grad_norm": 2.4776344299316406,
      "learning_rate": 4.343973809858166e-05,
      "loss": 0.5064,
      "step": 15050
    },
    {
      "epoch": 0.39724297590234664,
      "grad_norm": 2.22937273979187,
      "learning_rate": 4.3417795955624214e-05,
      "loss": 0.5193,
      "step": 15100
    },
    {
      "epoch": 0.3985583499947385,
      "grad_norm": 2.6266849040985107,
      "learning_rate": 4.339585381266677e-05,
      "loss": 0.4983,
      "step": 15150
    },
    {
      "epoch": 0.3998737240871304,
      "grad_norm": 2.5347166061401367,
      "learning_rate": 4.337391166970931e-05,
      "loss": 0.4965,
      "step": 15200
    },
    {
      "epoch": 0.40118909817952225,
      "grad_norm": 2.5053019523620605,
      "learning_rate": 4.335196952675186e-05,
      "loss": 0.4911,
      "step": 15250
    },
    {
      "epoch": 0.40250447227191416,
      "grad_norm": 2.6572303771972656,
      "learning_rate": 4.333002738379442e-05,
      "loss": 0.5021,
      "step": 15300
    },
    {
      "epoch": 0.403819846364306,
      "grad_norm": 2.6189658641815186,
      "learning_rate": 4.3308085240836965e-05,
      "loss": 0.4838,
      "step": 15350
    },
    {
      "epoch": 0.40513522045669786,
      "grad_norm": 2.2695157527923584,
      "learning_rate": 4.328614309787951e-05,
      "loss": 0.4977,
      "step": 15400
    },
    {
      "epoch": 0.40645059454908977,
      "grad_norm": 2.434584856033325,
      "learning_rate": 4.326420095492206e-05,
      "loss": 0.4926,
      "step": 15450
    },
    {
      "epoch": 0.4077659686414816,
      "grad_norm": 2.376437187194824,
      "learning_rate": 4.3242258811964614e-05,
      "loss": 0.4863,
      "step": 15500
    },
    {
      "epoch": 0.40908134273387353,
      "grad_norm": 2.409959554672241,
      "learning_rate": 4.322031666900717e-05,
      "loss": 0.4848,
      "step": 15550
    },
    {
      "epoch": 0.4103967168262654,
      "grad_norm": 2.4562735557556152,
      "learning_rate": 4.319837452604971e-05,
      "loss": 0.4808,
      "step": 15600
    },
    {
      "epoch": 0.4117120909186573,
      "grad_norm": 2.254756212234497,
      "learning_rate": 4.317643238309226e-05,
      "loss": 0.4666,
      "step": 15650
    },
    {
      "epoch": 0.41302746501104914,
      "grad_norm": 2.2607531547546387,
      "learning_rate": 4.315449024013482e-05,
      "loss": 0.4828,
      "step": 15700
    },
    {
      "epoch": 0.414342839103441,
      "grad_norm": 2.5096018314361572,
      "learning_rate": 4.3132548097177365e-05,
      "loss": 0.4676,
      "step": 15750
    },
    {
      "epoch": 0.4156582131958329,
      "grad_norm": 2.4482505321502686,
      "learning_rate": 4.311060595421991e-05,
      "loss": 0.4559,
      "step": 15800
    },
    {
      "epoch": 0.41697358728822476,
      "grad_norm": 2.353076934814453,
      "learning_rate": 4.3088663811262466e-05,
      "loss": 0.4655,
      "step": 15850
    },
    {
      "epoch": 0.41828896138061666,
      "grad_norm": 2.1600756645202637,
      "learning_rate": 4.3066721668305014e-05,
      "loss": 0.4645,
      "step": 15900
    },
    {
      "epoch": 0.4196043354730085,
      "grad_norm": 2.6957943439483643,
      "learning_rate": 4.304477952534757e-05,
      "loss": 0.4645,
      "step": 15950
    },
    {
      "epoch": 0.4209197095654004,
      "grad_norm": 2.5809781551361084,
      "learning_rate": 4.3022837382390116e-05,
      "loss": 0.4572,
      "step": 16000
    },
    {
      "epoch": 0.4222350836577923,
      "grad_norm": 2.542050361633301,
      "learning_rate": 4.300089523943266e-05,
      "loss": 0.4497,
      "step": 16050
    },
    {
      "epoch": 0.42355045775018413,
      "grad_norm": 2.4986584186553955,
      "learning_rate": 4.297895309647522e-05,
      "loss": 0.4548,
      "step": 16100
    },
    {
      "epoch": 0.42486583184257604,
      "grad_norm": 2.370870590209961,
      "learning_rate": 4.2957010953517765e-05,
      "loss": 0.4463,
      "step": 16150
    },
    {
      "epoch": 0.4261812059349679,
      "grad_norm": 2.2410635948181152,
      "learning_rate": 4.293506881056032e-05,
      "loss": 0.4506,
      "step": 16200
    },
    {
      "epoch": 0.4274965800273598,
      "grad_norm": 2.253066301345825,
      "learning_rate": 4.291312666760287e-05,
      "loss": 0.4491,
      "step": 16250
    },
    {
      "epoch": 0.42881195411975165,
      "grad_norm": 1.9927785396575928,
      "learning_rate": 4.2891184524645414e-05,
      "loss": 0.4394,
      "step": 16300
    },
    {
      "epoch": 0.43012732821214356,
      "grad_norm": 2.297797918319702,
      "learning_rate": 4.286924238168797e-05,
      "loss": 0.4437,
      "step": 16350
    },
    {
      "epoch": 0.4314427023045354,
      "grad_norm": 2.1411664485931396,
      "learning_rate": 4.284730023873052e-05,
      "loss": 0.4419,
      "step": 16400
    },
    {
      "epoch": 0.43275807639692726,
      "grad_norm": 2.3555705547332764,
      "learning_rate": 4.282535809577306e-05,
      "loss": 0.4457,
      "step": 16450
    },
    {
      "epoch": 0.43407345048931917,
      "grad_norm": 2.339259386062622,
      "learning_rate": 4.280341595281562e-05,
      "loss": 0.433,
      "step": 16500
    },
    {
      "epoch": 0.435388824581711,
      "grad_norm": 2.325526237487793,
      "learning_rate": 4.278147380985817e-05,
      "loss": 0.4388,
      "step": 16550
    },
    {
      "epoch": 0.43670419867410293,
      "grad_norm": 2.032620906829834,
      "learning_rate": 4.275953166690072e-05,
      "loss": 0.4365,
      "step": 16600
    },
    {
      "epoch": 0.4380195727664948,
      "grad_norm": 2.3665435314178467,
      "learning_rate": 4.273758952394327e-05,
      "loss": 0.4356,
      "step": 16650
    },
    {
      "epoch": 0.4393349468588867,
      "grad_norm": 2.293567180633545,
      "learning_rate": 4.271564738098582e-05,
      "loss": 0.4277,
      "step": 16700
    },
    {
      "epoch": 0.44065032095127854,
      "grad_norm": 2.5700337886810303,
      "learning_rate": 4.269370523802837e-05,
      "loss": 0.4278,
      "step": 16750
    },
    {
      "epoch": 0.4419656950436704,
      "grad_norm": 2.384019374847412,
      "learning_rate": 4.267176309507092e-05,
      "loss": 0.432,
      "step": 16800
    },
    {
      "epoch": 0.4432810691360623,
      "grad_norm": 2.189366340637207,
      "learning_rate": 4.264982095211347e-05,
      "loss": 0.4228,
      "step": 16850
    },
    {
      "epoch": 0.44459644322845415,
      "grad_norm": 2.488101005554199,
      "learning_rate": 4.262787880915602e-05,
      "loss": 0.4306,
      "step": 16900
    },
    {
      "epoch": 0.44591181732084606,
      "grad_norm": 2.424798011779785,
      "learning_rate": 4.260593666619857e-05,
      "loss": 0.4135,
      "step": 16950
    },
    {
      "epoch": 0.4472271914132379,
      "grad_norm": 1.9927325248718262,
      "learning_rate": 4.258399452324112e-05,
      "loss": 0.4141,
      "step": 17000
    },
    {
      "epoch": 0.4485425655056298,
      "grad_norm": 2.1556479930877686,
      "learning_rate": 4.256205238028367e-05,
      "loss": 0.4142,
      "step": 17050
    },
    {
      "epoch": 0.44985793959802167,
      "grad_norm": 2.3439714908599854,
      "learning_rate": 4.254011023732622e-05,
      "loss": 0.4112,
      "step": 17100
    },
    {
      "epoch": 0.4511733136904136,
      "grad_norm": 2.096755266189575,
      "learning_rate": 4.251816809436877e-05,
      "loss": 0.4127,
      "step": 17150
    },
    {
      "epoch": 0.45248868778280543,
      "grad_norm": 2.6717312335968018,
      "learning_rate": 4.249622595141132e-05,
      "loss": 0.4139,
      "step": 17200
    },
    {
      "epoch": 0.4538040618751973,
      "grad_norm": 2.1211702823638916,
      "learning_rate": 4.247428380845387e-05,
      "loss": 0.409,
      "step": 17250
    },
    {
      "epoch": 0.4551194359675892,
      "grad_norm": 2.0945515632629395,
      "learning_rate": 4.245234166549642e-05,
      "loss": 0.4043,
      "step": 17300
    },
    {
      "epoch": 0.45643481005998104,
      "grad_norm": 2.05155611038208,
      "learning_rate": 4.243039952253897e-05,
      "loss": 0.3999,
      "step": 17350
    },
    {
      "epoch": 0.45775018415237295,
      "grad_norm": 2.2186594009399414,
      "learning_rate": 4.2408457379581527e-05,
      "loss": 0.4022,
      "step": 17400
    },
    {
      "epoch": 0.4590655582447648,
      "grad_norm": 2.1839582920074463,
      "learning_rate": 4.238651523662407e-05,
      "loss": 0.3992,
      "step": 17450
    },
    {
      "epoch": 0.4603809323371567,
      "grad_norm": 2.3255302906036377,
      "learning_rate": 4.236457309366662e-05,
      "loss": 0.3992,
      "step": 17500
    },
    {
      "epoch": 0.46169630642954856,
      "grad_norm": 2.019540548324585,
      "learning_rate": 4.234263095070917e-05,
      "loss": 0.3987,
      "step": 17550
    },
    {
      "epoch": 0.4630116805219404,
      "grad_norm": 2.2276692390441895,
      "learning_rate": 4.232068880775172e-05,
      "loss": 0.393,
      "step": 17600
    },
    {
      "epoch": 0.4643270546143323,
      "grad_norm": 2.002012014389038,
      "learning_rate": 4.229874666479427e-05,
      "loss": 0.3967,
      "step": 17650
    },
    {
      "epoch": 0.4656424287067242,
      "grad_norm": 2.2188966274261475,
      "learning_rate": 4.227680452183682e-05,
      "loss": 0.3951,
      "step": 17700
    },
    {
      "epoch": 0.4669578027991161,
      "grad_norm": 2.121962308883667,
      "learning_rate": 4.225486237887937e-05,
      "loss": 0.3849,
      "step": 17750
    },
    {
      "epoch": 0.46827317689150794,
      "grad_norm": 1.8132470846176147,
      "learning_rate": 4.223292023592193e-05,
      "loss": 0.3936,
      "step": 17800
    },
    {
      "epoch": 0.46958855098389984,
      "grad_norm": 1.9530643224716187,
      "learning_rate": 4.2210978092964474e-05,
      "loss": 0.3871,
      "step": 17850
    },
    {
      "epoch": 0.4709039250762917,
      "grad_norm": 2.1460204124450684,
      "learning_rate": 4.218903595000702e-05,
      "loss": 0.4036,
      "step": 17900
    },
    {
      "epoch": 0.47221929916868355,
      "grad_norm": 2.0865912437438965,
      "learning_rate": 4.2167093807049576e-05,
      "loss": 0.3807,
      "step": 17950
    },
    {
      "epoch": 0.47353467326107546,
      "grad_norm": 2.2129032611846924,
      "learning_rate": 4.2145151664092123e-05,
      "loss": 0.3751,
      "step": 18000
    },
    {
      "epoch": 0.4748500473534673,
      "grad_norm": 2.2225730419158936,
      "learning_rate": 4.212320952113468e-05,
      "loss": 0.3844,
      "step": 18050
    },
    {
      "epoch": 0.4761654214458592,
      "grad_norm": 1.7696316242218018,
      "learning_rate": 4.2101267378177225e-05,
      "loss": 0.3882,
      "step": 18100
    },
    {
      "epoch": 0.47748079553825107,
      "grad_norm": 1.8403377532958984,
      "learning_rate": 4.207932523521977e-05,
      "loss": 0.3856,
      "step": 18150
    },
    {
      "epoch": 0.478796169630643,
      "grad_norm": 1.9796980619430542,
      "learning_rate": 4.205738309226233e-05,
      "loss": 0.3901,
      "step": 18200
    },
    {
      "epoch": 0.48011154372303483,
      "grad_norm": 2.200497627258301,
      "learning_rate": 4.2035440949304874e-05,
      "loss": 0.3801,
      "step": 18250
    },
    {
      "epoch": 0.4814269178154267,
      "grad_norm": 1.8627232313156128,
      "learning_rate": 4.201349880634742e-05,
      "loss": 0.3742,
      "step": 18300
    },
    {
      "epoch": 0.4827422919078186,
      "grad_norm": 2.250370502471924,
      "learning_rate": 4.1991556663389976e-05,
      "loss": 0.3776,
      "step": 18350
    },
    {
      "epoch": 0.48405766600021044,
      "grad_norm": 2.180147409439087,
      "learning_rate": 4.1969614520432524e-05,
      "loss": 0.3765,
      "step": 18400
    },
    {
      "epoch": 0.48537304009260235,
      "grad_norm": 1.9857169389724731,
      "learning_rate": 4.194767237747508e-05,
      "loss": 0.3684,
      "step": 18450
    },
    {
      "epoch": 0.4866884141849942,
      "grad_norm": 1.8866641521453857,
      "learning_rate": 4.1925730234517625e-05,
      "loss": 0.3689,
      "step": 18500
    },
    {
      "epoch": 0.4880037882773861,
      "grad_norm": 2.1667842864990234,
      "learning_rate": 4.190378809156017e-05,
      "loss": 0.3639,
      "step": 18550
    },
    {
      "epoch": 0.48931916236977796,
      "grad_norm": 2.094841480255127,
      "learning_rate": 4.188184594860273e-05,
      "loss": 0.3649,
      "step": 18600
    },
    {
      "epoch": 0.49063453646216987,
      "grad_norm": 2.043488025665283,
      "learning_rate": 4.185990380564528e-05,
      "loss": 0.3563,
      "step": 18650
    },
    {
      "epoch": 0.4919499105545617,
      "grad_norm": 2.0477895736694336,
      "learning_rate": 4.183796166268782e-05,
      "loss": 0.3651,
      "step": 18700
    },
    {
      "epoch": 0.4932652846469536,
      "grad_norm": 2.0176632404327393,
      "learning_rate": 4.1816019519730376e-05,
      "loss": 0.3662,
      "step": 18750
    },
    {
      "epoch": 0.4945806587393455,
      "grad_norm": 2.0719072818756104,
      "learning_rate": 4.179407737677293e-05,
      "loss": 0.3598,
      "step": 18800
    },
    {
      "epoch": 0.49589603283173733,
      "grad_norm": 2.376417636871338,
      "learning_rate": 4.177213523381548e-05,
      "loss": 0.357,
      "step": 18850
    },
    {
      "epoch": 0.49721140692412924,
      "grad_norm": 1.9602831602096558,
      "learning_rate": 4.1750193090858026e-05,
      "loss": 0.355,
      "step": 18900
    },
    {
      "epoch": 0.4985267810165211,
      "grad_norm": 2.0812582969665527,
      "learning_rate": 4.172825094790058e-05,
      "loss": 0.3586,
      "step": 18950
    },
    {
      "epoch": 0.499842155108913,
      "grad_norm": 1.9111384153366089,
      "learning_rate": 4.170630880494313e-05,
      "loss": 0.3567,
      "step": 19000
    },
    {
      "epoch": 0.5011575292013049,
      "grad_norm": 1.9391937255859375,
      "learning_rate": 4.168436666198568e-05,
      "loss": 0.353,
      "step": 19050
    },
    {
      "epoch": 0.5024729032936968,
      "grad_norm": 1.913360834121704,
      "learning_rate": 4.166242451902823e-05,
      "loss": 0.3605,
      "step": 19100
    },
    {
      "epoch": 0.5037882773860886,
      "grad_norm": 2.099674701690674,
      "learning_rate": 4.1640482376070777e-05,
      "loss": 0.3508,
      "step": 19150
    },
    {
      "epoch": 0.5051036514784805,
      "grad_norm": 2.1020667552948,
      "learning_rate": 4.161854023311333e-05,
      "loss": 0.3448,
      "step": 19200
    },
    {
      "epoch": 0.5064190255708724,
      "grad_norm": 2.141920328140259,
      "learning_rate": 4.159659809015588e-05,
      "loss": 0.3598,
      "step": 19250
    },
    {
      "epoch": 0.5077343996632643,
      "grad_norm": 1.967569351196289,
      "learning_rate": 4.1574655947198426e-05,
      "loss": 0.3457,
      "step": 19300
    },
    {
      "epoch": 0.5090497737556561,
      "grad_norm": 1.965361475944519,
      "learning_rate": 4.155271380424098e-05,
      "loss": 0.3475,
      "step": 19350
    },
    {
      "epoch": 0.510365147848048,
      "grad_norm": 1.9495199918746948,
      "learning_rate": 4.153077166128353e-05,
      "loss": 0.3408,
      "step": 19400
    },
    {
      "epoch": 0.5116805219404399,
      "grad_norm": 2.1132025718688965,
      "learning_rate": 4.150882951832608e-05,
      "loss": 0.3459,
      "step": 19450
    },
    {
      "epoch": 0.5129958960328317,
      "grad_norm": 1.9519342184066772,
      "learning_rate": 4.1486887375368636e-05,
      "loss": 0.3347,
      "step": 19500
    },
    {
      "epoch": 0.5143112701252236,
      "grad_norm": 1.9398012161254883,
      "learning_rate": 4.146494523241118e-05,
      "loss": 0.3438,
      "step": 19550
    },
    {
      "epoch": 0.5156266442176155,
      "grad_norm": 1.8094286918640137,
      "learning_rate": 4.144300308945373e-05,
      "loss": 0.3419,
      "step": 19600
    },
    {
      "epoch": 0.5169420183100074,
      "grad_norm": 1.8314257860183716,
      "learning_rate": 4.142106094649628e-05,
      "loss": 0.3387,
      "step": 19650
    },
    {
      "epoch": 0.5182573924023992,
      "grad_norm": 2.0593347549438477,
      "learning_rate": 4.139911880353883e-05,
      "loss": 0.3357,
      "step": 19700
    },
    {
      "epoch": 0.5195727664947911,
      "grad_norm": 1.9936552047729492,
      "learning_rate": 4.137717666058138e-05,
      "loss": 0.3335,
      "step": 19750
    },
    {
      "epoch": 0.520888140587183,
      "grad_norm": 2.0990045070648193,
      "learning_rate": 4.135523451762393e-05,
      "loss": 0.3381,
      "step": 19800
    },
    {
      "epoch": 0.5222035146795748,
      "grad_norm": 1.9891599416732788,
      "learning_rate": 4.133329237466648e-05,
      "loss": 0.3361,
      "step": 19850
    },
    {
      "epoch": 0.5235188887719667,
      "grad_norm": 1.6667726039886475,
      "learning_rate": 4.1311350231709036e-05,
      "loss": 0.331,
      "step": 19900
    },
    {
      "epoch": 0.5248342628643586,
      "grad_norm": 1.970432996749878,
      "learning_rate": 4.128940808875158e-05,
      "loss": 0.3334,
      "step": 19950
    },
    {
      "epoch": 0.5261496369567505,
      "grad_norm": 1.803802251815796,
      "learning_rate": 4.126746594579413e-05,
      "loss": 0.3252,
      "step": 20000
    },
    {
      "epoch": 0.5274650110491423,
      "grad_norm": 2.034318447113037,
      "learning_rate": 4.1245523802836685e-05,
      "loss": 0.3286,
      "step": 20050
    },
    {
      "epoch": 0.5287803851415342,
      "grad_norm": 2.1091957092285156,
      "learning_rate": 4.122358165987923e-05,
      "loss": 0.3351,
      "step": 20100
    },
    {
      "epoch": 0.5300957592339262,
      "grad_norm": 2.1287682056427,
      "learning_rate": 4.120163951692178e-05,
      "loss": 0.3225,
      "step": 20150
    },
    {
      "epoch": 0.531411133326318,
      "grad_norm": 2.042827606201172,
      "learning_rate": 4.1179697373964335e-05,
      "loss": 0.3295,
      "step": 20200
    },
    {
      "epoch": 0.5327265074187099,
      "grad_norm": 1.7641535997390747,
      "learning_rate": 4.115775523100688e-05,
      "loss": 0.3263,
      "step": 20250
    },
    {
      "epoch": 0.5340418815111018,
      "grad_norm": 1.8016870021820068,
      "learning_rate": 4.1135813088049436e-05,
      "loss": 0.3281,
      "step": 20300
    },
    {
      "epoch": 0.5353572556034937,
      "grad_norm": 1.872923731803894,
      "learning_rate": 4.1113870945091984e-05,
      "loss": 0.3224,
      "step": 20350
    },
    {
      "epoch": 0.5366726296958855,
      "grad_norm": 1.7890948057174683,
      "learning_rate": 4.109192880213453e-05,
      "loss": 0.326,
      "step": 20400
    },
    {
      "epoch": 0.5379880037882774,
      "grad_norm": 1.9087640047073364,
      "learning_rate": 4.1069986659177086e-05,
      "loss": 0.3167,
      "step": 20450
    },
    {
      "epoch": 0.5393033778806693,
      "grad_norm": 1.8644334077835083,
      "learning_rate": 4.104804451621963e-05,
      "loss": 0.3221,
      "step": 20500
    },
    {
      "epoch": 0.5406187519730611,
      "grad_norm": 1.8518412113189697,
      "learning_rate": 4.102610237326218e-05,
      "loss": 0.3262,
      "step": 20550
    },
    {
      "epoch": 0.541934126065453,
      "grad_norm": 1.8928602933883667,
      "learning_rate": 4.1004160230304735e-05,
      "loss": 0.3288,
      "step": 20600
    },
    {
      "epoch": 0.5432495001578449,
      "grad_norm": 1.8837379217147827,
      "learning_rate": 4.098221808734728e-05,
      "loss": 0.3199,
      "step": 20650
    },
    {
      "epoch": 0.5445648742502368,
      "grad_norm": 1.9670252799987793,
      "learning_rate": 4.0960275944389837e-05,
      "loss": 0.3129,
      "step": 20700
    },
    {
      "epoch": 0.5458802483426286,
      "grad_norm": 1.9259365797042847,
      "learning_rate": 4.0938333801432384e-05,
      "loss": 0.3128,
      "step": 20750
    },
    {
      "epoch": 0.5471956224350205,
      "grad_norm": 2.068244457244873,
      "learning_rate": 4.091639165847493e-05,
      "loss": 0.3216,
      "step": 20800
    },
    {
      "epoch": 0.5485109965274124,
      "grad_norm": 1.9397516250610352,
      "learning_rate": 4.0894449515517486e-05,
      "loss": 0.3156,
      "step": 20850
    },
    {
      "epoch": 0.5498263706198043,
      "grad_norm": 1.795192003250122,
      "learning_rate": 4.087250737256004e-05,
      "loss": 0.304,
      "step": 20900
    },
    {
      "epoch": 0.5511417447121961,
      "grad_norm": 1.7101761102676392,
      "learning_rate": 4.085056522960258e-05,
      "loss": 0.3114,
      "step": 20950
    },
    {
      "epoch": 0.552457118804588,
      "grad_norm": 1.870035171508789,
      "learning_rate": 4.0828623086645135e-05,
      "loss": 0.3142,
      "step": 21000
    },
    {
      "epoch": 0.5537724928969799,
      "grad_norm": 2.002314805984497,
      "learning_rate": 4.080668094368769e-05,
      "loss": 0.308,
      "step": 21050
    },
    {
      "epoch": 0.5550878669893717,
      "grad_norm": 1.8113762140274048,
      "learning_rate": 4.078473880073024e-05,
      "loss": 0.3157,
      "step": 21100
    },
    {
      "epoch": 0.5564032410817636,
      "grad_norm": 2.0075182914733887,
      "learning_rate": 4.076279665777279e-05,
      "loss": 0.3089,
      "step": 21150
    },
    {
      "epoch": 0.5577186151741556,
      "grad_norm": 2.0144240856170654,
      "learning_rate": 4.074085451481534e-05,
      "loss": 0.3066,
      "step": 21200
    },
    {
      "epoch": 0.5590339892665475,
      "grad_norm": 1.815737009048462,
      "learning_rate": 4.0718912371857886e-05,
      "loss": 0.3,
      "step": 21250
    },
    {
      "epoch": 0.5603493633589393,
      "grad_norm": 1.7563189268112183,
      "learning_rate": 4.069697022890044e-05,
      "loss": 0.3046,
      "step": 21300
    },
    {
      "epoch": 0.5616647374513312,
      "grad_norm": 1.8740389347076416,
      "learning_rate": 4.067502808594299e-05,
      "loss": 0.292,
      "step": 21350
    },
    {
      "epoch": 0.5629801115437231,
      "grad_norm": 1.64962637424469,
      "learning_rate": 4.0653085942985535e-05,
      "loss": 0.298,
      "step": 21400
    },
    {
      "epoch": 0.5642954856361149,
      "grad_norm": 1.933121681213379,
      "learning_rate": 4.063114380002809e-05,
      "loss": 0.3063,
      "step": 21450
    },
    {
      "epoch": 0.5656108597285068,
      "grad_norm": 1.9920742511749268,
      "learning_rate": 4.060920165707064e-05,
      "loss": 0.2972,
      "step": 21500
    },
    {
      "epoch": 0.5669262338208987,
      "grad_norm": 1.98365318775177,
      "learning_rate": 4.058725951411319e-05,
      "loss": 0.3059,
      "step": 21550
    },
    {
      "epoch": 0.5682416079132906,
      "grad_norm": 2.0012173652648926,
      "learning_rate": 4.056531737115574e-05,
      "loss": 0.3014,
      "step": 21600
    },
    {
      "epoch": 0.5695569820056824,
      "grad_norm": 1.7504949569702148,
      "learning_rate": 4.0543375228198286e-05,
      "loss": 0.2988,
      "step": 21650
    },
    {
      "epoch": 0.5708723560980743,
      "grad_norm": 1.6435582637786865,
      "learning_rate": 4.052143308524084e-05,
      "loss": 0.2963,
      "step": 21700
    },
    {
      "epoch": 0.5721877301904662,
      "grad_norm": 1.6290277242660522,
      "learning_rate": 4.049949094228339e-05,
      "loss": 0.2941,
      "step": 21750
    },
    {
      "epoch": 0.573503104282858,
      "grad_norm": 1.9443527460098267,
      "learning_rate": 4.0477548799325935e-05,
      "loss": 0.2961,
      "step": 21800
    },
    {
      "epoch": 0.5748184783752499,
      "grad_norm": 1.811331033706665,
      "learning_rate": 4.045560665636849e-05,
      "loss": 0.2921,
      "step": 21850
    },
    {
      "epoch": 0.5761338524676418,
      "grad_norm": 1.8747193813323975,
      "learning_rate": 4.043366451341104e-05,
      "loss": 0.2957,
      "step": 21900
    },
    {
      "epoch": 0.5774492265600337,
      "grad_norm": 1.5902210474014282,
      "learning_rate": 4.041172237045359e-05,
      "loss": 0.295,
      "step": 21950
    },
    {
      "epoch": 0.5787646006524255,
      "grad_norm": 1.7989850044250488,
      "learning_rate": 4.038978022749614e-05,
      "loss": 0.2988,
      "step": 22000
    },
    {
      "epoch": 0.5800799747448174,
      "grad_norm": 1.977724313735962,
      "learning_rate": 4.0367838084538686e-05,
      "loss": 0.2937,
      "step": 22050
    },
    {
      "epoch": 0.5813953488372093,
      "grad_norm": 1.7031621932983398,
      "learning_rate": 4.034589594158124e-05,
      "loss": 0.2851,
      "step": 22100
    },
    {
      "epoch": 0.5827107229296011,
      "grad_norm": 1.8063592910766602,
      "learning_rate": 4.0323953798623795e-05,
      "loss": 0.2867,
      "step": 22150
    },
    {
      "epoch": 0.584026097021993,
      "grad_norm": 1.8131951093673706,
      "learning_rate": 4.0302011655666336e-05,
      "loss": 0.2947,
      "step": 22200
    },
    {
      "epoch": 0.585341471114385,
      "grad_norm": 1.6390182971954346,
      "learning_rate": 4.028006951270889e-05,
      "loss": 0.2901,
      "step": 22250
    },
    {
      "epoch": 0.5866568452067769,
      "grad_norm": 1.741796612739563,
      "learning_rate": 4.0258127369751444e-05,
      "loss": 0.296,
      "step": 22300
    },
    {
      "epoch": 0.5879722192991687,
      "grad_norm": 1.7350696325302124,
      "learning_rate": 4.023618522679399e-05,
      "loss": 0.2897,
      "step": 22350
    },
    {
      "epoch": 0.5892875933915606,
      "grad_norm": 1.6053788661956787,
      "learning_rate": 4.021424308383654e-05,
      "loss": 0.2879,
      "step": 22400
    },
    {
      "epoch": 0.5906029674839525,
      "grad_norm": 1.7896227836608887,
      "learning_rate": 4.019230094087909e-05,
      "loss": 0.28,
      "step": 22450
    },
    {
      "epoch": 0.5919183415763443,
      "grad_norm": 1.7559270858764648,
      "learning_rate": 4.017035879792164e-05,
      "loss": 0.2887,
      "step": 22500
    },
    {
      "epoch": 0.5932337156687362,
      "grad_norm": 1.8093796968460083,
      "learning_rate": 4.0148416654964195e-05,
      "loss": 0.2844,
      "step": 22550
    },
    {
      "epoch": 0.5945490897611281,
      "grad_norm": 1.6868606805801392,
      "learning_rate": 4.012647451200674e-05,
      "loss": 0.2831,
      "step": 22600
    },
    {
      "epoch": 0.59586446385352,
      "grad_norm": 1.7589584589004517,
      "learning_rate": 4.010453236904929e-05,
      "loss": 0.2856,
      "step": 22650
    },
    {
      "epoch": 0.5971798379459118,
      "grad_norm": 1.9359031915664673,
      "learning_rate": 4.0082590226091844e-05,
      "loss": 0.2891,
      "step": 22700
    },
    {
      "epoch": 0.5984952120383037,
      "grad_norm": 2.8088033199310303,
      "learning_rate": 4.006064808313439e-05,
      "loss": 0.2846,
      "step": 22750
    },
    {
      "epoch": 0.5998105861306956,
      "grad_norm": 1.894108533859253,
      "learning_rate": 4.0038705940176946e-05,
      "loss": 0.2793,
      "step": 22800
    },
    {
      "epoch": 0.6011259602230874,
      "grad_norm": 1.751092791557312,
      "learning_rate": 4.0016763797219493e-05,
      "loss": 0.2803,
      "step": 22850
    },
    {
      "epoch": 0.6024413343154793,
      "grad_norm": 1.7192211151123047,
      "learning_rate": 3.999482165426204e-05,
      "loss": 0.2828,
      "step": 22900
    },
    {
      "epoch": 0.6037567084078712,
      "grad_norm": 1.6474076509475708,
      "learning_rate": 3.9972879511304595e-05,
      "loss": 0.2846,
      "step": 22950
    },
    {
      "epoch": 0.6050720825002631,
      "grad_norm": 1.8290730714797974,
      "learning_rate": 3.995093736834715e-05,
      "loss": 0.2821,
      "step": 23000
    },
    {
      "epoch": 0.6063874565926549,
      "grad_norm": 1.806753158569336,
      "learning_rate": 3.992899522538969e-05,
      "loss": 0.2804,
      "step": 23050
    },
    {
      "epoch": 0.6077028306850468,
      "grad_norm": 1.9262745380401611,
      "learning_rate": 3.9907053082432244e-05,
      "loss": 0.2814,
      "step": 23100
    },
    {
      "epoch": 0.6090182047774387,
      "grad_norm": 1.6363719701766968,
      "learning_rate": 3.98851109394748e-05,
      "loss": 0.2782,
      "step": 23150
    },
    {
      "epoch": 0.6103335788698305,
      "grad_norm": 1.8463135957717896,
      "learning_rate": 3.9863168796517346e-05,
      "loss": 0.2765,
      "step": 23200
    },
    {
      "epoch": 0.6116489529622224,
      "grad_norm": 2.03164005279541,
      "learning_rate": 3.9841226653559894e-05,
      "loss": 0.2776,
      "step": 23250
    },
    {
      "epoch": 0.6129643270546143,
      "grad_norm": 1.5626400709152222,
      "learning_rate": 3.981928451060245e-05,
      "loss": 0.2677,
      "step": 23300
    },
    {
      "epoch": 0.6142797011470063,
      "grad_norm": 1.947798252105713,
      "learning_rate": 3.9797342367644995e-05,
      "loss": 0.2774,
      "step": 23350
    },
    {
      "epoch": 0.615595075239398,
      "grad_norm": 1.625463604927063,
      "learning_rate": 3.977540022468755e-05,
      "loss": 0.2704,
      "step": 23400
    },
    {
      "epoch": 0.61691044933179,
      "grad_norm": 1.5681054592132568,
      "learning_rate": 3.97534580817301e-05,
      "loss": 0.2714,
      "step": 23450
    },
    {
      "epoch": 0.6182258234241819,
      "grad_norm": 1.7852388620376587,
      "learning_rate": 3.9731515938772645e-05,
      "loss": 0.2711,
      "step": 23500
    },
    {
      "epoch": 0.6195411975165737,
      "grad_norm": 1.4078881740570068,
      "learning_rate": 3.97095737958152e-05,
      "loss": 0.2746,
      "step": 23550
    },
    {
      "epoch": 0.6208565716089656,
      "grad_norm": 1.5640877485275269,
      "learning_rate": 3.9687631652857746e-05,
      "loss": 0.2671,
      "step": 23600
    },
    {
      "epoch": 0.6221719457013575,
      "grad_norm": 1.6640186309814453,
      "learning_rate": 3.9665689509900294e-05,
      "loss": 0.261,
      "step": 23650
    },
    {
      "epoch": 0.6234873197937494,
      "grad_norm": 1.7863320112228394,
      "learning_rate": 3.964374736694285e-05,
      "loss": 0.2747,
      "step": 23700
    },
    {
      "epoch": 0.6248026938861412,
      "grad_norm": 1.6037942171096802,
      "learning_rate": 3.9621805223985396e-05,
      "loss": 0.2707,
      "step": 23750
    },
    {
      "epoch": 0.6261180679785331,
      "grad_norm": 1.6479965448379517,
      "learning_rate": 3.959986308102795e-05,
      "loss": 0.2676,
      "step": 23800
    },
    {
      "epoch": 0.627433442070925,
      "grad_norm": 1.6185556650161743,
      "learning_rate": 3.95779209380705e-05,
      "loss": 0.2645,
      "step": 23850
    },
    {
      "epoch": 0.6287488161633168,
      "grad_norm": 1.3490374088287354,
      "learning_rate": 3.9555978795113045e-05,
      "loss": 0.2625,
      "step": 23900
    },
    {
      "epoch": 0.6300641902557087,
      "grad_norm": 1.657771110534668,
      "learning_rate": 3.95340366521556e-05,
      "loss": 0.2689,
      "step": 23950
    },
    {
      "epoch": 0.6313795643481006,
      "grad_norm": 1.577375888824463,
      "learning_rate": 3.9512094509198147e-05,
      "loss": 0.2634,
      "step": 24000
    },
    {
      "epoch": 0.6326949384404925,
      "grad_norm": 1.6397147178649902,
      "learning_rate": 3.9490152366240694e-05,
      "loss": 0.2716,
      "step": 24050
    },
    {
      "epoch": 0.6340103125328843,
      "grad_norm": 1.5212535858154297,
      "learning_rate": 3.946821022328325e-05,
      "loss": 0.2675,
      "step": 24100
    },
    {
      "epoch": 0.6353256866252762,
      "grad_norm": 1.534789800643921,
      "learning_rate": 3.9446268080325796e-05,
      "loss": 0.263,
      "step": 24150
    },
    {
      "epoch": 0.6366410607176681,
      "grad_norm": 1.7704685926437378,
      "learning_rate": 3.942432593736835e-05,
      "loss": 0.2612,
      "step": 24200
    },
    {
      "epoch": 0.63795643481006,
      "grad_norm": 1.828250765800476,
      "learning_rate": 3.9402383794410904e-05,
      "loss": 0.2588,
      "step": 24250
    },
    {
      "epoch": 0.6392718089024518,
      "grad_norm": 1.942631483078003,
      "learning_rate": 3.9380441651453445e-05,
      "loss": 0.272,
      "step": 24300
    },
    {
      "epoch": 0.6405871829948437,
      "grad_norm": 1.6646497249603271,
      "learning_rate": 3.9358499508496e-05,
      "loss": 0.258,
      "step": 24350
    },
    {
      "epoch": 0.6419025570872356,
      "grad_norm": 1.5387128591537476,
      "learning_rate": 3.9336557365538554e-05,
      "loss": 0.2599,
      "step": 24400
    },
    {
      "epoch": 0.6432179311796274,
      "grad_norm": 1.5947591066360474,
      "learning_rate": 3.93146152225811e-05,
      "loss": 0.2627,
      "step": 24450
    },
    {
      "epoch": 0.6445333052720194,
      "grad_norm": 1.3537331819534302,
      "learning_rate": 3.929267307962365e-05,
      "loss": 0.2587,
      "step": 24500
    },
    {
      "epoch": 0.6458486793644113,
      "grad_norm": 1.4471116065979004,
      "learning_rate": 3.92707309366662e-05,
      "loss": 0.2607,
      "step": 24550
    },
    {
      "epoch": 0.6471640534568032,
      "grad_norm": 1.609311580657959,
      "learning_rate": 3.924878879370875e-05,
      "loss": 0.255,
      "step": 24600
    },
    {
      "epoch": 0.648479427549195,
      "grad_norm": 1.471428394317627,
      "learning_rate": 3.9226846650751305e-05,
      "loss": 0.2585,
      "step": 24650
    },
    {
      "epoch": 0.6497948016415869,
      "grad_norm": 1.441395878791809,
      "learning_rate": 3.920490450779385e-05,
      "loss": 0.2604,
      "step": 24700
    },
    {
      "epoch": 0.6511101757339788,
      "grad_norm": 1.6014147996902466,
      "learning_rate": 3.91829623648364e-05,
      "loss": 0.2582,
      "step": 24750
    },
    {
      "epoch": 0.6524255498263706,
      "grad_norm": 1.6770819425582886,
      "learning_rate": 3.9161020221878954e-05,
      "loss": 0.2572,
      "step": 24800
    },
    {
      "epoch": 0.6537409239187625,
      "grad_norm": 1.5048595666885376,
      "learning_rate": 3.91390780789215e-05,
      "loss": 0.2528,
      "step": 24850
    },
    {
      "epoch": 0.6550562980111544,
      "grad_norm": 1.6338516473770142,
      "learning_rate": 3.911713593596405e-05,
      "loss": 0.2601,
      "step": 24900
    },
    {
      "epoch": 0.6563716721035463,
      "grad_norm": 1.619634985923767,
      "learning_rate": 3.90951937930066e-05,
      "loss": 0.2611,
      "step": 24950
    },
    {
      "epoch": 0.6576870461959381,
      "grad_norm": 1.6954147815704346,
      "learning_rate": 3.907325165004915e-05,
      "loss": 0.2573,
      "step": 25000
    },
    {
      "epoch": 0.65900242028833,
      "grad_norm": 1.4420475959777832,
      "learning_rate": 3.9051309507091705e-05,
      "loss": 0.2534,
      "step": 25050
    },
    {
      "epoch": 0.6603177943807219,
      "grad_norm": 1.5518141984939575,
      "learning_rate": 3.902936736413425e-05,
      "loss": 0.2535,
      "step": 25100
    },
    {
      "epoch": 0.6616331684731137,
      "grad_norm": 1.3949103355407715,
      "learning_rate": 3.90074252211768e-05,
      "loss": 0.2512,
      "step": 25150
    },
    {
      "epoch": 0.6629485425655056,
      "grad_norm": 1.4094144105911255,
      "learning_rate": 3.8985483078219354e-05,
      "loss": 0.2501,
      "step": 25200
    },
    {
      "epoch": 0.6642639166578975,
      "grad_norm": 1.528144359588623,
      "learning_rate": 3.896354093526191e-05,
      "loss": 0.2513,
      "step": 25250
    },
    {
      "epoch": 0.6655792907502894,
      "grad_norm": 1.6837157011032104,
      "learning_rate": 3.894159879230445e-05,
      "loss": 0.246,
      "step": 25300
    },
    {
      "epoch": 0.6668946648426812,
      "grad_norm": 1.6290473937988281,
      "learning_rate": 3.8919656649347e-05,
      "loss": 0.2549,
      "step": 25350
    },
    {
      "epoch": 0.6682100389350731,
      "grad_norm": 1.598894715309143,
      "learning_rate": 3.889771450638956e-05,
      "loss": 0.2596,
      "step": 25400
    },
    {
      "epoch": 0.669525413027465,
      "grad_norm": 1.4909968376159668,
      "learning_rate": 3.8875772363432105e-05,
      "loss": 0.2511,
      "step": 25450
    },
    {
      "epoch": 0.6708407871198568,
      "grad_norm": 1.7484205961227417,
      "learning_rate": 3.885383022047465e-05,
      "loss": 0.2453,
      "step": 25500
    },
    {
      "epoch": 0.6721561612122487,
      "grad_norm": 1.5330302715301514,
      "learning_rate": 3.883188807751721e-05,
      "loss": 0.2464,
      "step": 25550
    },
    {
      "epoch": 0.6734715353046407,
      "grad_norm": 1.5516866445541382,
      "learning_rate": 3.8809945934559754e-05,
      "loss": 0.2556,
      "step": 25600
    },
    {
      "epoch": 0.6747869093970326,
      "grad_norm": 1.4336796998977661,
      "learning_rate": 3.878800379160231e-05,
      "loss": 0.2524,
      "step": 25650
    },
    {
      "epoch": 0.6761022834894244,
      "grad_norm": 1.3561077117919922,
      "learning_rate": 3.876606164864485e-05,
      "loss": 0.2532,
      "step": 25700
    },
    {
      "epoch": 0.6774176575818163,
      "grad_norm": 1.5972862243652344,
      "learning_rate": 3.87441195056874e-05,
      "loss": 0.2491,
      "step": 25750
    },
    {
      "epoch": 0.6787330316742082,
      "grad_norm": 1.6115376949310303,
      "learning_rate": 3.872217736272996e-05,
      "loss": 0.2485,
      "step": 25800
    },
    {
      "epoch": 0.6800484057666,
      "grad_norm": 1.505363941192627,
      "learning_rate": 3.8700235219772505e-05,
      "loss": 0.2442,
      "step": 25850
    },
    {
      "epoch": 0.6813637798589919,
      "grad_norm": 1.4930856227874756,
      "learning_rate": 3.867829307681506e-05,
      "loss": 0.2504,
      "step": 25900
    },
    {
      "epoch": 0.6826791539513838,
      "grad_norm": 1.516725778579712,
      "learning_rate": 3.865635093385761e-05,
      "loss": 0.2433,
      "step": 25950
    },
    {
      "epoch": 0.6839945280437757,
      "grad_norm": 1.289876103401184,
      "learning_rate": 3.8634408790900154e-05,
      "loss": 0.2467,
      "step": 26000
    },
    {
      "epoch": 0.6853099021361675,
      "grad_norm": 2.2135581970214844,
      "learning_rate": 3.861246664794271e-05,
      "loss": 0.243,
      "step": 26050
    },
    {
      "epoch": 0.6866252762285594,
      "grad_norm": 1.6540606021881104,
      "learning_rate": 3.8590524504985256e-05,
      "loss": 0.2394,
      "step": 26100
    },
    {
      "epoch": 0.6879406503209513,
      "grad_norm": 1.564978003501892,
      "learning_rate": 3.8568582362027804e-05,
      "loss": 0.2449,
      "step": 26150
    },
    {
      "epoch": 0.6892560244133431,
      "grad_norm": 1.5420438051223755,
      "learning_rate": 3.854664021907036e-05,
      "loss": 0.2421,
      "step": 26200
    },
    {
      "epoch": 0.690571398505735,
      "grad_norm": 1.3560776710510254,
      "learning_rate": 3.8524698076112905e-05,
      "loss": 0.2449,
      "step": 26250
    },
    {
      "epoch": 0.6918867725981269,
      "grad_norm": 1.3327021598815918,
      "learning_rate": 3.850275593315546e-05,
      "loss": 0.2424,
      "step": 26300
    },
    {
      "epoch": 0.6932021466905188,
      "grad_norm": 1.6014200448989868,
      "learning_rate": 3.848081379019801e-05,
      "loss": 0.2367,
      "step": 26350
    },
    {
      "epoch": 0.6945175207829106,
      "grad_norm": 1.259813666343689,
      "learning_rate": 3.8458871647240554e-05,
      "loss": 0.2412,
      "step": 26400
    },
    {
      "epoch": 0.6958328948753025,
      "grad_norm": 1.4896916151046753,
      "learning_rate": 3.843692950428311e-05,
      "loss": 0.2448,
      "step": 26450
    },
    {
      "epoch": 0.6971482689676944,
      "grad_norm": 1.3749687671661377,
      "learning_rate": 3.841498736132566e-05,
      "loss": 0.2367,
      "step": 26500
    },
    {
      "epoch": 0.6984636430600862,
      "grad_norm": 1.5548001527786255,
      "learning_rate": 3.8393045218368204e-05,
      "loss": 0.2413,
      "step": 26550
    },
    {
      "epoch": 0.6997790171524781,
      "grad_norm": 1.4649909734725952,
      "learning_rate": 3.837110307541076e-05,
      "loss": 0.2344,
      "step": 26600
    },
    {
      "epoch": 0.70109439124487,
      "grad_norm": 1.2575244903564453,
      "learning_rate": 3.834916093245331e-05,
      "loss": 0.2343,
      "step": 26650
    },
    {
      "epoch": 0.702409765337262,
      "grad_norm": 1.5206961631774902,
      "learning_rate": 3.832721878949586e-05,
      "loss": 0.2425,
      "step": 26700
    },
    {
      "epoch": 0.7037251394296538,
      "grad_norm": 1.4650866985321045,
      "learning_rate": 3.830527664653841e-05,
      "loss": 0.2386,
      "step": 26750
    },
    {
      "epoch": 0.7050405135220457,
      "grad_norm": 1.512247920036316,
      "learning_rate": 3.828333450358096e-05,
      "loss": 0.2384,
      "step": 26800
    },
    {
      "epoch": 0.7063558876144376,
      "grad_norm": 1.4857094287872314,
      "learning_rate": 3.826139236062351e-05,
      "loss": 0.2345,
      "step": 26850
    },
    {
      "epoch": 0.7076712617068294,
      "grad_norm": 1.304590106010437,
      "learning_rate": 3.823945021766606e-05,
      "loss": 0.2383,
      "step": 26900
    },
    {
      "epoch": 0.7089866357992213,
      "grad_norm": 1.5496232509613037,
      "learning_rate": 3.821750807470861e-05,
      "loss": 0.2432,
      "step": 26950
    },
    {
      "epoch": 0.7103020098916132,
      "grad_norm": 1.6933072805404663,
      "learning_rate": 3.819556593175116e-05,
      "loss": 0.2366,
      "step": 27000
    },
    {
      "epoch": 0.7116173839840051,
      "grad_norm": 1.4763221740722656,
      "learning_rate": 3.817362378879371e-05,
      "loss": 0.2381,
      "step": 27050
    },
    {
      "epoch": 0.7129327580763969,
      "grad_norm": 1.402864933013916,
      "learning_rate": 3.815168164583626e-05,
      "loss": 0.2395,
      "step": 27100
    },
    {
      "epoch": 0.7142481321687888,
      "grad_norm": 1.5428673028945923,
      "learning_rate": 3.812973950287881e-05,
      "loss": 0.233,
      "step": 27150
    },
    {
      "epoch": 0.7155635062611807,
      "grad_norm": 1.5514343976974487,
      "learning_rate": 3.810779735992136e-05,
      "loss": 0.2356,
      "step": 27200
    },
    {
      "epoch": 0.7168788803535725,
      "grad_norm": 1.481351613998413,
      "learning_rate": 3.808585521696391e-05,
      "loss": 0.2329,
      "step": 27250
    },
    {
      "epoch": 0.7181942544459644,
      "grad_norm": 1.3305065631866455,
      "learning_rate": 3.8063913074006463e-05,
      "loss": 0.2326,
      "step": 27300
    },
    {
      "epoch": 0.7195096285383563,
      "grad_norm": 1.5479484796524048,
      "learning_rate": 3.804197093104901e-05,
      "loss": 0.2302,
      "step": 27350
    },
    {
      "epoch": 0.7208250026307482,
      "grad_norm": 1.275923728942871,
      "learning_rate": 3.802002878809156e-05,
      "loss": 0.2345,
      "step": 27400
    },
    {
      "epoch": 0.72214037672314,
      "grad_norm": 1.5070092678070068,
      "learning_rate": 3.799808664513411e-05,
      "loss": 0.2346,
      "step": 27450
    },
    {
      "epoch": 0.7234557508155319,
      "grad_norm": 1.2950198650360107,
      "learning_rate": 3.797614450217667e-05,
      "loss": 0.2289,
      "step": 27500
    },
    {
      "epoch": 0.7247711249079238,
      "grad_norm": 1.5114476680755615,
      "learning_rate": 3.7954202359219214e-05,
      "loss": 0.2367,
      "step": 27550
    },
    {
      "epoch": 0.7260864990003157,
      "grad_norm": 1.6777265071868896,
      "learning_rate": 3.793226021626176e-05,
      "loss": 0.229,
      "step": 27600
    },
    {
      "epoch": 0.7274018730927075,
      "grad_norm": 1.5052834749221802,
      "learning_rate": 3.7910318073304316e-05,
      "loss": 0.2334,
      "step": 27650
    },
    {
      "epoch": 0.7287172471850994,
      "grad_norm": 1.3025734424591064,
      "learning_rate": 3.7888375930346864e-05,
      "loss": 0.2287,
      "step": 27700
    },
    {
      "epoch": 0.7300326212774914,
      "grad_norm": 1.3658720254898071,
      "learning_rate": 3.786643378738942e-05,
      "loss": 0.2337,
      "step": 27750
    },
    {
      "epoch": 0.7313479953698832,
      "grad_norm": 1.6001559495925903,
      "learning_rate": 3.784449164443196e-05,
      "loss": 0.2332,
      "step": 27800
    },
    {
      "epoch": 0.7326633694622751,
      "grad_norm": 1.6664940118789673,
      "learning_rate": 3.782254950147451e-05,
      "loss": 0.2224,
      "step": 27850
    },
    {
      "epoch": 0.733978743554667,
      "grad_norm": 1.4877828359603882,
      "learning_rate": 3.780060735851707e-05,
      "loss": 0.2276,
      "step": 27900
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 1.5198370218276978,
      "learning_rate": 3.7778665215559615e-05,
      "loss": 0.2348,
      "step": 27950
    },
    {
      "epoch": 0.7366094917394507,
      "grad_norm": 1.2868990898132324,
      "learning_rate": 3.775672307260216e-05,
      "loss": 0.2304,
      "step": 28000
    },
    {
      "epoch": 0.7379248658318426,
      "grad_norm": 1.9097658395767212,
      "learning_rate": 3.7734780929644716e-05,
      "loss": 0.229,
      "step": 28050
    },
    {
      "epoch": 0.7392402399242345,
      "grad_norm": 1.5354472398757935,
      "learning_rate": 3.7712838786687264e-05,
      "loss": 0.2328,
      "step": 28100
    },
    {
      "epoch": 0.7405556140166263,
      "grad_norm": 1.5528086423873901,
      "learning_rate": 3.769089664372982e-05,
      "loss": 0.23,
      "step": 28150
    },
    {
      "epoch": 0.7418709881090182,
      "grad_norm": 1.209334373474121,
      "learning_rate": 3.7668954500772366e-05,
      "loss": 0.2219,
      "step": 28200
    },
    {
      "epoch": 0.7431863622014101,
      "grad_norm": 1.4459067583084106,
      "learning_rate": 3.764701235781491e-05,
      "loss": 0.2249,
      "step": 28250
    },
    {
      "epoch": 0.744501736293802,
      "grad_norm": 1.399046778678894,
      "learning_rate": 3.762507021485747e-05,
      "loss": 0.2244,
      "step": 28300
    },
    {
      "epoch": 0.7458171103861938,
      "grad_norm": 1.1845703125,
      "learning_rate": 3.7603128071900015e-05,
      "loss": 0.2221,
      "step": 28350
    },
    {
      "epoch": 0.7471324844785857,
      "grad_norm": 1.4761308431625366,
      "learning_rate": 3.758118592894256e-05,
      "loss": 0.2261,
      "step": 28400
    },
    {
      "epoch": 0.7484478585709776,
      "grad_norm": 1.4994251728057861,
      "learning_rate": 3.7559243785985116e-05,
      "loss": 0.2259,
      "step": 28450
    },
    {
      "epoch": 0.7497632326633694,
      "grad_norm": 1.4318406581878662,
      "learning_rate": 3.7537301643027664e-05,
      "loss": 0.2259,
      "step": 28500
    },
    {
      "epoch": 0.7510786067557613,
      "grad_norm": 1.4317981004714966,
      "learning_rate": 3.751535950007022e-05,
      "loss": 0.2245,
      "step": 28550
    },
    {
      "epoch": 0.7523939808481532,
      "grad_norm": 1.5322518348693848,
      "learning_rate": 3.7493417357112766e-05,
      "loss": 0.2237,
      "step": 28600
    },
    {
      "epoch": 0.7537093549405451,
      "grad_norm": 1.423736572265625,
      "learning_rate": 3.747147521415531e-05,
      "loss": 0.2249,
      "step": 28650
    },
    {
      "epoch": 0.7550247290329369,
      "grad_norm": 1.3104647397994995,
      "learning_rate": 3.744953307119787e-05,
      "loss": 0.2285,
      "step": 28700
    },
    {
      "epoch": 0.7563401031253288,
      "grad_norm": 1.5418859720230103,
      "learning_rate": 3.742759092824042e-05,
      "loss": 0.2251,
      "step": 28750
    },
    {
      "epoch": 0.7576554772177208,
      "grad_norm": 1.4737013578414917,
      "learning_rate": 3.740564878528296e-05,
      "loss": 0.2193,
      "step": 28800
    },
    {
      "epoch": 0.7589708513101125,
      "grad_norm": 1.3537907600402832,
      "learning_rate": 3.738370664232552e-05,
      "loss": 0.2271,
      "step": 28850
    },
    {
      "epoch": 0.7602862254025045,
      "grad_norm": 1.589633822441101,
      "learning_rate": 3.736176449936807e-05,
      "loss": 0.2255,
      "step": 28900
    },
    {
      "epoch": 0.7616015994948964,
      "grad_norm": 1.4409420490264893,
      "learning_rate": 3.733982235641062e-05,
      "loss": 0.2218,
      "step": 28950
    },
    {
      "epoch": 0.7629169735872883,
      "grad_norm": 1.5808807611465454,
      "learning_rate": 3.7317880213453166e-05,
      "loss": 0.2211,
      "step": 29000
    },
    {
      "epoch": 0.7642323476796801,
      "grad_norm": 1.4966373443603516,
      "learning_rate": 3.729593807049572e-05,
      "loss": 0.2184,
      "step": 29050
    },
    {
      "epoch": 0.765547721772072,
      "grad_norm": 1.309859275817871,
      "learning_rate": 3.727399592753827e-05,
      "loss": 0.222,
      "step": 29100
    },
    {
      "epoch": 0.7668630958644639,
      "grad_norm": 1.1867746114730835,
      "learning_rate": 3.725205378458082e-05,
      "loss": 0.2223,
      "step": 29150
    },
    {
      "epoch": 0.7681784699568557,
      "grad_norm": 1.3319302797317505,
      "learning_rate": 3.723011164162337e-05,
      "loss": 0.2206,
      "step": 29200
    },
    {
      "epoch": 0.7694938440492476,
      "grad_norm": 1.1193069219589233,
      "learning_rate": 3.720816949866592e-05,
      "loss": 0.2241,
      "step": 29250
    },
    {
      "epoch": 0.7708092181416395,
      "grad_norm": 1.4509193897247314,
      "learning_rate": 3.718622735570847e-05,
      "loss": 0.2266,
      "step": 29300
    },
    {
      "epoch": 0.7721245922340314,
      "grad_norm": 1.372885823249817,
      "learning_rate": 3.716428521275102e-05,
      "loss": 0.2112,
      "step": 29350
    },
    {
      "epoch": 0.7734399663264232,
      "grad_norm": 1.4212762117385864,
      "learning_rate": 3.714234306979357e-05,
      "loss": 0.215,
      "step": 29400
    },
    {
      "epoch": 0.7747553404188151,
      "grad_norm": 1.5498815774917603,
      "learning_rate": 3.712040092683612e-05,
      "loss": 0.2193,
      "step": 29450
    },
    {
      "epoch": 0.776070714511207,
      "grad_norm": 1.4057356119155884,
      "learning_rate": 3.709845878387867e-05,
      "loss": 0.2175,
      "step": 29500
    },
    {
      "epoch": 0.7773860886035988,
      "grad_norm": 1.2793346643447876,
      "learning_rate": 3.707651664092122e-05,
      "loss": 0.2188,
      "step": 29550
    },
    {
      "epoch": 0.7787014626959907,
      "grad_norm": 1.5365190505981445,
      "learning_rate": 3.7054574497963776e-05,
      "loss": 0.2171,
      "step": 29600
    },
    {
      "epoch": 0.7800168367883826,
      "grad_norm": 1.5036096572875977,
      "learning_rate": 3.703263235500632e-05,
      "loss": 0.2153,
      "step": 29650
    },
    {
      "epoch": 0.7813322108807745,
      "grad_norm": 1.4750510454177856,
      "learning_rate": 3.701069021204887e-05,
      "loss": 0.2156,
      "step": 29700
    },
    {
      "epoch": 0.7826475849731663,
      "grad_norm": 1.2545689344406128,
      "learning_rate": 3.6988748069091426e-05,
      "loss": 0.2134,
      "step": 29750
    },
    {
      "epoch": 0.7839629590655582,
      "grad_norm": 1.0998144149780273,
      "learning_rate": 3.696680592613397e-05,
      "loss": 0.2151,
      "step": 29800
    },
    {
      "epoch": 0.7852783331579501,
      "grad_norm": 1.3475252389907837,
      "learning_rate": 3.694486378317652e-05,
      "loss": 0.2155,
      "step": 29850
    },
    {
      "epoch": 0.786593707250342,
      "grad_norm": 1.3635571002960205,
      "learning_rate": 3.6922921640219075e-05,
      "loss": 0.2134,
      "step": 29900
    },
    {
      "epoch": 0.7879090813427339,
      "grad_norm": 1.2907626628875732,
      "learning_rate": 3.690097949726162e-05,
      "loss": 0.2135,
      "step": 29950
    },
    {
      "epoch": 0.7892244554351258,
      "grad_norm": 1.3989061117172241,
      "learning_rate": 3.6879037354304177e-05,
      "loss": 0.2151,
      "step": 30000
    },
    {
      "epoch": 0.7905398295275177,
      "grad_norm": 1.3138611316680908,
      "learning_rate": 3.685709521134672e-05,
      "loss": 0.2171,
      "step": 30050
    },
    {
      "epoch": 0.7918552036199095,
      "grad_norm": 1.4526703357696533,
      "learning_rate": 3.683515306838927e-05,
      "loss": 0.2164,
      "step": 30100
    },
    {
      "epoch": 0.7931705777123014,
      "grad_norm": 1.5081337690353394,
      "learning_rate": 3.6813210925431826e-05,
      "loss": 0.2111,
      "step": 30150
    },
    {
      "epoch": 0.7944859518046933,
      "grad_norm": 1.2218352556228638,
      "learning_rate": 3.679126878247437e-05,
      "loss": 0.2094,
      "step": 30200
    },
    {
      "epoch": 0.7958013258970851,
      "grad_norm": 1.4066965579986572,
      "learning_rate": 3.676932663951692e-05,
      "loss": 0.2087,
      "step": 30250
    },
    {
      "epoch": 0.797116699989477,
      "grad_norm": 1.4382795095443726,
      "learning_rate": 3.6747384496559475e-05,
      "loss": 0.2124,
      "step": 30300
    },
    {
      "epoch": 0.7984320740818689,
      "grad_norm": 1.2626020908355713,
      "learning_rate": 3.672544235360202e-05,
      "loss": 0.2126,
      "step": 30350
    },
    {
      "epoch": 0.7997474481742608,
      "grad_norm": 1.2194044589996338,
      "learning_rate": 3.670350021064458e-05,
      "loss": 0.2143,
      "step": 30400
    },
    {
      "epoch": 0.8010628222666526,
      "grad_norm": 1.5255317687988281,
      "learning_rate": 3.6681558067687124e-05,
      "loss": 0.2102,
      "step": 30450
    },
    {
      "epoch": 0.8023781963590445,
      "grad_norm": 1.340876817703247,
      "learning_rate": 3.665961592472967e-05,
      "loss": 0.2089,
      "step": 30500
    },
    {
      "epoch": 0.8036935704514364,
      "grad_norm": 1.4102455377578735,
      "learning_rate": 3.6637673781772226e-05,
      "loss": 0.2092,
      "step": 30550
    },
    {
      "epoch": 0.8050089445438283,
      "grad_norm": 1.4836194515228271,
      "learning_rate": 3.6615731638814773e-05,
      "loss": 0.2088,
      "step": 30600
    },
    {
      "epoch": 0.8063243186362201,
      "grad_norm": 1.3274449110031128,
      "learning_rate": 3.659378949585732e-05,
      "loss": 0.2103,
      "step": 30650
    },
    {
      "epoch": 0.807639692728612,
      "grad_norm": 1.4111276865005493,
      "learning_rate": 3.6571847352899875e-05,
      "loss": 0.2138,
      "step": 30700
    },
    {
      "epoch": 0.8089550668210039,
      "grad_norm": 1.6452361345291138,
      "learning_rate": 3.654990520994242e-05,
      "loss": 0.2105,
      "step": 30750
    },
    {
      "epoch": 0.8102704409133957,
      "grad_norm": 1.4636495113372803,
      "learning_rate": 3.652796306698498e-05,
      "loss": 0.2099,
      "step": 30800
    },
    {
      "epoch": 0.8115858150057876,
      "grad_norm": 1.2849977016448975,
      "learning_rate": 3.650602092402753e-05,
      "loss": 0.205,
      "step": 30850
    },
    {
      "epoch": 0.8129011890981795,
      "grad_norm": 1.3005255460739136,
      "learning_rate": 3.648407878107007e-05,
      "loss": 0.2103,
      "step": 30900
    },
    {
      "epoch": 0.8142165631905715,
      "grad_norm": 1.5462877750396729,
      "learning_rate": 3.6462136638112626e-05,
      "loss": 0.2085,
      "step": 30950
    },
    {
      "epoch": 0.8155319372829632,
      "grad_norm": 1.3298474550247192,
      "learning_rate": 3.644019449515518e-05,
      "loss": 0.2087,
      "step": 31000
    },
    {
      "epoch": 0.8168473113753552,
      "grad_norm": 1.445278286933899,
      "learning_rate": 3.641825235219773e-05,
      "loss": 0.2061,
      "step": 31050
    },
    {
      "epoch": 0.8181626854677471,
      "grad_norm": 1.414857029914856,
      "learning_rate": 3.6396310209240275e-05,
      "loss": 0.2155,
      "step": 31100
    },
    {
      "epoch": 0.8194780595601389,
      "grad_norm": 1.205337643623352,
      "learning_rate": 3.637436806628283e-05,
      "loss": 0.207,
      "step": 31150
    },
    {
      "epoch": 0.8207934336525308,
      "grad_norm": 1.4612895250320435,
      "learning_rate": 3.635242592332538e-05,
      "loss": 0.212,
      "step": 31200
    },
    {
      "epoch": 0.8221088077449227,
      "grad_norm": 1.298245906829834,
      "learning_rate": 3.633048378036793e-05,
      "loss": 0.2103,
      "step": 31250
    },
    {
      "epoch": 0.8234241818373146,
      "grad_norm": 1.5288702249526978,
      "learning_rate": 3.630854163741048e-05,
      "loss": 0.2103,
      "step": 31300
    },
    {
      "epoch": 0.8247395559297064,
      "grad_norm": 1.259883165359497,
      "learning_rate": 3.6286599494453026e-05,
      "loss": 0.2053,
      "step": 31350
    },
    {
      "epoch": 0.8260549300220983,
      "grad_norm": 1.4051945209503174,
      "learning_rate": 3.626465735149558e-05,
      "loss": 0.2068,
      "step": 31400
    },
    {
      "epoch": 0.8273703041144902,
      "grad_norm": 1.3686202764511108,
      "learning_rate": 3.624271520853813e-05,
      "loss": 0.2065,
      "step": 31450
    },
    {
      "epoch": 0.828685678206882,
      "grad_norm": 1.242853045463562,
      "learning_rate": 3.6220773065580676e-05,
      "loss": 0.2051,
      "step": 31500
    },
    {
      "epoch": 0.8300010522992739,
      "grad_norm": 1.322052240371704,
      "learning_rate": 3.619883092262323e-05,
      "loss": 0.2067,
      "step": 31550
    },
    {
      "epoch": 0.8313164263916658,
      "grad_norm": 1.3101176023483276,
      "learning_rate": 3.617688877966578e-05,
      "loss": 0.2042,
      "step": 31600
    },
    {
      "epoch": 0.8326318004840577,
      "grad_norm": 1.33831787109375,
      "learning_rate": 3.615494663670833e-05,
      "loss": 0.2096,
      "step": 31650
    },
    {
      "epoch": 0.8339471745764495,
      "grad_norm": 1.0935665369033813,
      "learning_rate": 3.613300449375088e-05,
      "loss": 0.2015,
      "step": 31700
    },
    {
      "epoch": 0.8352625486688414,
      "grad_norm": 1.2025262117385864,
      "learning_rate": 3.6111062350793427e-05,
      "loss": 0.1976,
      "step": 31750
    },
    {
      "epoch": 0.8365779227612333,
      "grad_norm": 1.3160079717636108,
      "learning_rate": 3.608912020783598e-05,
      "loss": 0.2076,
      "step": 31800
    },
    {
      "epoch": 0.8378932968536251,
      "grad_norm": 1.4128391742706299,
      "learning_rate": 3.6067178064878535e-05,
      "loss": 0.2055,
      "step": 31850
    },
    {
      "epoch": 0.839208670946017,
      "grad_norm": 1.1828373670578003,
      "learning_rate": 3.6045235921921076e-05,
      "loss": 0.206,
      "step": 31900
    },
    {
      "epoch": 0.8405240450384089,
      "grad_norm": 1.3821349143981934,
      "learning_rate": 3.602329377896363e-05,
      "loss": 0.2098,
      "step": 31950
    },
    {
      "epoch": 0.8418394191308008,
      "grad_norm": 1.2148597240447998,
      "learning_rate": 3.6001351636006184e-05,
      "loss": 0.2113,
      "step": 32000
    },
    {
      "epoch": 0.8431547932231926,
      "grad_norm": 1.1587308645248413,
      "learning_rate": 3.597940949304873e-05,
      "loss": 0.2031,
      "step": 32050
    },
    {
      "epoch": 0.8444701673155846,
      "grad_norm": 1.1996526718139648,
      "learning_rate": 3.595746735009128e-05,
      "loss": 0.2062,
      "step": 32100
    },
    {
      "epoch": 0.8457855414079765,
      "grad_norm": 1.4276763200759888,
      "learning_rate": 3.593552520713383e-05,
      "loss": 0.2019,
      "step": 32150
    },
    {
      "epoch": 0.8471009155003683,
      "grad_norm": 1.317507028579712,
      "learning_rate": 3.591358306417638e-05,
      "loss": 0.2037,
      "step": 32200
    },
    {
      "epoch": 0.8484162895927602,
      "grad_norm": 1.2798491716384888,
      "learning_rate": 3.5891640921218935e-05,
      "loss": 0.2045,
      "step": 32250
    },
    {
      "epoch": 0.8497316636851521,
      "grad_norm": 1.3740891218185425,
      "learning_rate": 3.586969877826148e-05,
      "loss": 0.2065,
      "step": 32300
    },
    {
      "epoch": 0.851047037777544,
      "grad_norm": 1.2482198476791382,
      "learning_rate": 3.584775663530403e-05,
      "loss": 0.2031,
      "step": 32350
    },
    {
      "epoch": 0.8523624118699358,
      "grad_norm": 1.3078798055648804,
      "learning_rate": 3.5825814492346584e-05,
      "loss": 0.2051,
      "step": 32400
    },
    {
      "epoch": 0.8536777859623277,
      "grad_norm": 1.3674304485321045,
      "learning_rate": 3.580387234938913e-05,
      "loss": 0.197,
      "step": 32450
    },
    {
      "epoch": 0.8549931600547196,
      "grad_norm": 1.21657133102417,
      "learning_rate": 3.5781930206431686e-05,
      "loss": 0.2013,
      "step": 32500
    },
    {
      "epoch": 0.8563085341471114,
      "grad_norm": 1.2016575336456299,
      "learning_rate": 3.5759988063474234e-05,
      "loss": 0.2073,
      "step": 32550
    },
    {
      "epoch": 0.8576239082395033,
      "grad_norm": 1.3549972772598267,
      "learning_rate": 3.573804592051678e-05,
      "loss": 0.2024,
      "step": 32600
    },
    {
      "epoch": 0.8589392823318952,
      "grad_norm": 1.557024359703064,
      "learning_rate": 3.5716103777559335e-05,
      "loss": 0.2033,
      "step": 32650
    },
    {
      "epoch": 0.8602546564242871,
      "grad_norm": 1.239909291267395,
      "learning_rate": 3.569416163460188e-05,
      "loss": 0.1998,
      "step": 32700
    },
    {
      "epoch": 0.8615700305166789,
      "grad_norm": 1.2465022802352905,
      "learning_rate": 3.567221949164443e-05,
      "loss": 0.2028,
      "step": 32750
    },
    {
      "epoch": 0.8628854046090708,
      "grad_norm": 1.3709639310836792,
      "learning_rate": 3.5650277348686985e-05,
      "loss": 0.2065,
      "step": 32800
    },
    {
      "epoch": 0.8642007787014627,
      "grad_norm": 1.2136300802230835,
      "learning_rate": 3.562833520572953e-05,
      "loss": 0.1979,
      "step": 32850
    },
    {
      "epoch": 0.8655161527938545,
      "grad_norm": 1.2808932065963745,
      "learning_rate": 3.5606393062772086e-05,
      "loss": 0.2038,
      "step": 32900
    },
    {
      "epoch": 0.8668315268862464,
      "grad_norm": 1.2611876726150513,
      "learning_rate": 3.5584450919814634e-05,
      "loss": 0.1982,
      "step": 32950
    },
    {
      "epoch": 0.8681469009786383,
      "grad_norm": 1.3160368204116821,
      "learning_rate": 3.556250877685718e-05,
      "loss": 0.2004,
      "step": 33000
    },
    {
      "epoch": 0.8694622750710302,
      "grad_norm": 1.3118915557861328,
      "learning_rate": 3.5540566633899736e-05,
      "loss": 0.1984,
      "step": 33050
    },
    {
      "epoch": 0.870777649163422,
      "grad_norm": 1.347971796989441,
      "learning_rate": 3.551862449094229e-05,
      "loss": 0.2031,
      "step": 33100
    },
    {
      "epoch": 0.872093023255814,
      "grad_norm": 1.2347850799560547,
      "learning_rate": 3.549668234798483e-05,
      "loss": 0.1935,
      "step": 33150
    },
    {
      "epoch": 0.8734083973482059,
      "grad_norm": 1.2981187105178833,
      "learning_rate": 3.5474740205027385e-05,
      "loss": 0.2007,
      "step": 33200
    },
    {
      "epoch": 0.8747237714405977,
      "grad_norm": 1.3842333555221558,
      "learning_rate": 3.545279806206994e-05,
      "loss": 0.2021,
      "step": 33250
    },
    {
      "epoch": 0.8760391455329896,
      "grad_norm": 1.047545313835144,
      "learning_rate": 3.5430855919112487e-05,
      "loss": 0.1983,
      "step": 33300
    },
    {
      "epoch": 0.8773545196253815,
      "grad_norm": 1.223337173461914,
      "learning_rate": 3.5408913776155034e-05,
      "loss": 0.1996,
      "step": 33350
    },
    {
      "epoch": 0.8786698937177734,
      "grad_norm": 1.3049265146255493,
      "learning_rate": 3.538697163319759e-05,
      "loss": 0.1997,
      "step": 33400
    },
    {
      "epoch": 0.8799852678101652,
      "grad_norm": 1.3683602809906006,
      "learning_rate": 3.5365029490240136e-05,
      "loss": 0.1994,
      "step": 33450
    },
    {
      "epoch": 0.8813006419025571,
      "grad_norm": 1.3818162679672241,
      "learning_rate": 3.534308734728269e-05,
      "loss": 0.2014,
      "step": 33500
    },
    {
      "epoch": 0.882616015994949,
      "grad_norm": 1.372527837753296,
      "learning_rate": 3.532114520432524e-05,
      "loss": 0.2052,
      "step": 33550
    },
    {
      "epoch": 0.8839313900873408,
      "grad_norm": 1.563276767730713,
      "learning_rate": 3.5299203061367785e-05,
      "loss": 0.1942,
      "step": 33600
    },
    {
      "epoch": 0.8852467641797327,
      "grad_norm": 1.0585793256759644,
      "learning_rate": 3.527726091841034e-05,
      "loss": 0.1931,
      "step": 33650
    },
    {
      "epoch": 0.8865621382721246,
      "grad_norm": 1.1828054189682007,
      "learning_rate": 3.525531877545289e-05,
      "loss": 0.1942,
      "step": 33700
    },
    {
      "epoch": 0.8878775123645165,
      "grad_norm": 1.0284289121627808,
      "learning_rate": 3.5233376632495434e-05,
      "loss": 0.1934,
      "step": 33750
    },
    {
      "epoch": 0.8891928864569083,
      "grad_norm": 1.4205950498580933,
      "learning_rate": 3.521143448953799e-05,
      "loss": 0.1935,
      "step": 33800
    },
    {
      "epoch": 0.8905082605493002,
      "grad_norm": 1.1342103481292725,
      "learning_rate": 3.5189492346580536e-05,
      "loss": 0.1937,
      "step": 33850
    },
    {
      "epoch": 0.8918236346416921,
      "grad_norm": 1.0391541719436646,
      "learning_rate": 3.516755020362309e-05,
      "loss": 0.1941,
      "step": 33900
    },
    {
      "epoch": 0.893139008734084,
      "grad_norm": 1.195397138595581,
      "learning_rate": 3.5145608060665644e-05,
      "loss": 0.1923,
      "step": 33950
    },
    {
      "epoch": 0.8944543828264758,
      "grad_norm": 1.1887108087539673,
      "learning_rate": 3.5123665917708185e-05,
      "loss": 0.1974,
      "step": 34000
    },
    {
      "epoch": 0.8957697569188677,
      "grad_norm": 1.2915072441101074,
      "learning_rate": 3.510172377475074e-05,
      "loss": 0.1956,
      "step": 34050
    },
    {
      "epoch": 0.8970851310112596,
      "grad_norm": 1.249222993850708,
      "learning_rate": 3.5079781631793294e-05,
      "loss": 0.1965,
      "step": 34100
    },
    {
      "epoch": 0.8984005051036514,
      "grad_norm": 0.9826666712760925,
      "learning_rate": 3.505783948883584e-05,
      "loss": 0.1923,
      "step": 34150
    },
    {
      "epoch": 0.8997158791960433,
      "grad_norm": 1.3113675117492676,
      "learning_rate": 3.503589734587839e-05,
      "loss": 0.1913,
      "step": 34200
    },
    {
      "epoch": 0.9010312532884353,
      "grad_norm": 1.0489717721939087,
      "learning_rate": 3.5013955202920936e-05,
      "loss": 0.1932,
      "step": 34250
    },
    {
      "epoch": 0.9023466273808272,
      "grad_norm": 1.1398568153381348,
      "learning_rate": 3.499201305996349e-05,
      "loss": 0.1928,
      "step": 34300
    },
    {
      "epoch": 0.903662001473219,
      "grad_norm": 1.3217543363571167,
      "learning_rate": 3.4970070917006045e-05,
      "loss": 0.1934,
      "step": 34350
    },
    {
      "epoch": 0.9049773755656109,
      "grad_norm": 1.261696696281433,
      "learning_rate": 3.4948128774048585e-05,
      "loss": 0.1911,
      "step": 34400
    },
    {
      "epoch": 0.9062927496580028,
      "grad_norm": 1.248612403869629,
      "learning_rate": 3.492618663109114e-05,
      "loss": 0.1928,
      "step": 34450
    },
    {
      "epoch": 0.9076081237503946,
      "grad_norm": 1.1871839761734009,
      "learning_rate": 3.4904244488133694e-05,
      "loss": 0.1917,
      "step": 34500
    },
    {
      "epoch": 0.9089234978427865,
      "grad_norm": 1.3049687147140503,
      "learning_rate": 3.488230234517624e-05,
      "loss": 0.1934,
      "step": 34550
    },
    {
      "epoch": 0.9102388719351784,
      "grad_norm": 1.2583932876586914,
      "learning_rate": 3.486036020221879e-05,
      "loss": 0.1935,
      "step": 34600
    },
    {
      "epoch": 0.9115542460275703,
      "grad_norm": 1.0998022556304932,
      "learning_rate": 3.483841805926134e-05,
      "loss": 0.1926,
      "step": 34650
    },
    {
      "epoch": 0.9128696201199621,
      "grad_norm": 1.1814453601837158,
      "learning_rate": 3.481647591630389e-05,
      "loss": 0.1903,
      "step": 34700
    },
    {
      "epoch": 0.914184994212354,
      "grad_norm": 1.2882890701293945,
      "learning_rate": 3.4794533773346445e-05,
      "loss": 0.1935,
      "step": 34750
    },
    {
      "epoch": 0.9155003683047459,
      "grad_norm": 1.0318336486816406,
      "learning_rate": 3.477259163038899e-05,
      "loss": 0.1956,
      "step": 34800
    },
    {
      "epoch": 0.9168157423971377,
      "grad_norm": 1.1288602352142334,
      "learning_rate": 3.475064948743154e-05,
      "loss": 0.1928,
      "step": 34850
    },
    {
      "epoch": 0.9181311164895296,
      "grad_norm": 1.3140262365341187,
      "learning_rate": 3.4728707344474094e-05,
      "loss": 0.1893,
      "step": 34900
    },
    {
      "epoch": 0.9194464905819215,
      "grad_norm": 1.262315273284912,
      "learning_rate": 3.470676520151664e-05,
      "loss": 0.1943,
      "step": 34950
    },
    {
      "epoch": 0.9207618646743134,
      "grad_norm": 1.3068312406539917,
      "learning_rate": 3.468482305855919e-05,
      "loss": 0.1919,
      "step": 35000
    },
    {
      "epoch": 0.9220772387667052,
      "grad_norm": 1.2146130800247192,
      "learning_rate": 3.466288091560174e-05,
      "loss": 0.1889,
      "step": 35050
    },
    {
      "epoch": 0.9233926128590971,
      "grad_norm": 1.3800610303878784,
      "learning_rate": 3.464093877264429e-05,
      "loss": 0.1909,
      "step": 35100
    },
    {
      "epoch": 0.924707986951489,
      "grad_norm": 1.3551758527755737,
      "learning_rate": 3.4618996629686845e-05,
      "loss": 0.1902,
      "step": 35150
    },
    {
      "epoch": 0.9260233610438808,
      "grad_norm": 1.7657475471496582,
      "learning_rate": 3.459705448672939e-05,
      "loss": 0.1903,
      "step": 35200
    },
    {
      "epoch": 0.9273387351362727,
      "grad_norm": 1.0584728717803955,
      "learning_rate": 3.457511234377194e-05,
      "loss": 0.1908,
      "step": 35250
    },
    {
      "epoch": 0.9286541092286646,
      "grad_norm": 1.3232899904251099,
      "learning_rate": 3.4553170200814494e-05,
      "loss": 0.1931,
      "step": 35300
    },
    {
      "epoch": 0.9299694833210566,
      "grad_norm": 1.0142565965652466,
      "learning_rate": 3.453122805785705e-05,
      "loss": 0.1854,
      "step": 35350
    },
    {
      "epoch": 0.9312848574134484,
      "grad_norm": 1.2711678743362427,
      "learning_rate": 3.450928591489959e-05,
      "loss": 0.1819,
      "step": 35400
    },
    {
      "epoch": 0.9326002315058403,
      "grad_norm": 1.08943772315979,
      "learning_rate": 3.4487343771942144e-05,
      "loss": 0.1911,
      "step": 35450
    },
    {
      "epoch": 0.9339156055982322,
      "grad_norm": 1.5161677598953247,
      "learning_rate": 3.44654016289847e-05,
      "loss": 0.192,
      "step": 35500
    },
    {
      "epoch": 0.935230979690624,
      "grad_norm": 1.3469947576522827,
      "learning_rate": 3.4443459486027245e-05,
      "loss": 0.1897,
      "step": 35550
    },
    {
      "epoch": 0.9365463537830159,
      "grad_norm": 1.162487268447876,
      "learning_rate": 3.44215173430698e-05,
      "loss": 0.1896,
      "step": 35600
    },
    {
      "epoch": 0.9378617278754078,
      "grad_norm": 1.3664369583129883,
      "learning_rate": 3.439957520011235e-05,
      "loss": 0.1889,
      "step": 35650
    },
    {
      "epoch": 0.9391771019677997,
      "grad_norm": 1.3918752670288086,
      "learning_rate": 3.4377633057154894e-05,
      "loss": 0.1881,
      "step": 35700
    },
    {
      "epoch": 0.9404924760601915,
      "grad_norm": 1.1998114585876465,
      "learning_rate": 3.435569091419745e-05,
      "loss": 0.1855,
      "step": 35750
    },
    {
      "epoch": 0.9418078501525834,
      "grad_norm": 1.252682089805603,
      "learning_rate": 3.4333748771239996e-05,
      "loss": 0.1892,
      "step": 35800
    },
    {
      "epoch": 0.9431232242449753,
      "grad_norm": 0.971422016620636,
      "learning_rate": 3.4311806628282544e-05,
      "loss": 0.1883,
      "step": 35850
    },
    {
      "epoch": 0.9444385983373671,
      "grad_norm": 1.2468091249465942,
      "learning_rate": 3.42898644853251e-05,
      "loss": 0.1873,
      "step": 35900
    },
    {
      "epoch": 0.945753972429759,
      "grad_norm": 1.2218097448349,
      "learning_rate": 3.4267922342367645e-05,
      "loss": 0.1873,
      "step": 35950
    },
    {
      "epoch": 0.9470693465221509,
      "grad_norm": 1.0063563585281372,
      "learning_rate": 3.42459801994102e-05,
      "loss": 0.1783,
      "step": 36000
    },
    {
      "epoch": 0.9483847206145428,
      "grad_norm": 1.2725980281829834,
      "learning_rate": 3.422403805645275e-05,
      "loss": 0.1875,
      "step": 36050
    },
    {
      "epoch": 0.9497000947069346,
      "grad_norm": 1.2903658151626587,
      "learning_rate": 3.4202095913495295e-05,
      "loss": 0.19,
      "step": 36100
    },
    {
      "epoch": 0.9510154687993265,
      "grad_norm": 1.109824776649475,
      "learning_rate": 3.418015377053785e-05,
      "loss": 0.193,
      "step": 36150
    },
    {
      "epoch": 0.9523308428917184,
      "grad_norm": 1.200801968574524,
      "learning_rate": 3.41582116275804e-05,
      "loss": 0.1893,
      "step": 36200
    },
    {
      "epoch": 0.9536462169841102,
      "grad_norm": 1.2068402767181396,
      "learning_rate": 3.4136269484622944e-05,
      "loss": 0.1883,
      "step": 36250
    },
    {
      "epoch": 0.9549615910765021,
      "grad_norm": 1.3524584770202637,
      "learning_rate": 3.41143273416655e-05,
      "loss": 0.1805,
      "step": 36300
    },
    {
      "epoch": 0.956276965168894,
      "grad_norm": 1.0126203298568726,
      "learning_rate": 3.4092385198708046e-05,
      "loss": 0.1817,
      "step": 36350
    },
    {
      "epoch": 0.957592339261286,
      "grad_norm": 1.2051589488983154,
      "learning_rate": 3.40704430557506e-05,
      "loss": 0.1846,
      "step": 36400
    },
    {
      "epoch": 0.9589077133536777,
      "grad_norm": 1.188600778579712,
      "learning_rate": 3.404850091279315e-05,
      "loss": 0.1841,
      "step": 36450
    },
    {
      "epoch": 0.9602230874460697,
      "grad_norm": 1.2156893014907837,
      "learning_rate": 3.4026558769835695e-05,
      "loss": 0.184,
      "step": 36500
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 1.171922206878662,
      "learning_rate": 3.400461662687825e-05,
      "loss": 0.1843,
      "step": 36550
    },
    {
      "epoch": 0.9628538356308534,
      "grad_norm": 1.25690758228302,
      "learning_rate": 3.39826744839208e-05,
      "loss": 0.1873,
      "step": 36600
    },
    {
      "epoch": 0.9641692097232453,
      "grad_norm": 1.158801555633545,
      "learning_rate": 3.3960732340963344e-05,
      "loss": 0.1823,
      "step": 36650
    },
    {
      "epoch": 0.9654845838156372,
      "grad_norm": 1.0365734100341797,
      "learning_rate": 3.39387901980059e-05,
      "loss": 0.1858,
      "step": 36700
    },
    {
      "epoch": 0.9667999579080291,
      "grad_norm": 1.1824887990951538,
      "learning_rate": 3.391684805504845e-05,
      "loss": 0.1796,
      "step": 36750
    },
    {
      "epoch": 0.9681153320004209,
      "grad_norm": 1.1878081560134888,
      "learning_rate": 3.3894905912091e-05,
      "loss": 0.1809,
      "step": 36800
    },
    {
      "epoch": 0.9694307060928128,
      "grad_norm": 1.0375075340270996,
      "learning_rate": 3.387296376913355e-05,
      "loss": 0.1907,
      "step": 36850
    },
    {
      "epoch": 0.9707460801852047,
      "grad_norm": 1.112040638923645,
      "learning_rate": 3.38510216261761e-05,
      "loss": 0.1825,
      "step": 36900
    },
    {
      "epoch": 0.9720614542775966,
      "grad_norm": 1.159608244895935,
      "learning_rate": 3.382907948321865e-05,
      "loss": 0.183,
      "step": 36950
    },
    {
      "epoch": 0.9733768283699884,
      "grad_norm": 1.2944369316101074,
      "learning_rate": 3.3807137340261204e-05,
      "loss": 0.1818,
      "step": 37000
    },
    {
      "epoch": 0.9746922024623803,
      "grad_norm": 1.2007259130477905,
      "learning_rate": 3.378519519730375e-05,
      "loss": 0.1806,
      "step": 37050
    },
    {
      "epoch": 0.9760075765547722,
      "grad_norm": 0.9759324789047241,
      "learning_rate": 3.37632530543463e-05,
      "loss": 0.1824,
      "step": 37100
    },
    {
      "epoch": 0.977322950647164,
      "grad_norm": 1.0390849113464355,
      "learning_rate": 3.374131091138885e-05,
      "loss": 0.1839,
      "step": 37150
    },
    {
      "epoch": 0.9786383247395559,
      "grad_norm": 1.0453037023544312,
      "learning_rate": 3.37193687684314e-05,
      "loss": 0.1828,
      "step": 37200
    },
    {
      "epoch": 0.9799536988319478,
      "grad_norm": 1.1156375408172607,
      "learning_rate": 3.3697426625473955e-05,
      "loss": 0.1845,
      "step": 37250
    },
    {
      "epoch": 0.9812690729243397,
      "grad_norm": 1.3912349939346313,
      "learning_rate": 3.36754844825165e-05,
      "loss": 0.1864,
      "step": 37300
    },
    {
      "epoch": 0.9825844470167315,
      "grad_norm": 1.2116177082061768,
      "learning_rate": 3.365354233955905e-05,
      "loss": 0.1809,
      "step": 37350
    },
    {
      "epoch": 0.9838998211091234,
      "grad_norm": 0.9651437997817993,
      "learning_rate": 3.3631600196601604e-05,
      "loss": 0.1826,
      "step": 37400
    },
    {
      "epoch": 0.9852151952015153,
      "grad_norm": 1.1004703044891357,
      "learning_rate": 3.360965805364416e-05,
      "loss": 0.1861,
      "step": 37450
    },
    {
      "epoch": 0.9865305692939071,
      "grad_norm": 1.1253503561019897,
      "learning_rate": 3.35877159106867e-05,
      "loss": 0.1794,
      "step": 37500
    },
    {
      "epoch": 0.987845943386299,
      "grad_norm": 1.036530613899231,
      "learning_rate": 3.356577376772925e-05,
      "loss": 0.1831,
      "step": 37550
    },
    {
      "epoch": 0.989161317478691,
      "grad_norm": 1.0404479503631592,
      "learning_rate": 3.354383162477181e-05,
      "loss": 0.1833,
      "step": 37600
    },
    {
      "epoch": 0.9904766915710829,
      "grad_norm": 0.8470432758331299,
      "learning_rate": 3.3521889481814355e-05,
      "loss": 0.1813,
      "step": 37650
    },
    {
      "epoch": 0.9917920656634747,
      "grad_norm": 1.0628939867019653,
      "learning_rate": 3.34999473388569e-05,
      "loss": 0.1781,
      "step": 37700
    },
    {
      "epoch": 0.9931074397558666,
      "grad_norm": 1.092995524406433,
      "learning_rate": 3.3478005195899456e-05,
      "loss": 0.1839,
      "step": 37750
    },
    {
      "epoch": 0.9944228138482585,
      "grad_norm": 1.1659321784973145,
      "learning_rate": 3.3456063052942004e-05,
      "loss": 0.1764,
      "step": 37800
    },
    {
      "epoch": 0.9957381879406503,
      "grad_norm": 1.166887879371643,
      "learning_rate": 3.343412090998456e-05,
      "loss": 0.1792,
      "step": 37850
    },
    {
      "epoch": 0.9970535620330422,
      "grad_norm": 1.1123865842819214,
      "learning_rate": 3.3412178767027106e-05,
      "loss": 0.1792,
      "step": 37900
    },
    {
      "epoch": 0.9983689361254341,
      "grad_norm": 1.1532608270645142,
      "learning_rate": 3.339023662406965e-05,
      "loss": 0.1825,
      "step": 37950
    },
    {
      "epoch": 0.999684310217826,
      "grad_norm": 1.1581355333328247,
      "learning_rate": 3.336829448111221e-05,
      "loss": 0.1844,
      "step": 38000
    },
    {
      "epoch": 1.0,
      "eval_loss": 7.296446323394775,
      "eval_runtime": 224.39,
      "eval_samples_per_second": 150.074,
      "eval_steps_per_second": 18.762,
      "step": 38012
    }
  ],
  "logging_steps": 50,
  "max_steps": 114036,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9864334794752e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
