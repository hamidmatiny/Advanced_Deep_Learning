{
  "best_global_step": 38012,
  "best_metric": 7.296446323394775,
  "best_model_checkpoint": "./gpt2-shakespeare-results/checkpoint-38012",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 114036,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0013153740923918763,
      "grad_norm": 7.928862571716309,
      "learning_rate": 2.45e-05,
      "loss": 4.3667,
      "step": 50
    },
    {
      "epoch": 0.0026307481847837526,
      "grad_norm": 8.35387134552002,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 3.8824,
      "step": 100
    },
    {
      "epoch": 0.003946122277175629,
      "grad_norm": 7.884564399719238,
      "learning_rate": 4.99784966999017e-05,
      "loss": 3.7378,
      "step": 150
    },
    {
      "epoch": 0.005261496369567505,
      "grad_norm": 7.377553939819336,
      "learning_rate": 4.995655455694425e-05,
      "loss": 3.5954,
      "step": 200
    },
    {
      "epoch": 0.006576870461959382,
      "grad_norm": 6.887958526611328,
      "learning_rate": 4.9934612413986805e-05,
      "loss": 3.5354,
      "step": 250
    },
    {
      "epoch": 0.007892244554351257,
      "grad_norm": 6.980103969573975,
      "learning_rate": 4.991267027102935e-05,
      "loss": 3.5043,
      "step": 300
    },
    {
      "epoch": 0.009207618646743134,
      "grad_norm": 6.705517768859863,
      "learning_rate": 4.98907281280719e-05,
      "loss": 3.4942,
      "step": 350
    },
    {
      "epoch": 0.01052299273913501,
      "grad_norm": 5.854396820068359,
      "learning_rate": 4.9868785985114454e-05,
      "loss": 3.4188,
      "step": 400
    },
    {
      "epoch": 0.011838366831526887,
      "grad_norm": 6.6587395668029785,
      "learning_rate": 4.9846843842157e-05,
      "loss": 3.4018,
      "step": 450
    },
    {
      "epoch": 0.013153740923918763,
      "grad_norm": 5.207996368408203,
      "learning_rate": 4.9824901699199556e-05,
      "loss": 3.3904,
      "step": 500
    },
    {
      "epoch": 0.014469115016310638,
      "grad_norm": 5.716810703277588,
      "learning_rate": 4.98029595562421e-05,
      "loss": 3.3451,
      "step": 550
    },
    {
      "epoch": 0.015784489108702515,
      "grad_norm": 6.076563835144043,
      "learning_rate": 4.978101741328465e-05,
      "loss": 3.3517,
      "step": 600
    },
    {
      "epoch": 0.01709986320109439,
      "grad_norm": 5.174357891082764,
      "learning_rate": 4.9759075270327205e-05,
      "loss": 3.3234,
      "step": 650
    },
    {
      "epoch": 0.018415237293486268,
      "grad_norm": 5.308799743652344,
      "learning_rate": 4.973713312736976e-05,
      "loss": 3.2533,
      "step": 700
    },
    {
      "epoch": 0.019730611385878144,
      "grad_norm": 5.732443332672119,
      "learning_rate": 4.97151909844123e-05,
      "loss": 3.2649,
      "step": 750
    },
    {
      "epoch": 0.02104598547827002,
      "grad_norm": 4.812621116638184,
      "learning_rate": 4.9693248841454854e-05,
      "loss": 3.2652,
      "step": 800
    },
    {
      "epoch": 0.022361359570661897,
      "grad_norm": 4.481085300445557,
      "learning_rate": 4.96713066984974e-05,
      "loss": 3.181,
      "step": 850
    },
    {
      "epoch": 0.023676733663053773,
      "grad_norm": 4.627078056335449,
      "learning_rate": 4.9649364555539956e-05,
      "loss": 3.1709,
      "step": 900
    },
    {
      "epoch": 0.02499210775544565,
      "grad_norm": 4.521010398864746,
      "learning_rate": 4.9627422412582504e-05,
      "loss": 3.1655,
      "step": 950
    },
    {
      "epoch": 0.026307481847837526,
      "grad_norm": 4.143497943878174,
      "learning_rate": 4.960548026962505e-05,
      "loss": 3.1399,
      "step": 1000
    },
    {
      "epoch": 0.0276228559402294,
      "grad_norm": 4.366379737854004,
      "learning_rate": 4.9583538126667605e-05,
      "loss": 3.1083,
      "step": 1050
    },
    {
      "epoch": 0.028938230032621276,
      "grad_norm": 4.8006978034973145,
      "learning_rate": 4.956159598371016e-05,
      "loss": 3.137,
      "step": 1100
    },
    {
      "epoch": 0.030253604125013153,
      "grad_norm": 4.457635402679443,
      "learning_rate": 4.95396538407527e-05,
      "loss": 3.1145,
      "step": 1150
    },
    {
      "epoch": 0.03156897821740503,
      "grad_norm": 4.645639419555664,
      "learning_rate": 4.9517711697795254e-05,
      "loss": 3.0531,
      "step": 1200
    },
    {
      "epoch": 0.03288435230979691,
      "grad_norm": 4.2459611892700195,
      "learning_rate": 4.949576955483781e-05,
      "loss": 2.9847,
      "step": 1250
    },
    {
      "epoch": 0.03419972640218878,
      "grad_norm": 4.164949893951416,
      "learning_rate": 4.9473827411880356e-05,
      "loss": 3.06,
      "step": 1300
    },
    {
      "epoch": 0.03551510049458066,
      "grad_norm": 3.9387176036834717,
      "learning_rate": 4.9451885268922904e-05,
      "loss": 3.0451,
      "step": 1350
    },
    {
      "epoch": 0.036830474586972535,
      "grad_norm": 4.140332221984863,
      "learning_rate": 4.942994312596546e-05,
      "loss": 2.9632,
      "step": 1400
    },
    {
      "epoch": 0.03814584867936441,
      "grad_norm": 3.912034034729004,
      "learning_rate": 4.9408000983008005e-05,
      "loss": 2.992,
      "step": 1450
    },
    {
      "epoch": 0.03946122277175629,
      "grad_norm": 4.060060501098633,
      "learning_rate": 4.938605884005056e-05,
      "loss": 2.9542,
      "step": 1500
    },
    {
      "epoch": 0.04077659686414816,
      "grad_norm": 3.7688229084014893,
      "learning_rate": 4.936411669709311e-05,
      "loss": 2.9729,
      "step": 1550
    },
    {
      "epoch": 0.04209197095654004,
      "grad_norm": 3.912684917449951,
      "learning_rate": 4.9342174554135655e-05,
      "loss": 2.9122,
      "step": 1600
    },
    {
      "epoch": 0.043407345048931914,
      "grad_norm": 3.926635503768921,
      "learning_rate": 4.932023241117821e-05,
      "loss": 2.8848,
      "step": 1650
    },
    {
      "epoch": 0.044722719141323794,
      "grad_norm": 3.7508904933929443,
      "learning_rate": 4.9298290268220756e-05,
      "loss": 2.8326,
      "step": 1700
    },
    {
      "epoch": 0.04603809323371567,
      "grad_norm": 3.6149775981903076,
      "learning_rate": 4.927634812526331e-05,
      "loss": 2.8757,
      "step": 1750
    },
    {
      "epoch": 0.04735346732610755,
      "grad_norm": 3.5737292766571045,
      "learning_rate": 4.925440598230586e-05,
      "loss": 2.8518,
      "step": 1800
    },
    {
      "epoch": 0.04866884141849942,
      "grad_norm": 3.5663764476776123,
      "learning_rate": 4.9232463839348406e-05,
      "loss": 2.803,
      "step": 1850
    },
    {
      "epoch": 0.0499842155108913,
      "grad_norm": 3.6550686359405518,
      "learning_rate": 4.921052169639096e-05,
      "loss": 2.7856,
      "step": 1900
    },
    {
      "epoch": 0.05129958960328317,
      "grad_norm": 3.404341459274292,
      "learning_rate": 4.9188579553433514e-05,
      "loss": 2.8256,
      "step": 1950
    },
    {
      "epoch": 0.05261496369567505,
      "grad_norm": 3.6926426887512207,
      "learning_rate": 4.9166637410476055e-05,
      "loss": 2.7853,
      "step": 2000
    },
    {
      "epoch": 0.053930337788066926,
      "grad_norm": 3.9886672496795654,
      "learning_rate": 4.914469526751861e-05,
      "loss": 2.7507,
      "step": 2050
    },
    {
      "epoch": 0.0552457118804588,
      "grad_norm": 3.5916130542755127,
      "learning_rate": 4.912275312456116e-05,
      "loss": 2.7331,
      "step": 2100
    },
    {
      "epoch": 0.05656108597285068,
      "grad_norm": 3.516690969467163,
      "learning_rate": 4.910081098160371e-05,
      "loss": 2.7415,
      "step": 2150
    },
    {
      "epoch": 0.05787646006524255,
      "grad_norm": 3.710052251815796,
      "learning_rate": 4.907886883864626e-05,
      "loss": 2.7296,
      "step": 2200
    },
    {
      "epoch": 0.05919183415763443,
      "grad_norm": 3.7253050804138184,
      "learning_rate": 4.905692669568881e-05,
      "loss": 2.7056,
      "step": 2250
    },
    {
      "epoch": 0.060507208250026305,
      "grad_norm": 3.393331527709961,
      "learning_rate": 4.903498455273136e-05,
      "loss": 2.7219,
      "step": 2300
    },
    {
      "epoch": 0.061822582342418185,
      "grad_norm": 3.439713716506958,
      "learning_rate": 4.9013042409773914e-05,
      "loss": 2.6136,
      "step": 2350
    },
    {
      "epoch": 0.06313795643481006,
      "grad_norm": 3.531374931335449,
      "learning_rate": 4.899110026681646e-05,
      "loss": 2.6214,
      "step": 2400
    },
    {
      "epoch": 0.06445333052720194,
      "grad_norm": 3.528536558151245,
      "learning_rate": 4.896915812385901e-05,
      "loss": 2.5735,
      "step": 2450
    },
    {
      "epoch": 0.06576870461959382,
      "grad_norm": 3.499691963195801,
      "learning_rate": 4.8947215980901564e-05,
      "loss": 2.5654,
      "step": 2500
    },
    {
      "epoch": 0.06708407871198568,
      "grad_norm": 3.9494006633758545,
      "learning_rate": 4.892527383794411e-05,
      "loss": 2.6022,
      "step": 2550
    },
    {
      "epoch": 0.06839945280437756,
      "grad_norm": 3.260120153427124,
      "learning_rate": 4.890333169498666e-05,
      "loss": 2.5475,
      "step": 2600
    },
    {
      "epoch": 0.06971482689676944,
      "grad_norm": 3.5896267890930176,
      "learning_rate": 4.888138955202921e-05,
      "loss": 2.5623,
      "step": 2650
    },
    {
      "epoch": 0.07103020098916132,
      "grad_norm": 3.59356427192688,
      "learning_rate": 4.885944740907176e-05,
      "loss": 2.5548,
      "step": 2700
    },
    {
      "epoch": 0.07234557508155319,
      "grad_norm": 3.6232950687408447,
      "learning_rate": 4.8837505266114315e-05,
      "loss": 2.5556,
      "step": 2750
    },
    {
      "epoch": 0.07366094917394507,
      "grad_norm": 3.538086175918579,
      "learning_rate": 4.881556312315686e-05,
      "loss": 2.4868,
      "step": 2800
    },
    {
      "epoch": 0.07497632326633695,
      "grad_norm": 3.6372792720794678,
      "learning_rate": 4.879362098019941e-05,
      "loss": 2.4982,
      "step": 2850
    },
    {
      "epoch": 0.07629169735872882,
      "grad_norm": 3.437744617462158,
      "learning_rate": 4.8771678837241964e-05,
      "loss": 2.4534,
      "step": 2900
    },
    {
      "epoch": 0.0776070714511207,
      "grad_norm": 3.473422050476074,
      "learning_rate": 4.874973669428451e-05,
      "loss": 2.4596,
      "step": 2950
    },
    {
      "epoch": 0.07892244554351258,
      "grad_norm": 3.682365894317627,
      "learning_rate": 4.872779455132706e-05,
      "loss": 2.4622,
      "step": 3000
    },
    {
      "epoch": 0.08023781963590446,
      "grad_norm": 3.8403143882751465,
      "learning_rate": 4.870585240836961e-05,
      "loss": 2.4407,
      "step": 3050
    },
    {
      "epoch": 0.08155319372829632,
      "grad_norm": 3.7377207279205322,
      "learning_rate": 4.868391026541216e-05,
      "loss": 2.4332,
      "step": 3100
    },
    {
      "epoch": 0.0828685678206882,
      "grad_norm": 3.6815052032470703,
      "learning_rate": 4.8661968122454715e-05,
      "loss": 2.4308,
      "step": 3150
    },
    {
      "epoch": 0.08418394191308008,
      "grad_norm": 3.5947234630584717,
      "learning_rate": 4.864002597949726e-05,
      "loss": 2.3685,
      "step": 3200
    },
    {
      "epoch": 0.08549931600547196,
      "grad_norm": 3.4938981533050537,
      "learning_rate": 4.861808383653981e-05,
      "loss": 2.3689,
      "step": 3250
    },
    {
      "epoch": 0.08681469009786383,
      "grad_norm": 3.753218412399292,
      "learning_rate": 4.8596141693582364e-05,
      "loss": 2.3835,
      "step": 3300
    },
    {
      "epoch": 0.08813006419025571,
      "grad_norm": 3.5779364109039307,
      "learning_rate": 4.857419955062492e-05,
      "loss": 2.3033,
      "step": 3350
    },
    {
      "epoch": 0.08944543828264759,
      "grad_norm": 3.35483980178833,
      "learning_rate": 4.8552257407667466e-05,
      "loss": 2.3503,
      "step": 3400
    },
    {
      "epoch": 0.09076081237503947,
      "grad_norm": 3.662656545639038,
      "learning_rate": 4.853031526471001e-05,
      "loss": 2.3076,
      "step": 3450
    },
    {
      "epoch": 0.09207618646743133,
      "grad_norm": 3.527604818344116,
      "learning_rate": 4.850837312175257e-05,
      "loss": 2.2586,
      "step": 3500
    },
    {
      "epoch": 0.09339156055982321,
      "grad_norm": 3.635446310043335,
      "learning_rate": 4.8486430978795115e-05,
      "loss": 2.2511,
      "step": 3550
    },
    {
      "epoch": 0.0947069346522151,
      "grad_norm": 3.4657187461853027,
      "learning_rate": 4.846448883583767e-05,
      "loss": 2.2606,
      "step": 3600
    },
    {
      "epoch": 0.09602230874460696,
      "grad_norm": 3.622511148452759,
      "learning_rate": 4.844254669288022e-05,
      "loss": 2.2173,
      "step": 3650
    },
    {
      "epoch": 0.09733768283699884,
      "grad_norm": 3.5834832191467285,
      "learning_rate": 4.8420604549922764e-05,
      "loss": 2.2259,
      "step": 3700
    },
    {
      "epoch": 0.09865305692939072,
      "grad_norm": 3.779200553894043,
      "learning_rate": 4.839866240696532e-05,
      "loss": 2.2525,
      "step": 3750
    },
    {
      "epoch": 0.0999684310217826,
      "grad_norm": 3.5496299266815186,
      "learning_rate": 4.8376720264007866e-05,
      "loss": 2.2126,
      "step": 3800
    },
    {
      "epoch": 0.10128380511417447,
      "grad_norm": 3.735586404800415,
      "learning_rate": 4.835477812105041e-05,
      "loss": 2.169,
      "step": 3850
    },
    {
      "epoch": 0.10259917920656635,
      "grad_norm": 3.8019607067108154,
      "learning_rate": 4.833283597809297e-05,
      "loss": 2.1902,
      "step": 3900
    },
    {
      "epoch": 0.10391455329895823,
      "grad_norm": 3.694018602371216,
      "learning_rate": 4.8310893835135515e-05,
      "loss": 2.1462,
      "step": 3950
    },
    {
      "epoch": 0.1052299273913501,
      "grad_norm": 3.6843111515045166,
      "learning_rate": 4.828895169217807e-05,
      "loss": 2.1652,
      "step": 4000
    },
    {
      "epoch": 0.10654530148374197,
      "grad_norm": 4.06701135635376,
      "learning_rate": 4.826700954922062e-05,
      "loss": 2.1193,
      "step": 4050
    },
    {
      "epoch": 0.10786067557613385,
      "grad_norm": 3.8372323513031006,
      "learning_rate": 4.8245067406263164e-05,
      "loss": 2.0927,
      "step": 4100
    },
    {
      "epoch": 0.10917604966852573,
      "grad_norm": 3.82944655418396,
      "learning_rate": 4.822312526330572e-05,
      "loss": 2.0595,
      "step": 4150
    },
    {
      "epoch": 0.1104914237609176,
      "grad_norm": 3.9085335731506348,
      "learning_rate": 4.820118312034827e-05,
      "loss": 2.0883,
      "step": 4200
    },
    {
      "epoch": 0.11180679785330948,
      "grad_norm": 4.022552490234375,
      "learning_rate": 4.8179240977390814e-05,
      "loss": 2.0197,
      "step": 4250
    },
    {
      "epoch": 0.11312217194570136,
      "grad_norm": 3.7517001628875732,
      "learning_rate": 4.815729883443337e-05,
      "loss": 2.055,
      "step": 4300
    },
    {
      "epoch": 0.11443754603809324,
      "grad_norm": 3.823434352874756,
      "learning_rate": 4.813535669147592e-05,
      "loss": 2.0422,
      "step": 4350
    },
    {
      "epoch": 0.1157529201304851,
      "grad_norm": 3.76379132270813,
      "learning_rate": 4.811341454851847e-05,
      "loss": 2.0322,
      "step": 4400
    },
    {
      "epoch": 0.11706829422287698,
      "grad_norm": 3.727142333984375,
      "learning_rate": 4.809147240556102e-05,
      "loss": 1.9907,
      "step": 4450
    },
    {
      "epoch": 0.11838366831526886,
      "grad_norm": 3.817352056503296,
      "learning_rate": 4.806953026260357e-05,
      "loss": 1.9718,
      "step": 4500
    },
    {
      "epoch": 0.11969904240766074,
      "grad_norm": 3.5675930976867676,
      "learning_rate": 4.804758811964612e-05,
      "loss": 1.9428,
      "step": 4550
    },
    {
      "epoch": 0.12101441650005261,
      "grad_norm": 3.9215779304504395,
      "learning_rate": 4.802564597668867e-05,
      "loss": 2.0269,
      "step": 4600
    },
    {
      "epoch": 0.12232979059244449,
      "grad_norm": 3.868548631668091,
      "learning_rate": 4.800370383373122e-05,
      "loss": 1.9371,
      "step": 4650
    },
    {
      "epoch": 0.12364516468483637,
      "grad_norm": 4.0765180587768555,
      "learning_rate": 4.798176169077377e-05,
      "loss": 1.9603,
      "step": 4700
    },
    {
      "epoch": 0.12496053877722825,
      "grad_norm": 3.7478644847869873,
      "learning_rate": 4.795981954781632e-05,
      "loss": 1.9355,
      "step": 4750
    },
    {
      "epoch": 0.12627591286962012,
      "grad_norm": 3.381047010421753,
      "learning_rate": 4.793787740485887e-05,
      "loss": 1.922,
      "step": 4800
    },
    {
      "epoch": 0.127591286962012,
      "grad_norm": 3.800903081893921,
      "learning_rate": 4.791593526190142e-05,
      "loss": 1.9486,
      "step": 4850
    },
    {
      "epoch": 0.12890666105440388,
      "grad_norm": 3.712846517562866,
      "learning_rate": 4.789399311894397e-05,
      "loss": 1.8799,
      "step": 4900
    },
    {
      "epoch": 0.13022203514679576,
      "grad_norm": 3.567807674407959,
      "learning_rate": 4.787205097598652e-05,
      "loss": 1.9152,
      "step": 4950
    },
    {
      "epoch": 0.13153740923918764,
      "grad_norm": 3.8524787425994873,
      "learning_rate": 4.785010883302907e-05,
      "loss": 1.846,
      "step": 5000
    },
    {
      "epoch": 0.1328527833315795,
      "grad_norm": 3.691301107406616,
      "learning_rate": 4.782816669007163e-05,
      "loss": 1.854,
      "step": 5050
    },
    {
      "epoch": 0.13416815742397137,
      "grad_norm": 3.628784418106079,
      "learning_rate": 4.780622454711417e-05,
      "loss": 1.8486,
      "step": 5100
    },
    {
      "epoch": 0.13548353151636325,
      "grad_norm": 3.802617073059082,
      "learning_rate": 4.778428240415672e-05,
      "loss": 1.8074,
      "step": 5150
    },
    {
      "epoch": 0.13679890560875513,
      "grad_norm": 3.6810762882232666,
      "learning_rate": 4.776234026119927e-05,
      "loss": 1.8398,
      "step": 5200
    },
    {
      "epoch": 0.138114279701147,
      "grad_norm": 3.6902554035186768,
      "learning_rate": 4.7740398118241824e-05,
      "loss": 1.8145,
      "step": 5250
    },
    {
      "epoch": 0.1394296537935389,
      "grad_norm": 3.6626811027526855,
      "learning_rate": 4.771845597528437e-05,
      "loss": 1.8058,
      "step": 5300
    },
    {
      "epoch": 0.14074502788593077,
      "grad_norm": 4.146917819976807,
      "learning_rate": 4.769651383232692e-05,
      "loss": 1.7824,
      "step": 5350
    },
    {
      "epoch": 0.14206040197832265,
      "grad_norm": 4.075908184051514,
      "learning_rate": 4.7674571689369473e-05,
      "loss": 1.7595,
      "step": 5400
    },
    {
      "epoch": 0.1433757760707145,
      "grad_norm": 4.705069541931152,
      "learning_rate": 4.765262954641203e-05,
      "loss": 1.7479,
      "step": 5450
    },
    {
      "epoch": 0.14469115016310638,
      "grad_norm": 3.9182751178741455,
      "learning_rate": 4.763068740345457e-05,
      "loss": 1.7428,
      "step": 5500
    },
    {
      "epoch": 0.14600652425549826,
      "grad_norm": 3.950749635696411,
      "learning_rate": 4.760874526049712e-05,
      "loss": 1.7652,
      "step": 5550
    },
    {
      "epoch": 0.14732189834789014,
      "grad_norm": 3.8378541469573975,
      "learning_rate": 4.758680311753968e-05,
      "loss": 1.7204,
      "step": 5600
    },
    {
      "epoch": 0.14863727244028202,
      "grad_norm": 4.005204677581787,
      "learning_rate": 4.7564860974582224e-05,
      "loss": 1.7031,
      "step": 5650
    },
    {
      "epoch": 0.1499526465326739,
      "grad_norm": 3.9221715927124023,
      "learning_rate": 4.754291883162477e-05,
      "loss": 1.6787,
      "step": 5700
    },
    {
      "epoch": 0.15126802062506578,
      "grad_norm": 3.8911564350128174,
      "learning_rate": 4.7520976688667326e-05,
      "loss": 1.6771,
      "step": 5750
    },
    {
      "epoch": 0.15258339471745763,
      "grad_norm": 3.839562177658081,
      "learning_rate": 4.7499034545709874e-05,
      "loss": 1.6658,
      "step": 5800
    },
    {
      "epoch": 0.1538987688098495,
      "grad_norm": 3.637214183807373,
      "learning_rate": 4.747709240275243e-05,
      "loss": 1.6714,
      "step": 5850
    },
    {
      "epoch": 0.1552141429022414,
      "grad_norm": 3.6993391513824463,
      "learning_rate": 4.7455150259794975e-05,
      "loss": 1.6594,
      "step": 5900
    },
    {
      "epoch": 0.15652951699463327,
      "grad_norm": 3.794693946838379,
      "learning_rate": 4.743320811683752e-05,
      "loss": 1.6188,
      "step": 5950
    },
    {
      "epoch": 0.15784489108702515,
      "grad_norm": 3.5773661136627197,
      "learning_rate": 4.741126597388008e-05,
      "loss": 1.607,
      "step": 6000
    },
    {
      "epoch": 0.15916026517941703,
      "grad_norm": 3.844616413116455,
      "learning_rate": 4.7389323830922625e-05,
      "loss": 1.6251,
      "step": 6050
    },
    {
      "epoch": 0.1604756392718089,
      "grad_norm": 3.7326931953430176,
      "learning_rate": 4.736738168796517e-05,
      "loss": 1.5865,
      "step": 6100
    },
    {
      "epoch": 0.1617910133642008,
      "grad_norm": 3.732696533203125,
      "learning_rate": 4.7345439545007726e-05,
      "loss": 1.57,
      "step": 6150
    },
    {
      "epoch": 0.16310638745659264,
      "grad_norm": 3.7096824645996094,
      "learning_rate": 4.7323497402050274e-05,
      "loss": 1.6151,
      "step": 6200
    },
    {
      "epoch": 0.16442176154898452,
      "grad_norm": 3.4991278648376465,
      "learning_rate": 4.730155525909283e-05,
      "loss": 1.5879,
      "step": 6250
    },
    {
      "epoch": 0.1657371356413764,
      "grad_norm": 3.5851821899414062,
      "learning_rate": 4.7279613116135376e-05,
      "loss": 1.5705,
      "step": 6300
    },
    {
      "epoch": 0.16705250973376828,
      "grad_norm": 3.6867311000823975,
      "learning_rate": 4.725767097317792e-05,
      "loss": 1.5719,
      "step": 6350
    },
    {
      "epoch": 0.16836788382616016,
      "grad_norm": 3.909468173980713,
      "learning_rate": 4.723572883022048e-05,
      "loss": 1.5266,
      "step": 6400
    },
    {
      "epoch": 0.16968325791855204,
      "grad_norm": 3.6597445011138916,
      "learning_rate": 4.721378668726303e-05,
      "loss": 1.513,
      "step": 6450
    },
    {
      "epoch": 0.17099863201094392,
      "grad_norm": 3.4932639598846436,
      "learning_rate": 4.719184454430557e-05,
      "loss": 1.5081,
      "step": 6500
    },
    {
      "epoch": 0.17231400610333578,
      "grad_norm": 3.959824562072754,
      "learning_rate": 4.7169902401348126e-05,
      "loss": 1.5124,
      "step": 6550
    },
    {
      "epoch": 0.17362938019572766,
      "grad_norm": 3.7129294872283936,
      "learning_rate": 4.714796025839068e-05,
      "loss": 1.4906,
      "step": 6600
    },
    {
      "epoch": 0.17494475428811954,
      "grad_norm": 3.463050127029419,
      "learning_rate": 4.712601811543323e-05,
      "loss": 1.4994,
      "step": 6650
    },
    {
      "epoch": 0.17626012838051142,
      "grad_norm": 3.6359970569610596,
      "learning_rate": 4.710407597247578e-05,
      "loss": 1.4671,
      "step": 6700
    },
    {
      "epoch": 0.1775755024729033,
      "grad_norm": 4.196108818054199,
      "learning_rate": 4.708213382951833e-05,
      "loss": 1.4752,
      "step": 6750
    },
    {
      "epoch": 0.17889087656529518,
      "grad_norm": 3.853898763656616,
      "learning_rate": 4.706019168656088e-05,
      "loss": 1.4515,
      "step": 6800
    },
    {
      "epoch": 0.18020625065768706,
      "grad_norm": 3.7030718326568604,
      "learning_rate": 4.703824954360343e-05,
      "loss": 1.4069,
      "step": 6850
    },
    {
      "epoch": 0.18152162475007894,
      "grad_norm": 3.563126564025879,
      "learning_rate": 4.701630740064598e-05,
      "loss": 1.4574,
      "step": 6900
    },
    {
      "epoch": 0.1828369988424708,
      "grad_norm": 4.239049434661865,
      "learning_rate": 4.699436525768853e-05,
      "loss": 1.4589,
      "step": 6950
    },
    {
      "epoch": 0.18415237293486267,
      "grad_norm": 3.819837808609009,
      "learning_rate": 4.697242311473108e-05,
      "loss": 1.3907,
      "step": 7000
    },
    {
      "epoch": 0.18546774702725455,
      "grad_norm": 3.7029905319213867,
      "learning_rate": 4.695048097177363e-05,
      "loss": 1.3885,
      "step": 7050
    },
    {
      "epoch": 0.18678312111964643,
      "grad_norm": 3.8869221210479736,
      "learning_rate": 4.692853882881618e-05,
      "loss": 1.4102,
      "step": 7100
    },
    {
      "epoch": 0.1880984952120383,
      "grad_norm": 4.0819172859191895,
      "learning_rate": 4.690659668585873e-05,
      "loss": 1.4131,
      "step": 7150
    },
    {
      "epoch": 0.1894138693044302,
      "grad_norm": 3.8263983726501465,
      "learning_rate": 4.688465454290128e-05,
      "loss": 1.3745,
      "step": 7200
    },
    {
      "epoch": 0.19072924339682207,
      "grad_norm": 3.665156602859497,
      "learning_rate": 4.686271239994383e-05,
      "loss": 1.3827,
      "step": 7250
    },
    {
      "epoch": 0.19204461748921392,
      "grad_norm": 3.75203275680542,
      "learning_rate": 4.684077025698638e-05,
      "loss": 1.3619,
      "step": 7300
    },
    {
      "epoch": 0.1933599915816058,
      "grad_norm": 3.593564748764038,
      "learning_rate": 4.681882811402893e-05,
      "loss": 1.3505,
      "step": 7350
    },
    {
      "epoch": 0.19467536567399768,
      "grad_norm": 3.7101950645446777,
      "learning_rate": 4.679688597107148e-05,
      "loss": 1.3356,
      "step": 7400
    },
    {
      "epoch": 0.19599073976638956,
      "grad_norm": 3.4601266384124756,
      "learning_rate": 4.677494382811403e-05,
      "loss": 1.3542,
      "step": 7450
    },
    {
      "epoch": 0.19730611385878144,
      "grad_norm": 3.885892868041992,
      "learning_rate": 4.675300168515658e-05,
      "loss": 1.3528,
      "step": 7500
    },
    {
      "epoch": 0.19862148795117332,
      "grad_norm": 3.7246696949005127,
      "learning_rate": 4.673105954219913e-05,
      "loss": 1.3045,
      "step": 7550
    },
    {
      "epoch": 0.1999368620435652,
      "grad_norm": 3.375638246536255,
      "learning_rate": 4.670911739924168e-05,
      "loss": 1.3057,
      "step": 7600
    },
    {
      "epoch": 0.20125223613595708,
      "grad_norm": 3.618948221206665,
      "learning_rate": 4.668717525628423e-05,
      "loss": 1.3381,
      "step": 7650
    },
    {
      "epoch": 0.20256761022834893,
      "grad_norm": 3.548267126083374,
      "learning_rate": 4.6665233113326786e-05,
      "loss": 1.2762,
      "step": 7700
    },
    {
      "epoch": 0.2038829843207408,
      "grad_norm": 3.7376480102539062,
      "learning_rate": 4.664329097036933e-05,
      "loss": 1.2748,
      "step": 7750
    },
    {
      "epoch": 0.2051983584131327,
      "grad_norm": 3.2393016815185547,
      "learning_rate": 4.662134882741188e-05,
      "loss": 1.3048,
      "step": 7800
    },
    {
      "epoch": 0.20651373250552457,
      "grad_norm": 3.762183427810669,
      "learning_rate": 4.6599406684454436e-05,
      "loss": 1.2847,
      "step": 7850
    },
    {
      "epoch": 0.20782910659791645,
      "grad_norm": 3.4829180240631104,
      "learning_rate": 4.657746454149698e-05,
      "loss": 1.2529,
      "step": 7900
    },
    {
      "epoch": 0.20914448069030833,
      "grad_norm": 3.4270777702331543,
      "learning_rate": 4.655552239853953e-05,
      "loss": 1.2186,
      "step": 7950
    },
    {
      "epoch": 0.2104598547827002,
      "grad_norm": 3.0711357593536377,
      "learning_rate": 4.6533580255582085e-05,
      "loss": 1.2375,
      "step": 8000
    },
    {
      "epoch": 0.21177522887509206,
      "grad_norm": 3.5724921226501465,
      "learning_rate": 4.651163811262463e-05,
      "loss": 1.226,
      "step": 8050
    },
    {
      "epoch": 0.21309060296748394,
      "grad_norm": 3.8929495811462402,
      "learning_rate": 4.6489695969667187e-05,
      "loss": 1.2317,
      "step": 8100
    },
    {
      "epoch": 0.21440597705987582,
      "grad_norm": 3.6373775005340576,
      "learning_rate": 4.6467753826709734e-05,
      "loss": 1.213,
      "step": 8150
    },
    {
      "epoch": 0.2157213511522677,
      "grad_norm": 3.3798668384552,
      "learning_rate": 4.644581168375228e-05,
      "loss": 1.2042,
      "step": 8200
    },
    {
      "epoch": 0.21703672524465958,
      "grad_norm": 3.4051513671875,
      "learning_rate": 4.6423869540794836e-05,
      "loss": 1.1793,
      "step": 8250
    },
    {
      "epoch": 0.21835209933705146,
      "grad_norm": 3.480412006378174,
      "learning_rate": 4.640192739783738e-05,
      "loss": 1.1785,
      "step": 8300
    },
    {
      "epoch": 0.21966747342944334,
      "grad_norm": 3.6101315021514893,
      "learning_rate": 4.637998525487994e-05,
      "loss": 1.1828,
      "step": 8350
    },
    {
      "epoch": 0.2209828475218352,
      "grad_norm": 3.6551015377044678,
      "learning_rate": 4.6358043111922485e-05,
      "loss": 1.1579,
      "step": 8400
    },
    {
      "epoch": 0.22229822161422708,
      "grad_norm": 3.4503331184387207,
      "learning_rate": 4.633610096896503e-05,
      "loss": 1.1299,
      "step": 8450
    },
    {
      "epoch": 0.22361359570661896,
      "grad_norm": 3.5262672901153564,
      "learning_rate": 4.631415882600759e-05,
      "loss": 1.1659,
      "step": 8500
    },
    {
      "epoch": 0.22492896979901084,
      "grad_norm": 3.8064424991607666,
      "learning_rate": 4.629221668305014e-05,
      "loss": 1.1765,
      "step": 8550
    },
    {
      "epoch": 0.22624434389140272,
      "grad_norm": 3.5359644889831543,
      "learning_rate": 4.627027454009268e-05,
      "loss": 1.1507,
      "step": 8600
    },
    {
      "epoch": 0.2275597179837946,
      "grad_norm": 3.370638847351074,
      "learning_rate": 4.6248332397135236e-05,
      "loss": 1.1343,
      "step": 8650
    },
    {
      "epoch": 0.22887509207618648,
      "grad_norm": 3.4958245754241943,
      "learning_rate": 4.622639025417779e-05,
      "loss": 1.113,
      "step": 8700
    },
    {
      "epoch": 0.23019046616857836,
      "grad_norm": 3.226184844970703,
      "learning_rate": 4.620444811122034e-05,
      "loss": 1.084,
      "step": 8750
    },
    {
      "epoch": 0.2315058402609702,
      "grad_norm": 3.5963146686553955,
      "learning_rate": 4.6182505968262885e-05,
      "loss": 1.082,
      "step": 8800
    },
    {
      "epoch": 0.2328212143533621,
      "grad_norm": 3.373671770095825,
      "learning_rate": 4.616056382530544e-05,
      "loss": 1.0979,
      "step": 8850
    },
    {
      "epoch": 0.23413658844575397,
      "grad_norm": 3.5425708293914795,
      "learning_rate": 4.613862168234799e-05,
      "loss": 1.1099,
      "step": 8900
    },
    {
      "epoch": 0.23545196253814585,
      "grad_norm": 3.440082550048828,
      "learning_rate": 4.611667953939054e-05,
      "loss": 1.0861,
      "step": 8950
    },
    {
      "epoch": 0.23676733663053773,
      "grad_norm": 3.4458281993865967,
      "learning_rate": 4.609473739643309e-05,
      "loss": 1.0689,
      "step": 9000
    },
    {
      "epoch": 0.2380827107229296,
      "grad_norm": 3.2051799297332764,
      "learning_rate": 4.6072795253475636e-05,
      "loss": 1.0822,
      "step": 9050
    },
    {
      "epoch": 0.2393980848153215,
      "grad_norm": 3.7254574298858643,
      "learning_rate": 4.605085311051819e-05,
      "loss": 1.0632,
      "step": 9100
    },
    {
      "epoch": 0.24071345890771334,
      "grad_norm": 3.5449750423431396,
      "learning_rate": 4.602891096756074e-05,
      "loss": 1.0654,
      "step": 9150
    },
    {
      "epoch": 0.24202883300010522,
      "grad_norm": 3.5466675758361816,
      "learning_rate": 4.6006968824603285e-05,
      "loss": 1.0586,
      "step": 9200
    },
    {
      "epoch": 0.2433442070924971,
      "grad_norm": 3.0237770080566406,
      "learning_rate": 4.598502668164584e-05,
      "loss": 1.0352,
      "step": 9250
    },
    {
      "epoch": 0.24465958118488898,
      "grad_norm": 3.4985313415527344,
      "learning_rate": 4.596308453868839e-05,
      "loss": 1.0287,
      "step": 9300
    },
    {
      "epoch": 0.24597495527728086,
      "grad_norm": 3.1623334884643555,
      "learning_rate": 4.594114239573094e-05,
      "loss": 1.0087,
      "step": 9350
    },
    {
      "epoch": 0.24729032936967274,
      "grad_norm": 3.3031067848205566,
      "learning_rate": 4.591920025277349e-05,
      "loss": 1.0316,
      "step": 9400
    },
    {
      "epoch": 0.24860570346206462,
      "grad_norm": 2.7166216373443604,
      "learning_rate": 4.5897258109816036e-05,
      "loss": 1.0401,
      "step": 9450
    },
    {
      "epoch": 0.2499210775544565,
      "grad_norm": 3.2653353214263916,
      "learning_rate": 4.587531596685859e-05,
      "loss": 1.023,
      "step": 9500
    },
    {
      "epoch": 0.2512364516468484,
      "grad_norm": 3.227163076400757,
      "learning_rate": 4.585337382390114e-05,
      "loss": 1.0006,
      "step": 9550
    },
    {
      "epoch": 0.25255182573924023,
      "grad_norm": 3.293539047241211,
      "learning_rate": 4.5831431680943686e-05,
      "loss": 1.0037,
      "step": 9600
    },
    {
      "epoch": 0.25386719983163214,
      "grad_norm": 3.1043334007263184,
      "learning_rate": 4.580948953798624e-05,
      "loss": 0.9992,
      "step": 9650
    },
    {
      "epoch": 0.255182573924024,
      "grad_norm": 3.4505693912506104,
      "learning_rate": 4.578754739502879e-05,
      "loss": 0.9658,
      "step": 9700
    },
    {
      "epoch": 0.25649794801641584,
      "grad_norm": 3.0007901191711426,
      "learning_rate": 4.576560525207134e-05,
      "loss": 0.9706,
      "step": 9750
    },
    {
      "epoch": 0.25781332210880775,
      "grad_norm": 3.3313891887664795,
      "learning_rate": 4.5743663109113896e-05,
      "loss": 0.9598,
      "step": 9800
    },
    {
      "epoch": 0.2591286962011996,
      "grad_norm": 3.2076072692871094,
      "learning_rate": 4.5721720966156437e-05,
      "loss": 0.9682,
      "step": 9850
    },
    {
      "epoch": 0.2604440702935915,
      "grad_norm": 3.260403633117676,
      "learning_rate": 4.569977882319899e-05,
      "loss": 0.9568,
      "step": 9900
    },
    {
      "epoch": 0.26175944438598336,
      "grad_norm": 3.230219841003418,
      "learning_rate": 4.5677836680241545e-05,
      "loss": 0.9537,
      "step": 9950
    },
    {
      "epoch": 0.26307481847837527,
      "grad_norm": 3.1810789108276367,
      "learning_rate": 4.565589453728409e-05,
      "loss": 0.9444,
      "step": 10000
    },
    {
      "epoch": 0.2643901925707671,
      "grad_norm": 3.494575023651123,
      "learning_rate": 4.563395239432664e-05,
      "loss": 0.9122,
      "step": 10050
    },
    {
      "epoch": 0.265705566663159,
      "grad_norm": 3.653334379196167,
      "learning_rate": 4.5612010251369194e-05,
      "loss": 0.905,
      "step": 10100
    },
    {
      "epoch": 0.2670209407555509,
      "grad_norm": 2.9708564281463623,
      "learning_rate": 4.559006810841174e-05,
      "loss": 0.9137,
      "step": 10150
    },
    {
      "epoch": 0.26833631484794274,
      "grad_norm": 3.0757315158843994,
      "learning_rate": 4.5568125965454296e-05,
      "loss": 0.9038,
      "step": 10200
    },
    {
      "epoch": 0.26965168894033464,
      "grad_norm": 3.2796518802642822,
      "learning_rate": 4.5546183822496843e-05,
      "loss": 0.893,
      "step": 10250
    },
    {
      "epoch": 0.2709670630327265,
      "grad_norm": 3.2860803604125977,
      "learning_rate": 4.552424167953939e-05,
      "loss": 0.9261,
      "step": 10300
    },
    {
      "epoch": 0.2722824371251184,
      "grad_norm": 3.781313419342041,
      "learning_rate": 4.5502299536581945e-05,
      "loss": 0.8905,
      "step": 10350
    },
    {
      "epoch": 0.27359781121751026,
      "grad_norm": 2.8962879180908203,
      "learning_rate": 4.548035739362449e-05,
      "loss": 0.8942,
      "step": 10400
    },
    {
      "epoch": 0.27491318530990216,
      "grad_norm": 3.1563656330108643,
      "learning_rate": 4.545841525066704e-05,
      "loss": 0.8808,
      "step": 10450
    },
    {
      "epoch": 0.276228559402294,
      "grad_norm": 3.503777265548706,
      "learning_rate": 4.5436473107709594e-05,
      "loss": 0.8736,
      "step": 10500
    },
    {
      "epoch": 0.27754393349468587,
      "grad_norm": 3.2380638122558594,
      "learning_rate": 4.541453096475214e-05,
      "loss": 0.8567,
      "step": 10550
    },
    {
      "epoch": 0.2788593075870778,
      "grad_norm": 3.213435173034668,
      "learning_rate": 4.5392588821794696e-05,
      "loss": 0.8587,
      "step": 10600
    },
    {
      "epoch": 0.28017468167946963,
      "grad_norm": 3.0643270015716553,
      "learning_rate": 4.5370646678837244e-05,
      "loss": 0.8684,
      "step": 10650
    },
    {
      "epoch": 0.28149005577186154,
      "grad_norm": 3.014063596725464,
      "learning_rate": 4.534870453587979e-05,
      "loss": 0.8467,
      "step": 10700
    },
    {
      "epoch": 0.2828054298642534,
      "grad_norm": 3.0326268672943115,
      "learning_rate": 4.5326762392922345e-05,
      "loss": 0.8426,
      "step": 10750
    },
    {
      "epoch": 0.2841208039566453,
      "grad_norm": 2.934464931488037,
      "learning_rate": 4.53048202499649e-05,
      "loss": 0.838,
      "step": 10800
    },
    {
      "epoch": 0.28543617804903715,
      "grad_norm": 3.30582594871521,
      "learning_rate": 4.528287810700744e-05,
      "loss": 0.8397,
      "step": 10850
    },
    {
      "epoch": 0.286751552141429,
      "grad_norm": 3.0838534832000732,
      "learning_rate": 4.5260935964049995e-05,
      "loss": 0.8289,
      "step": 10900
    },
    {
      "epoch": 0.2880669262338209,
      "grad_norm": 3.064761161804199,
      "learning_rate": 4.523899382109255e-05,
      "loss": 0.8151,
      "step": 10950
    },
    {
      "epoch": 0.28938230032621276,
      "grad_norm": 3.2611160278320312,
      "learning_rate": 4.5217051678135096e-05,
      "loss": 0.8316,
      "step": 11000
    },
    {
      "epoch": 0.29069767441860467,
      "grad_norm": 3.057140350341797,
      "learning_rate": 4.5195109535177644e-05,
      "loss": 0.8093,
      "step": 11050
    },
    {
      "epoch": 0.2920130485109965,
      "grad_norm": 2.962185859680176,
      "learning_rate": 4.51731673922202e-05,
      "loss": 0.8248,
      "step": 11100
    },
    {
      "epoch": 0.29332842260338843,
      "grad_norm": 3.0366640090942383,
      "learning_rate": 4.5151225249262746e-05,
      "loss": 0.7997,
      "step": 11150
    },
    {
      "epoch": 0.2946437966957803,
      "grad_norm": 3.1724936962127686,
      "learning_rate": 4.51292831063053e-05,
      "loss": 0.807,
      "step": 11200
    },
    {
      "epoch": 0.29595917078817213,
      "grad_norm": 2.7166125774383545,
      "learning_rate": 4.510734096334784e-05,
      "loss": 0.7909,
      "step": 11250
    },
    {
      "epoch": 0.29727454488056404,
      "grad_norm": 2.9784135818481445,
      "learning_rate": 4.5085398820390395e-05,
      "loss": 0.8188,
      "step": 11300
    },
    {
      "epoch": 0.2985899189729559,
      "grad_norm": 2.9838805198669434,
      "learning_rate": 4.506345667743295e-05,
      "loss": 0.7882,
      "step": 11350
    },
    {
      "epoch": 0.2999052930653478,
      "grad_norm": 3.1872074604034424,
      "learning_rate": 4.5041514534475497e-05,
      "loss": 0.7947,
      "step": 11400
    },
    {
      "epoch": 0.30122066715773965,
      "grad_norm": 2.776980400085449,
      "learning_rate": 4.501957239151805e-05,
      "loss": 0.7865,
      "step": 11450
    },
    {
      "epoch": 0.30253604125013156,
      "grad_norm": 3.322749376296997,
      "learning_rate": 4.49976302485606e-05,
      "loss": 0.7702,
      "step": 11500
    },
    {
      "epoch": 0.3038514153425234,
      "grad_norm": 3.234407663345337,
      "learning_rate": 4.4975688105603146e-05,
      "loss": 0.7881,
      "step": 11550
    },
    {
      "epoch": 0.30516678943491526,
      "grad_norm": 2.940218448638916,
      "learning_rate": 4.49537459626457e-05,
      "loss": 0.7684,
      "step": 11600
    },
    {
      "epoch": 0.30648216352730717,
      "grad_norm": 2.8729984760284424,
      "learning_rate": 4.493180381968825e-05,
      "loss": 0.7576,
      "step": 11650
    },
    {
      "epoch": 0.307797537619699,
      "grad_norm": 3.138914108276367,
      "learning_rate": 4.4909861676730795e-05,
      "loss": 0.7442,
      "step": 11700
    },
    {
      "epoch": 0.30911291171209093,
      "grad_norm": 2.705392837524414,
      "learning_rate": 4.488791953377335e-05,
      "loss": 0.7487,
      "step": 11750
    },
    {
      "epoch": 0.3104282858044828,
      "grad_norm": 2.935662269592285,
      "learning_rate": 4.48659773908159e-05,
      "loss": 0.7519,
      "step": 11800
    },
    {
      "epoch": 0.3117436598968747,
      "grad_norm": 2.73587703704834,
      "learning_rate": 4.484403524785845e-05,
      "loss": 0.7354,
      "step": 11850
    },
    {
      "epoch": 0.31305903398926654,
      "grad_norm": 3.1390371322631836,
      "learning_rate": 4.4822093104901e-05,
      "loss": 0.7363,
      "step": 11900
    },
    {
      "epoch": 0.3143744080816584,
      "grad_norm": 2.904305934906006,
      "learning_rate": 4.4800150961943546e-05,
      "loss": 0.7295,
      "step": 11950
    },
    {
      "epoch": 0.3156897821740503,
      "grad_norm": 2.815061092376709,
      "learning_rate": 4.47782088189861e-05,
      "loss": 0.7263,
      "step": 12000
    },
    {
      "epoch": 0.31700515626644216,
      "grad_norm": 2.6257686614990234,
      "learning_rate": 4.4756266676028655e-05,
      "loss": 0.7286,
      "step": 12050
    },
    {
      "epoch": 0.31832053035883406,
      "grad_norm": 2.583008050918579,
      "learning_rate": 4.4734324533071195e-05,
      "loss": 0.7187,
      "step": 12100
    },
    {
      "epoch": 0.3196359044512259,
      "grad_norm": 3.060189962387085,
      "learning_rate": 4.471238239011375e-05,
      "loss": 0.7143,
      "step": 12150
    },
    {
      "epoch": 0.3209512785436178,
      "grad_norm": 3.110095977783203,
      "learning_rate": 4.4690440247156304e-05,
      "loss": 0.7162,
      "step": 12200
    },
    {
      "epoch": 0.3222666526360097,
      "grad_norm": 2.943249225616455,
      "learning_rate": 4.466849810419885e-05,
      "loss": 0.6994,
      "step": 12250
    },
    {
      "epoch": 0.3235820267284016,
      "grad_norm": 2.7117364406585693,
      "learning_rate": 4.46465559612414e-05,
      "loss": 0.689,
      "step": 12300
    },
    {
      "epoch": 0.32489740082079344,
      "grad_norm": 3.070216655731201,
      "learning_rate": 4.462461381828395e-05,
      "loss": 0.6984,
      "step": 12350
    },
    {
      "epoch": 0.3262127749131853,
      "grad_norm": 2.931431293487549,
      "learning_rate": 4.46026716753265e-05,
      "loss": 0.6989,
      "step": 12400
    },
    {
      "epoch": 0.3275281490055772,
      "grad_norm": 2.6515653133392334,
      "learning_rate": 4.4580729532369055e-05,
      "loss": 0.6885,
      "step": 12450
    },
    {
      "epoch": 0.32884352309796905,
      "grad_norm": 3.064366340637207,
      "learning_rate": 4.45587873894116e-05,
      "loss": 0.6711,
      "step": 12500
    },
    {
      "epoch": 0.33015889719036096,
      "grad_norm": 2.869436502456665,
      "learning_rate": 4.453684524645415e-05,
      "loss": 0.662,
      "step": 12550
    },
    {
      "epoch": 0.3314742712827528,
      "grad_norm": 2.773674726486206,
      "learning_rate": 4.4514903103496704e-05,
      "loss": 0.6685,
      "step": 12600
    },
    {
      "epoch": 0.3327896453751447,
      "grad_norm": 2.77616286277771,
      "learning_rate": 4.449296096053925e-05,
      "loss": 0.6639,
      "step": 12650
    },
    {
      "epoch": 0.33410501946753657,
      "grad_norm": 2.909740447998047,
      "learning_rate": 4.44710188175818e-05,
      "loss": 0.6612,
      "step": 12700
    },
    {
      "epoch": 0.3354203935599284,
      "grad_norm": 2.940307140350342,
      "learning_rate": 4.444907667462435e-05,
      "loss": 0.6542,
      "step": 12750
    },
    {
      "epoch": 0.33673576765232033,
      "grad_norm": 2.9244985580444336,
      "learning_rate": 4.44271345316669e-05,
      "loss": 0.6657,
      "step": 12800
    },
    {
      "epoch": 0.3380511417447122,
      "grad_norm": 2.8674862384796143,
      "learning_rate": 4.4405192388709455e-05,
      "loss": 0.6478,
      "step": 12850
    },
    {
      "epoch": 0.3393665158371041,
      "grad_norm": 2.9744865894317627,
      "learning_rate": 4.4383250245752e-05,
      "loss": 0.658,
      "step": 12900
    },
    {
      "epoch": 0.34068188992949594,
      "grad_norm": 2.990710735321045,
      "learning_rate": 4.436130810279455e-05,
      "loss": 0.6392,
      "step": 12950
    },
    {
      "epoch": 0.34199726402188785,
      "grad_norm": 2.699868679046631,
      "learning_rate": 4.4339365959837104e-05,
      "loss": 0.6515,
      "step": 13000
    },
    {
      "epoch": 0.3433126381142797,
      "grad_norm": 2.740922212600708,
      "learning_rate": 4.431742381687966e-05,
      "loss": 0.6535,
      "step": 13050
    },
    {
      "epoch": 0.34462801220667155,
      "grad_norm": 2.973483085632324,
      "learning_rate": 4.4295481673922206e-05,
      "loss": 0.6341,
      "step": 13100
    },
    {
      "epoch": 0.34594338629906346,
      "grad_norm": 2.4955503940582275,
      "learning_rate": 4.427353953096475e-05,
      "loss": 0.6315,
      "step": 13150
    },
    {
      "epoch": 0.3472587603914553,
      "grad_norm": 2.520702838897705,
      "learning_rate": 4.425159738800731e-05,
      "loss": 0.6253,
      "step": 13200
    },
    {
      "epoch": 0.3485741344838472,
      "grad_norm": 2.706864356994629,
      "learning_rate": 4.4229655245049855e-05,
      "loss": 0.6242,
      "step": 13250
    },
    {
      "epoch": 0.34988950857623907,
      "grad_norm": 2.8329126834869385,
      "learning_rate": 4.420771310209241e-05,
      "loss": 0.6236,
      "step": 13300
    },
    {
      "epoch": 0.351204882668631,
      "grad_norm": 2.675360918045044,
      "learning_rate": 4.418577095913495e-05,
      "loss": 0.6098,
      "step": 13350
    },
    {
      "epoch": 0.35252025676102283,
      "grad_norm": 2.8619494438171387,
      "learning_rate": 4.4163828816177504e-05,
      "loss": 0.5916,
      "step": 13400
    },
    {
      "epoch": 0.3538356308534147,
      "grad_norm": 3.000617027282715,
      "learning_rate": 4.414188667322006e-05,
      "loss": 0.616,
      "step": 13450
    },
    {
      "epoch": 0.3551510049458066,
      "grad_norm": 2.789241313934326,
      "learning_rate": 4.4119944530262606e-05,
      "loss": 0.6116,
      "step": 13500
    },
    {
      "epoch": 0.35646637903819844,
      "grad_norm": 2.6547443866729736,
      "learning_rate": 4.4098002387305154e-05,
      "loss": 0.5908,
      "step": 13550
    },
    {
      "epoch": 0.35778175313059035,
      "grad_norm": 2.4766688346862793,
      "learning_rate": 4.407606024434771e-05,
      "loss": 0.5986,
      "step": 13600
    },
    {
      "epoch": 0.3590971272229822,
      "grad_norm": 2.6894354820251465,
      "learning_rate": 4.4054118101390255e-05,
      "loss": 0.5979,
      "step": 13650
    },
    {
      "epoch": 0.3604125013153741,
      "grad_norm": 2.8115947246551514,
      "learning_rate": 4.403217595843281e-05,
      "loss": 0.5783,
      "step": 13700
    },
    {
      "epoch": 0.36172787540776596,
      "grad_norm": 2.5773770809173584,
      "learning_rate": 4.401023381547536e-05,
      "loss": 0.5859,
      "step": 13750
    },
    {
      "epoch": 0.36304324950015787,
      "grad_norm": 2.727440595626831,
      "learning_rate": 4.3988291672517904e-05,
      "loss": 0.5864,
      "step": 13800
    },
    {
      "epoch": 0.3643586235925497,
      "grad_norm": 2.6812055110931396,
      "learning_rate": 4.396634952956046e-05,
      "loss": 0.5894,
      "step": 13850
    },
    {
      "epoch": 0.3656739976849416,
      "grad_norm": 2.7384026050567627,
      "learning_rate": 4.3944407386603006e-05,
      "loss": 0.5853,
      "step": 13900
    },
    {
      "epoch": 0.3669893717773335,
      "grad_norm": 2.936875343322754,
      "learning_rate": 4.3922465243645554e-05,
      "loss": 0.5833,
      "step": 13950
    },
    {
      "epoch": 0.36830474586972534,
      "grad_norm": 2.8788137435913086,
      "learning_rate": 4.390052310068811e-05,
      "loss": 0.5744,
      "step": 14000
    },
    {
      "epoch": 0.36962011996211724,
      "grad_norm": 2.592273712158203,
      "learning_rate": 4.3878580957730655e-05,
      "loss": 0.5683,
      "step": 14050
    },
    {
      "epoch": 0.3709354940545091,
      "grad_norm": 2.562497138977051,
      "learning_rate": 4.385663881477321e-05,
      "loss": 0.5661,
      "step": 14100
    },
    {
      "epoch": 0.372250868146901,
      "grad_norm": 2.4759182929992676,
      "learning_rate": 4.383469667181576e-05,
      "loss": 0.5516,
      "step": 14150
    },
    {
      "epoch": 0.37356624223929286,
      "grad_norm": 2.499873638153076,
      "learning_rate": 4.3812754528858305e-05,
      "loss": 0.5569,
      "step": 14200
    },
    {
      "epoch": 0.3748816163316847,
      "grad_norm": 2.603523015975952,
      "learning_rate": 4.379081238590086e-05,
      "loss": 0.5588,
      "step": 14250
    },
    {
      "epoch": 0.3761969904240766,
      "grad_norm": 2.606407880783081,
      "learning_rate": 4.376887024294341e-05,
      "loss": 0.5579,
      "step": 14300
    },
    {
      "epoch": 0.37751236451646847,
      "grad_norm": 2.543240785598755,
      "learning_rate": 4.3746928099985954e-05,
      "loss": 0.5519,
      "step": 14350
    },
    {
      "epoch": 0.3788277386088604,
      "grad_norm": 2.586846113204956,
      "learning_rate": 4.372498595702851e-05,
      "loss": 0.5411,
      "step": 14400
    },
    {
      "epoch": 0.38014311270125223,
      "grad_norm": 2.7681398391723633,
      "learning_rate": 4.370304381407106e-05,
      "loss": 0.5423,
      "step": 14450
    },
    {
      "epoch": 0.38145848679364414,
      "grad_norm": 2.4719860553741455,
      "learning_rate": 4.368110167111361e-05,
      "loss": 0.5426,
      "step": 14500
    },
    {
      "epoch": 0.382773860886036,
      "grad_norm": 2.4519734382629395,
      "learning_rate": 4.365915952815616e-05,
      "loss": 0.5372,
      "step": 14550
    },
    {
      "epoch": 0.38408923497842784,
      "grad_norm": 2.5911545753479004,
      "learning_rate": 4.363721738519871e-05,
      "loss": 0.5299,
      "step": 14600
    },
    {
      "epoch": 0.38540460907081975,
      "grad_norm": 2.719980478286743,
      "learning_rate": 4.361527524224126e-05,
      "loss": 0.532,
      "step": 14650
    },
    {
      "epoch": 0.3867199831632116,
      "grad_norm": 2.3516337871551514,
      "learning_rate": 4.359333309928381e-05,
      "loss": 0.524,
      "step": 14700
    },
    {
      "epoch": 0.3880353572556035,
      "grad_norm": 2.357236862182617,
      "learning_rate": 4.357139095632636e-05,
      "loss": 0.5305,
      "step": 14750
    },
    {
      "epoch": 0.38935073134799536,
      "grad_norm": 2.386638879776001,
      "learning_rate": 4.354944881336891e-05,
      "loss": 0.5273,
      "step": 14800
    },
    {
      "epoch": 0.39066610544038727,
      "grad_norm": 2.4769434928894043,
      "learning_rate": 4.352750667041146e-05,
      "loss": 0.5269,
      "step": 14850
    },
    {
      "epoch": 0.3919814795327791,
      "grad_norm": 2.2444844245910645,
      "learning_rate": 4.350556452745401e-05,
      "loss": 0.5151,
      "step": 14900
    },
    {
      "epoch": 0.393296853625171,
      "grad_norm": 2.4094343185424805,
      "learning_rate": 4.3483622384496564e-05,
      "loss": 0.508,
      "step": 14950
    },
    {
      "epoch": 0.3946122277175629,
      "grad_norm": 2.4472122192382812,
      "learning_rate": 4.346168024153911e-05,
      "loss": 0.5057,
      "step": 15000
    },
    {
      "epoch": 0.39592760180995473,
      "grad_norm": 2.4776344299316406,
      "learning_rate": 4.343973809858166e-05,
      "loss": 0.5064,
      "step": 15050
    },
    {
      "epoch": 0.39724297590234664,
      "grad_norm": 2.22937273979187,
      "learning_rate": 4.3417795955624214e-05,
      "loss": 0.5193,
      "step": 15100
    },
    {
      "epoch": 0.3985583499947385,
      "grad_norm": 2.6266849040985107,
      "learning_rate": 4.339585381266677e-05,
      "loss": 0.4983,
      "step": 15150
    },
    {
      "epoch": 0.3998737240871304,
      "grad_norm": 2.5347166061401367,
      "learning_rate": 4.337391166970931e-05,
      "loss": 0.4965,
      "step": 15200
    },
    {
      "epoch": 0.40118909817952225,
      "grad_norm": 2.5053019523620605,
      "learning_rate": 4.335196952675186e-05,
      "loss": 0.4911,
      "step": 15250
    },
    {
      "epoch": 0.40250447227191416,
      "grad_norm": 2.6572303771972656,
      "learning_rate": 4.333002738379442e-05,
      "loss": 0.5021,
      "step": 15300
    },
    {
      "epoch": 0.403819846364306,
      "grad_norm": 2.6189658641815186,
      "learning_rate": 4.3308085240836965e-05,
      "loss": 0.4838,
      "step": 15350
    },
    {
      "epoch": 0.40513522045669786,
      "grad_norm": 2.2695157527923584,
      "learning_rate": 4.328614309787951e-05,
      "loss": 0.4977,
      "step": 15400
    },
    {
      "epoch": 0.40645059454908977,
      "grad_norm": 2.434584856033325,
      "learning_rate": 4.326420095492206e-05,
      "loss": 0.4926,
      "step": 15450
    },
    {
      "epoch": 0.4077659686414816,
      "grad_norm": 2.376437187194824,
      "learning_rate": 4.3242258811964614e-05,
      "loss": 0.4863,
      "step": 15500
    },
    {
      "epoch": 0.40908134273387353,
      "grad_norm": 2.409959554672241,
      "learning_rate": 4.322031666900717e-05,
      "loss": 0.4848,
      "step": 15550
    },
    {
      "epoch": 0.4103967168262654,
      "grad_norm": 2.4562735557556152,
      "learning_rate": 4.319837452604971e-05,
      "loss": 0.4808,
      "step": 15600
    },
    {
      "epoch": 0.4117120909186573,
      "grad_norm": 2.254756212234497,
      "learning_rate": 4.317643238309226e-05,
      "loss": 0.4666,
      "step": 15650
    },
    {
      "epoch": 0.41302746501104914,
      "grad_norm": 2.2607531547546387,
      "learning_rate": 4.315449024013482e-05,
      "loss": 0.4828,
      "step": 15700
    },
    {
      "epoch": 0.414342839103441,
      "grad_norm": 2.5096018314361572,
      "learning_rate": 4.3132548097177365e-05,
      "loss": 0.4676,
      "step": 15750
    },
    {
      "epoch": 0.4156582131958329,
      "grad_norm": 2.4482505321502686,
      "learning_rate": 4.311060595421991e-05,
      "loss": 0.4559,
      "step": 15800
    },
    {
      "epoch": 0.41697358728822476,
      "grad_norm": 2.353076934814453,
      "learning_rate": 4.3088663811262466e-05,
      "loss": 0.4655,
      "step": 15850
    },
    {
      "epoch": 0.41828896138061666,
      "grad_norm": 2.1600756645202637,
      "learning_rate": 4.3066721668305014e-05,
      "loss": 0.4645,
      "step": 15900
    },
    {
      "epoch": 0.4196043354730085,
      "grad_norm": 2.6957943439483643,
      "learning_rate": 4.304477952534757e-05,
      "loss": 0.4645,
      "step": 15950
    },
    {
      "epoch": 0.4209197095654004,
      "grad_norm": 2.5809781551361084,
      "learning_rate": 4.3022837382390116e-05,
      "loss": 0.4572,
      "step": 16000
    },
    {
      "epoch": 0.4222350836577923,
      "grad_norm": 2.542050361633301,
      "learning_rate": 4.300089523943266e-05,
      "loss": 0.4497,
      "step": 16050
    },
    {
      "epoch": 0.42355045775018413,
      "grad_norm": 2.4986584186553955,
      "learning_rate": 4.297895309647522e-05,
      "loss": 0.4548,
      "step": 16100
    },
    {
      "epoch": 0.42486583184257604,
      "grad_norm": 2.370870590209961,
      "learning_rate": 4.2957010953517765e-05,
      "loss": 0.4463,
      "step": 16150
    },
    {
      "epoch": 0.4261812059349679,
      "grad_norm": 2.2410635948181152,
      "learning_rate": 4.293506881056032e-05,
      "loss": 0.4506,
      "step": 16200
    },
    {
      "epoch": 0.4274965800273598,
      "grad_norm": 2.253066301345825,
      "learning_rate": 4.291312666760287e-05,
      "loss": 0.4491,
      "step": 16250
    },
    {
      "epoch": 0.42881195411975165,
      "grad_norm": 1.9927785396575928,
      "learning_rate": 4.2891184524645414e-05,
      "loss": 0.4394,
      "step": 16300
    },
    {
      "epoch": 0.43012732821214356,
      "grad_norm": 2.297797918319702,
      "learning_rate": 4.286924238168797e-05,
      "loss": 0.4437,
      "step": 16350
    },
    {
      "epoch": 0.4314427023045354,
      "grad_norm": 2.1411664485931396,
      "learning_rate": 4.284730023873052e-05,
      "loss": 0.4419,
      "step": 16400
    },
    {
      "epoch": 0.43275807639692726,
      "grad_norm": 2.3555705547332764,
      "learning_rate": 4.282535809577306e-05,
      "loss": 0.4457,
      "step": 16450
    },
    {
      "epoch": 0.43407345048931917,
      "grad_norm": 2.339259386062622,
      "learning_rate": 4.280341595281562e-05,
      "loss": 0.433,
      "step": 16500
    },
    {
      "epoch": 0.435388824581711,
      "grad_norm": 2.325526237487793,
      "learning_rate": 4.278147380985817e-05,
      "loss": 0.4388,
      "step": 16550
    },
    {
      "epoch": 0.43670419867410293,
      "grad_norm": 2.032620906829834,
      "learning_rate": 4.275953166690072e-05,
      "loss": 0.4365,
      "step": 16600
    },
    {
      "epoch": 0.4380195727664948,
      "grad_norm": 2.3665435314178467,
      "learning_rate": 4.273758952394327e-05,
      "loss": 0.4356,
      "step": 16650
    },
    {
      "epoch": 0.4393349468588867,
      "grad_norm": 2.293567180633545,
      "learning_rate": 4.271564738098582e-05,
      "loss": 0.4277,
      "step": 16700
    },
    {
      "epoch": 0.44065032095127854,
      "grad_norm": 2.5700337886810303,
      "learning_rate": 4.269370523802837e-05,
      "loss": 0.4278,
      "step": 16750
    },
    {
      "epoch": 0.4419656950436704,
      "grad_norm": 2.384019374847412,
      "learning_rate": 4.267176309507092e-05,
      "loss": 0.432,
      "step": 16800
    },
    {
      "epoch": 0.4432810691360623,
      "grad_norm": 2.189366340637207,
      "learning_rate": 4.264982095211347e-05,
      "loss": 0.4228,
      "step": 16850
    },
    {
      "epoch": 0.44459644322845415,
      "grad_norm": 2.488101005554199,
      "learning_rate": 4.262787880915602e-05,
      "loss": 0.4306,
      "step": 16900
    },
    {
      "epoch": 0.44591181732084606,
      "grad_norm": 2.424798011779785,
      "learning_rate": 4.260593666619857e-05,
      "loss": 0.4135,
      "step": 16950
    },
    {
      "epoch": 0.4472271914132379,
      "grad_norm": 1.9927325248718262,
      "learning_rate": 4.258399452324112e-05,
      "loss": 0.4141,
      "step": 17000
    },
    {
      "epoch": 0.4485425655056298,
      "grad_norm": 2.1556479930877686,
      "learning_rate": 4.256205238028367e-05,
      "loss": 0.4142,
      "step": 17050
    },
    {
      "epoch": 0.44985793959802167,
      "grad_norm": 2.3439714908599854,
      "learning_rate": 4.254011023732622e-05,
      "loss": 0.4112,
      "step": 17100
    },
    {
      "epoch": 0.4511733136904136,
      "grad_norm": 2.096755266189575,
      "learning_rate": 4.251816809436877e-05,
      "loss": 0.4127,
      "step": 17150
    },
    {
      "epoch": 0.45248868778280543,
      "grad_norm": 2.6717312335968018,
      "learning_rate": 4.249622595141132e-05,
      "loss": 0.4139,
      "step": 17200
    },
    {
      "epoch": 0.4538040618751973,
      "grad_norm": 2.1211702823638916,
      "learning_rate": 4.247428380845387e-05,
      "loss": 0.409,
      "step": 17250
    },
    {
      "epoch": 0.4551194359675892,
      "grad_norm": 2.0945515632629395,
      "learning_rate": 4.245234166549642e-05,
      "loss": 0.4043,
      "step": 17300
    },
    {
      "epoch": 0.45643481005998104,
      "grad_norm": 2.05155611038208,
      "learning_rate": 4.243039952253897e-05,
      "loss": 0.3999,
      "step": 17350
    },
    {
      "epoch": 0.45775018415237295,
      "grad_norm": 2.2186594009399414,
      "learning_rate": 4.2408457379581527e-05,
      "loss": 0.4022,
      "step": 17400
    },
    {
      "epoch": 0.4590655582447648,
      "grad_norm": 2.1839582920074463,
      "learning_rate": 4.238651523662407e-05,
      "loss": 0.3992,
      "step": 17450
    },
    {
      "epoch": 0.4603809323371567,
      "grad_norm": 2.3255302906036377,
      "learning_rate": 4.236457309366662e-05,
      "loss": 0.3992,
      "step": 17500
    },
    {
      "epoch": 0.46169630642954856,
      "grad_norm": 2.019540548324585,
      "learning_rate": 4.234263095070917e-05,
      "loss": 0.3987,
      "step": 17550
    },
    {
      "epoch": 0.4630116805219404,
      "grad_norm": 2.2276692390441895,
      "learning_rate": 4.232068880775172e-05,
      "loss": 0.393,
      "step": 17600
    },
    {
      "epoch": 0.4643270546143323,
      "grad_norm": 2.002012014389038,
      "learning_rate": 4.229874666479427e-05,
      "loss": 0.3967,
      "step": 17650
    },
    {
      "epoch": 0.4656424287067242,
      "grad_norm": 2.2188966274261475,
      "learning_rate": 4.227680452183682e-05,
      "loss": 0.3951,
      "step": 17700
    },
    {
      "epoch": 0.4669578027991161,
      "grad_norm": 2.121962308883667,
      "learning_rate": 4.225486237887937e-05,
      "loss": 0.3849,
      "step": 17750
    },
    {
      "epoch": 0.46827317689150794,
      "grad_norm": 1.8132470846176147,
      "learning_rate": 4.223292023592193e-05,
      "loss": 0.3936,
      "step": 17800
    },
    {
      "epoch": 0.46958855098389984,
      "grad_norm": 1.9530643224716187,
      "learning_rate": 4.2210978092964474e-05,
      "loss": 0.3871,
      "step": 17850
    },
    {
      "epoch": 0.4709039250762917,
      "grad_norm": 2.1460204124450684,
      "learning_rate": 4.218903595000702e-05,
      "loss": 0.4036,
      "step": 17900
    },
    {
      "epoch": 0.47221929916868355,
      "grad_norm": 2.0865912437438965,
      "learning_rate": 4.2167093807049576e-05,
      "loss": 0.3807,
      "step": 17950
    },
    {
      "epoch": 0.47353467326107546,
      "grad_norm": 2.2129032611846924,
      "learning_rate": 4.2145151664092123e-05,
      "loss": 0.3751,
      "step": 18000
    },
    {
      "epoch": 0.4748500473534673,
      "grad_norm": 2.2225730419158936,
      "learning_rate": 4.212320952113468e-05,
      "loss": 0.3844,
      "step": 18050
    },
    {
      "epoch": 0.4761654214458592,
      "grad_norm": 1.7696316242218018,
      "learning_rate": 4.2101267378177225e-05,
      "loss": 0.3882,
      "step": 18100
    },
    {
      "epoch": 0.47748079553825107,
      "grad_norm": 1.8403377532958984,
      "learning_rate": 4.207932523521977e-05,
      "loss": 0.3856,
      "step": 18150
    },
    {
      "epoch": 0.478796169630643,
      "grad_norm": 1.9796980619430542,
      "learning_rate": 4.205738309226233e-05,
      "loss": 0.3901,
      "step": 18200
    },
    {
      "epoch": 0.48011154372303483,
      "grad_norm": 2.200497627258301,
      "learning_rate": 4.2035440949304874e-05,
      "loss": 0.3801,
      "step": 18250
    },
    {
      "epoch": 0.4814269178154267,
      "grad_norm": 1.8627232313156128,
      "learning_rate": 4.201349880634742e-05,
      "loss": 0.3742,
      "step": 18300
    },
    {
      "epoch": 0.4827422919078186,
      "grad_norm": 2.250370502471924,
      "learning_rate": 4.1991556663389976e-05,
      "loss": 0.3776,
      "step": 18350
    },
    {
      "epoch": 0.48405766600021044,
      "grad_norm": 2.180147409439087,
      "learning_rate": 4.1969614520432524e-05,
      "loss": 0.3765,
      "step": 18400
    },
    {
      "epoch": 0.48537304009260235,
      "grad_norm": 1.9857169389724731,
      "learning_rate": 4.194767237747508e-05,
      "loss": 0.3684,
      "step": 18450
    },
    {
      "epoch": 0.4866884141849942,
      "grad_norm": 1.8866641521453857,
      "learning_rate": 4.1925730234517625e-05,
      "loss": 0.3689,
      "step": 18500
    },
    {
      "epoch": 0.4880037882773861,
      "grad_norm": 2.1667842864990234,
      "learning_rate": 4.190378809156017e-05,
      "loss": 0.3639,
      "step": 18550
    },
    {
      "epoch": 0.48931916236977796,
      "grad_norm": 2.094841480255127,
      "learning_rate": 4.188184594860273e-05,
      "loss": 0.3649,
      "step": 18600
    },
    {
      "epoch": 0.49063453646216987,
      "grad_norm": 2.043488025665283,
      "learning_rate": 4.185990380564528e-05,
      "loss": 0.3563,
      "step": 18650
    },
    {
      "epoch": 0.4919499105545617,
      "grad_norm": 2.0477895736694336,
      "learning_rate": 4.183796166268782e-05,
      "loss": 0.3651,
      "step": 18700
    },
    {
      "epoch": 0.4932652846469536,
      "grad_norm": 2.0176632404327393,
      "learning_rate": 4.1816019519730376e-05,
      "loss": 0.3662,
      "step": 18750
    },
    {
      "epoch": 0.4945806587393455,
      "grad_norm": 2.0719072818756104,
      "learning_rate": 4.179407737677293e-05,
      "loss": 0.3598,
      "step": 18800
    },
    {
      "epoch": 0.49589603283173733,
      "grad_norm": 2.376417636871338,
      "learning_rate": 4.177213523381548e-05,
      "loss": 0.357,
      "step": 18850
    },
    {
      "epoch": 0.49721140692412924,
      "grad_norm": 1.9602831602096558,
      "learning_rate": 4.1750193090858026e-05,
      "loss": 0.355,
      "step": 18900
    },
    {
      "epoch": 0.4985267810165211,
      "grad_norm": 2.0812582969665527,
      "learning_rate": 4.172825094790058e-05,
      "loss": 0.3586,
      "step": 18950
    },
    {
      "epoch": 0.499842155108913,
      "grad_norm": 1.9111384153366089,
      "learning_rate": 4.170630880494313e-05,
      "loss": 0.3567,
      "step": 19000
    },
    {
      "epoch": 0.5011575292013049,
      "grad_norm": 1.9391937255859375,
      "learning_rate": 4.168436666198568e-05,
      "loss": 0.353,
      "step": 19050
    },
    {
      "epoch": 0.5024729032936968,
      "grad_norm": 1.913360834121704,
      "learning_rate": 4.166242451902823e-05,
      "loss": 0.3605,
      "step": 19100
    },
    {
      "epoch": 0.5037882773860886,
      "grad_norm": 2.099674701690674,
      "learning_rate": 4.1640482376070777e-05,
      "loss": 0.3508,
      "step": 19150
    },
    {
      "epoch": 0.5051036514784805,
      "grad_norm": 2.1020667552948,
      "learning_rate": 4.161854023311333e-05,
      "loss": 0.3448,
      "step": 19200
    },
    {
      "epoch": 0.5064190255708724,
      "grad_norm": 2.141920328140259,
      "learning_rate": 4.159659809015588e-05,
      "loss": 0.3598,
      "step": 19250
    },
    {
      "epoch": 0.5077343996632643,
      "grad_norm": 1.967569351196289,
      "learning_rate": 4.1574655947198426e-05,
      "loss": 0.3457,
      "step": 19300
    },
    {
      "epoch": 0.5090497737556561,
      "grad_norm": 1.965361475944519,
      "learning_rate": 4.155271380424098e-05,
      "loss": 0.3475,
      "step": 19350
    },
    {
      "epoch": 0.510365147848048,
      "grad_norm": 1.9495199918746948,
      "learning_rate": 4.153077166128353e-05,
      "loss": 0.3408,
      "step": 19400
    },
    {
      "epoch": 0.5116805219404399,
      "grad_norm": 2.1132025718688965,
      "learning_rate": 4.150882951832608e-05,
      "loss": 0.3459,
      "step": 19450
    },
    {
      "epoch": 0.5129958960328317,
      "grad_norm": 1.9519342184066772,
      "learning_rate": 4.1486887375368636e-05,
      "loss": 0.3347,
      "step": 19500
    },
    {
      "epoch": 0.5143112701252236,
      "grad_norm": 1.9398012161254883,
      "learning_rate": 4.146494523241118e-05,
      "loss": 0.3438,
      "step": 19550
    },
    {
      "epoch": 0.5156266442176155,
      "grad_norm": 1.8094286918640137,
      "learning_rate": 4.144300308945373e-05,
      "loss": 0.3419,
      "step": 19600
    },
    {
      "epoch": 0.5169420183100074,
      "grad_norm": 1.8314257860183716,
      "learning_rate": 4.142106094649628e-05,
      "loss": 0.3387,
      "step": 19650
    },
    {
      "epoch": 0.5182573924023992,
      "grad_norm": 2.0593347549438477,
      "learning_rate": 4.139911880353883e-05,
      "loss": 0.3357,
      "step": 19700
    },
    {
      "epoch": 0.5195727664947911,
      "grad_norm": 1.9936552047729492,
      "learning_rate": 4.137717666058138e-05,
      "loss": 0.3335,
      "step": 19750
    },
    {
      "epoch": 0.520888140587183,
      "grad_norm": 2.0990045070648193,
      "learning_rate": 4.135523451762393e-05,
      "loss": 0.3381,
      "step": 19800
    },
    {
      "epoch": 0.5222035146795748,
      "grad_norm": 1.9891599416732788,
      "learning_rate": 4.133329237466648e-05,
      "loss": 0.3361,
      "step": 19850
    },
    {
      "epoch": 0.5235188887719667,
      "grad_norm": 1.6667726039886475,
      "learning_rate": 4.1311350231709036e-05,
      "loss": 0.331,
      "step": 19900
    },
    {
      "epoch": 0.5248342628643586,
      "grad_norm": 1.970432996749878,
      "learning_rate": 4.128940808875158e-05,
      "loss": 0.3334,
      "step": 19950
    },
    {
      "epoch": 0.5261496369567505,
      "grad_norm": 1.803802251815796,
      "learning_rate": 4.126746594579413e-05,
      "loss": 0.3252,
      "step": 20000
    },
    {
      "epoch": 0.5274650110491423,
      "grad_norm": 2.034318447113037,
      "learning_rate": 4.1245523802836685e-05,
      "loss": 0.3286,
      "step": 20050
    },
    {
      "epoch": 0.5287803851415342,
      "grad_norm": 2.1091957092285156,
      "learning_rate": 4.122358165987923e-05,
      "loss": 0.3351,
      "step": 20100
    },
    {
      "epoch": 0.5300957592339262,
      "grad_norm": 2.1287682056427,
      "learning_rate": 4.120163951692178e-05,
      "loss": 0.3225,
      "step": 20150
    },
    {
      "epoch": 0.531411133326318,
      "grad_norm": 2.042827606201172,
      "learning_rate": 4.1179697373964335e-05,
      "loss": 0.3295,
      "step": 20200
    },
    {
      "epoch": 0.5327265074187099,
      "grad_norm": 1.7641535997390747,
      "learning_rate": 4.115775523100688e-05,
      "loss": 0.3263,
      "step": 20250
    },
    {
      "epoch": 0.5340418815111018,
      "grad_norm": 1.8016870021820068,
      "learning_rate": 4.1135813088049436e-05,
      "loss": 0.3281,
      "step": 20300
    },
    {
      "epoch": 0.5353572556034937,
      "grad_norm": 1.872923731803894,
      "learning_rate": 4.1113870945091984e-05,
      "loss": 0.3224,
      "step": 20350
    },
    {
      "epoch": 0.5366726296958855,
      "grad_norm": 1.7890948057174683,
      "learning_rate": 4.109192880213453e-05,
      "loss": 0.326,
      "step": 20400
    },
    {
      "epoch": 0.5379880037882774,
      "grad_norm": 1.9087640047073364,
      "learning_rate": 4.1069986659177086e-05,
      "loss": 0.3167,
      "step": 20450
    },
    {
      "epoch": 0.5393033778806693,
      "grad_norm": 1.8644334077835083,
      "learning_rate": 4.104804451621963e-05,
      "loss": 0.3221,
      "step": 20500
    },
    {
      "epoch": 0.5406187519730611,
      "grad_norm": 1.8518412113189697,
      "learning_rate": 4.102610237326218e-05,
      "loss": 0.3262,
      "step": 20550
    },
    {
      "epoch": 0.541934126065453,
      "grad_norm": 1.8928602933883667,
      "learning_rate": 4.1004160230304735e-05,
      "loss": 0.3288,
      "step": 20600
    },
    {
      "epoch": 0.5432495001578449,
      "grad_norm": 1.8837379217147827,
      "learning_rate": 4.098221808734728e-05,
      "loss": 0.3199,
      "step": 20650
    },
    {
      "epoch": 0.5445648742502368,
      "grad_norm": 1.9670252799987793,
      "learning_rate": 4.0960275944389837e-05,
      "loss": 0.3129,
      "step": 20700
    },
    {
      "epoch": 0.5458802483426286,
      "grad_norm": 1.9259365797042847,
      "learning_rate": 4.0938333801432384e-05,
      "loss": 0.3128,
      "step": 20750
    },
    {
      "epoch": 0.5471956224350205,
      "grad_norm": 2.068244457244873,
      "learning_rate": 4.091639165847493e-05,
      "loss": 0.3216,
      "step": 20800
    },
    {
      "epoch": 0.5485109965274124,
      "grad_norm": 1.9397516250610352,
      "learning_rate": 4.0894449515517486e-05,
      "loss": 0.3156,
      "step": 20850
    },
    {
      "epoch": 0.5498263706198043,
      "grad_norm": 1.795192003250122,
      "learning_rate": 4.087250737256004e-05,
      "loss": 0.304,
      "step": 20900
    },
    {
      "epoch": 0.5511417447121961,
      "grad_norm": 1.7101761102676392,
      "learning_rate": 4.085056522960258e-05,
      "loss": 0.3114,
      "step": 20950
    },
    {
      "epoch": 0.552457118804588,
      "grad_norm": 1.870035171508789,
      "learning_rate": 4.0828623086645135e-05,
      "loss": 0.3142,
      "step": 21000
    },
    {
      "epoch": 0.5537724928969799,
      "grad_norm": 2.002314805984497,
      "learning_rate": 4.080668094368769e-05,
      "loss": 0.308,
      "step": 21050
    },
    {
      "epoch": 0.5550878669893717,
      "grad_norm": 1.8113762140274048,
      "learning_rate": 4.078473880073024e-05,
      "loss": 0.3157,
      "step": 21100
    },
    {
      "epoch": 0.5564032410817636,
      "grad_norm": 2.0075182914733887,
      "learning_rate": 4.076279665777279e-05,
      "loss": 0.3089,
      "step": 21150
    },
    {
      "epoch": 0.5577186151741556,
      "grad_norm": 2.0144240856170654,
      "learning_rate": 4.074085451481534e-05,
      "loss": 0.3066,
      "step": 21200
    },
    {
      "epoch": 0.5590339892665475,
      "grad_norm": 1.815737009048462,
      "learning_rate": 4.0718912371857886e-05,
      "loss": 0.3,
      "step": 21250
    },
    {
      "epoch": 0.5603493633589393,
      "grad_norm": 1.7563189268112183,
      "learning_rate": 4.069697022890044e-05,
      "loss": 0.3046,
      "step": 21300
    },
    {
      "epoch": 0.5616647374513312,
      "grad_norm": 1.8740389347076416,
      "learning_rate": 4.067502808594299e-05,
      "loss": 0.292,
      "step": 21350
    },
    {
      "epoch": 0.5629801115437231,
      "grad_norm": 1.64962637424469,
      "learning_rate": 4.0653085942985535e-05,
      "loss": 0.298,
      "step": 21400
    },
    {
      "epoch": 0.5642954856361149,
      "grad_norm": 1.933121681213379,
      "learning_rate": 4.063114380002809e-05,
      "loss": 0.3063,
      "step": 21450
    },
    {
      "epoch": 0.5656108597285068,
      "grad_norm": 1.9920742511749268,
      "learning_rate": 4.060920165707064e-05,
      "loss": 0.2972,
      "step": 21500
    },
    {
      "epoch": 0.5669262338208987,
      "grad_norm": 1.98365318775177,
      "learning_rate": 4.058725951411319e-05,
      "loss": 0.3059,
      "step": 21550
    },
    {
      "epoch": 0.5682416079132906,
      "grad_norm": 2.0012173652648926,
      "learning_rate": 4.056531737115574e-05,
      "loss": 0.3014,
      "step": 21600
    },
    {
      "epoch": 0.5695569820056824,
      "grad_norm": 1.7504949569702148,
      "learning_rate": 4.0543375228198286e-05,
      "loss": 0.2988,
      "step": 21650
    },
    {
      "epoch": 0.5708723560980743,
      "grad_norm": 1.6435582637786865,
      "learning_rate": 4.052143308524084e-05,
      "loss": 0.2963,
      "step": 21700
    },
    {
      "epoch": 0.5721877301904662,
      "grad_norm": 1.6290277242660522,
      "learning_rate": 4.049949094228339e-05,
      "loss": 0.2941,
      "step": 21750
    },
    {
      "epoch": 0.573503104282858,
      "grad_norm": 1.9443527460098267,
      "learning_rate": 4.0477548799325935e-05,
      "loss": 0.2961,
      "step": 21800
    },
    {
      "epoch": 0.5748184783752499,
      "grad_norm": 1.811331033706665,
      "learning_rate": 4.045560665636849e-05,
      "loss": 0.2921,
      "step": 21850
    },
    {
      "epoch": 0.5761338524676418,
      "grad_norm": 1.8747193813323975,
      "learning_rate": 4.043366451341104e-05,
      "loss": 0.2957,
      "step": 21900
    },
    {
      "epoch": 0.5774492265600337,
      "grad_norm": 1.5902210474014282,
      "learning_rate": 4.041172237045359e-05,
      "loss": 0.295,
      "step": 21950
    },
    {
      "epoch": 0.5787646006524255,
      "grad_norm": 1.7989850044250488,
      "learning_rate": 4.038978022749614e-05,
      "loss": 0.2988,
      "step": 22000
    },
    {
      "epoch": 0.5800799747448174,
      "grad_norm": 1.977724313735962,
      "learning_rate": 4.0367838084538686e-05,
      "loss": 0.2937,
      "step": 22050
    },
    {
      "epoch": 0.5813953488372093,
      "grad_norm": 1.7031621932983398,
      "learning_rate": 4.034589594158124e-05,
      "loss": 0.2851,
      "step": 22100
    },
    {
      "epoch": 0.5827107229296011,
      "grad_norm": 1.8063592910766602,
      "learning_rate": 4.0323953798623795e-05,
      "loss": 0.2867,
      "step": 22150
    },
    {
      "epoch": 0.584026097021993,
      "grad_norm": 1.8131951093673706,
      "learning_rate": 4.0302011655666336e-05,
      "loss": 0.2947,
      "step": 22200
    },
    {
      "epoch": 0.585341471114385,
      "grad_norm": 1.6390182971954346,
      "learning_rate": 4.028006951270889e-05,
      "loss": 0.2901,
      "step": 22250
    },
    {
      "epoch": 0.5866568452067769,
      "grad_norm": 1.741796612739563,
      "learning_rate": 4.0258127369751444e-05,
      "loss": 0.296,
      "step": 22300
    },
    {
      "epoch": 0.5879722192991687,
      "grad_norm": 1.7350696325302124,
      "learning_rate": 4.023618522679399e-05,
      "loss": 0.2897,
      "step": 22350
    },
    {
      "epoch": 0.5892875933915606,
      "grad_norm": 1.6053788661956787,
      "learning_rate": 4.021424308383654e-05,
      "loss": 0.2879,
      "step": 22400
    },
    {
      "epoch": 0.5906029674839525,
      "grad_norm": 1.7896227836608887,
      "learning_rate": 4.019230094087909e-05,
      "loss": 0.28,
      "step": 22450
    },
    {
      "epoch": 0.5919183415763443,
      "grad_norm": 1.7559270858764648,
      "learning_rate": 4.017035879792164e-05,
      "loss": 0.2887,
      "step": 22500
    },
    {
      "epoch": 0.5932337156687362,
      "grad_norm": 1.8093796968460083,
      "learning_rate": 4.0148416654964195e-05,
      "loss": 0.2844,
      "step": 22550
    },
    {
      "epoch": 0.5945490897611281,
      "grad_norm": 1.6868606805801392,
      "learning_rate": 4.012647451200674e-05,
      "loss": 0.2831,
      "step": 22600
    },
    {
      "epoch": 0.59586446385352,
      "grad_norm": 1.7589584589004517,
      "learning_rate": 4.010453236904929e-05,
      "loss": 0.2856,
      "step": 22650
    },
    {
      "epoch": 0.5971798379459118,
      "grad_norm": 1.9359031915664673,
      "learning_rate": 4.0082590226091844e-05,
      "loss": 0.2891,
      "step": 22700
    },
    {
      "epoch": 0.5984952120383037,
      "grad_norm": 2.8088033199310303,
      "learning_rate": 4.006064808313439e-05,
      "loss": 0.2846,
      "step": 22750
    },
    {
      "epoch": 0.5998105861306956,
      "grad_norm": 1.894108533859253,
      "learning_rate": 4.0038705940176946e-05,
      "loss": 0.2793,
      "step": 22800
    },
    {
      "epoch": 0.6011259602230874,
      "grad_norm": 1.751092791557312,
      "learning_rate": 4.0016763797219493e-05,
      "loss": 0.2803,
      "step": 22850
    },
    {
      "epoch": 0.6024413343154793,
      "grad_norm": 1.7192211151123047,
      "learning_rate": 3.999482165426204e-05,
      "loss": 0.2828,
      "step": 22900
    },
    {
      "epoch": 0.6037567084078712,
      "grad_norm": 1.6474076509475708,
      "learning_rate": 3.9972879511304595e-05,
      "loss": 0.2846,
      "step": 22950
    },
    {
      "epoch": 0.6050720825002631,
      "grad_norm": 1.8290730714797974,
      "learning_rate": 3.995093736834715e-05,
      "loss": 0.2821,
      "step": 23000
    },
    {
      "epoch": 0.6063874565926549,
      "grad_norm": 1.806753158569336,
      "learning_rate": 3.992899522538969e-05,
      "loss": 0.2804,
      "step": 23050
    },
    {
      "epoch": 0.6077028306850468,
      "grad_norm": 1.9262745380401611,
      "learning_rate": 3.9907053082432244e-05,
      "loss": 0.2814,
      "step": 23100
    },
    {
      "epoch": 0.6090182047774387,
      "grad_norm": 1.6363719701766968,
      "learning_rate": 3.98851109394748e-05,
      "loss": 0.2782,
      "step": 23150
    },
    {
      "epoch": 0.6103335788698305,
      "grad_norm": 1.8463135957717896,
      "learning_rate": 3.9863168796517346e-05,
      "loss": 0.2765,
      "step": 23200
    },
    {
      "epoch": 0.6116489529622224,
      "grad_norm": 2.03164005279541,
      "learning_rate": 3.9841226653559894e-05,
      "loss": 0.2776,
      "step": 23250
    },
    {
      "epoch": 0.6129643270546143,
      "grad_norm": 1.5626400709152222,
      "learning_rate": 3.981928451060245e-05,
      "loss": 0.2677,
      "step": 23300
    },
    {
      "epoch": 0.6142797011470063,
      "grad_norm": 1.947798252105713,
      "learning_rate": 3.9797342367644995e-05,
      "loss": 0.2774,
      "step": 23350
    },
    {
      "epoch": 0.615595075239398,
      "grad_norm": 1.625463604927063,
      "learning_rate": 3.977540022468755e-05,
      "loss": 0.2704,
      "step": 23400
    },
    {
      "epoch": 0.61691044933179,
      "grad_norm": 1.5681054592132568,
      "learning_rate": 3.97534580817301e-05,
      "loss": 0.2714,
      "step": 23450
    },
    {
      "epoch": 0.6182258234241819,
      "grad_norm": 1.7852388620376587,
      "learning_rate": 3.9731515938772645e-05,
      "loss": 0.2711,
      "step": 23500
    },
    {
      "epoch": 0.6195411975165737,
      "grad_norm": 1.4078881740570068,
      "learning_rate": 3.97095737958152e-05,
      "loss": 0.2746,
      "step": 23550
    },
    {
      "epoch": 0.6208565716089656,
      "grad_norm": 1.5640877485275269,
      "learning_rate": 3.9687631652857746e-05,
      "loss": 0.2671,
      "step": 23600
    },
    {
      "epoch": 0.6221719457013575,
      "grad_norm": 1.6640186309814453,
      "learning_rate": 3.9665689509900294e-05,
      "loss": 0.261,
      "step": 23650
    },
    {
      "epoch": 0.6234873197937494,
      "grad_norm": 1.7863320112228394,
      "learning_rate": 3.964374736694285e-05,
      "loss": 0.2747,
      "step": 23700
    },
    {
      "epoch": 0.6248026938861412,
      "grad_norm": 1.6037942171096802,
      "learning_rate": 3.9621805223985396e-05,
      "loss": 0.2707,
      "step": 23750
    },
    {
      "epoch": 0.6261180679785331,
      "grad_norm": 1.6479965448379517,
      "learning_rate": 3.959986308102795e-05,
      "loss": 0.2676,
      "step": 23800
    },
    {
      "epoch": 0.627433442070925,
      "grad_norm": 1.6185556650161743,
      "learning_rate": 3.95779209380705e-05,
      "loss": 0.2645,
      "step": 23850
    },
    {
      "epoch": 0.6287488161633168,
      "grad_norm": 1.3490374088287354,
      "learning_rate": 3.9555978795113045e-05,
      "loss": 0.2625,
      "step": 23900
    },
    {
      "epoch": 0.6300641902557087,
      "grad_norm": 1.657771110534668,
      "learning_rate": 3.95340366521556e-05,
      "loss": 0.2689,
      "step": 23950
    },
    {
      "epoch": 0.6313795643481006,
      "grad_norm": 1.577375888824463,
      "learning_rate": 3.9512094509198147e-05,
      "loss": 0.2634,
      "step": 24000
    },
    {
      "epoch": 0.6326949384404925,
      "grad_norm": 1.6397147178649902,
      "learning_rate": 3.9490152366240694e-05,
      "loss": 0.2716,
      "step": 24050
    },
    {
      "epoch": 0.6340103125328843,
      "grad_norm": 1.5212535858154297,
      "learning_rate": 3.946821022328325e-05,
      "loss": 0.2675,
      "step": 24100
    },
    {
      "epoch": 0.6353256866252762,
      "grad_norm": 1.534789800643921,
      "learning_rate": 3.9446268080325796e-05,
      "loss": 0.263,
      "step": 24150
    },
    {
      "epoch": 0.6366410607176681,
      "grad_norm": 1.7704685926437378,
      "learning_rate": 3.942432593736835e-05,
      "loss": 0.2612,
      "step": 24200
    },
    {
      "epoch": 0.63795643481006,
      "grad_norm": 1.828250765800476,
      "learning_rate": 3.9402383794410904e-05,
      "loss": 0.2588,
      "step": 24250
    },
    {
      "epoch": 0.6392718089024518,
      "grad_norm": 1.942631483078003,
      "learning_rate": 3.9380441651453445e-05,
      "loss": 0.272,
      "step": 24300
    },
    {
      "epoch": 0.6405871829948437,
      "grad_norm": 1.6646497249603271,
      "learning_rate": 3.9358499508496e-05,
      "loss": 0.258,
      "step": 24350
    },
    {
      "epoch": 0.6419025570872356,
      "grad_norm": 1.5387128591537476,
      "learning_rate": 3.9336557365538554e-05,
      "loss": 0.2599,
      "step": 24400
    },
    {
      "epoch": 0.6432179311796274,
      "grad_norm": 1.5947591066360474,
      "learning_rate": 3.93146152225811e-05,
      "loss": 0.2627,
      "step": 24450
    },
    {
      "epoch": 0.6445333052720194,
      "grad_norm": 1.3537331819534302,
      "learning_rate": 3.929267307962365e-05,
      "loss": 0.2587,
      "step": 24500
    },
    {
      "epoch": 0.6458486793644113,
      "grad_norm": 1.4471116065979004,
      "learning_rate": 3.92707309366662e-05,
      "loss": 0.2607,
      "step": 24550
    },
    {
      "epoch": 0.6471640534568032,
      "grad_norm": 1.609311580657959,
      "learning_rate": 3.924878879370875e-05,
      "loss": 0.255,
      "step": 24600
    },
    {
      "epoch": 0.648479427549195,
      "grad_norm": 1.471428394317627,
      "learning_rate": 3.9226846650751305e-05,
      "loss": 0.2585,
      "step": 24650
    },
    {
      "epoch": 0.6497948016415869,
      "grad_norm": 1.441395878791809,
      "learning_rate": 3.920490450779385e-05,
      "loss": 0.2604,
      "step": 24700
    },
    {
      "epoch": 0.6511101757339788,
      "grad_norm": 1.6014147996902466,
      "learning_rate": 3.91829623648364e-05,
      "loss": 0.2582,
      "step": 24750
    },
    {
      "epoch": 0.6524255498263706,
      "grad_norm": 1.6770819425582886,
      "learning_rate": 3.9161020221878954e-05,
      "loss": 0.2572,
      "step": 24800
    },
    {
      "epoch": 0.6537409239187625,
      "grad_norm": 1.5048595666885376,
      "learning_rate": 3.91390780789215e-05,
      "loss": 0.2528,
      "step": 24850
    },
    {
      "epoch": 0.6550562980111544,
      "grad_norm": 1.6338516473770142,
      "learning_rate": 3.911713593596405e-05,
      "loss": 0.2601,
      "step": 24900
    },
    {
      "epoch": 0.6563716721035463,
      "grad_norm": 1.619634985923767,
      "learning_rate": 3.90951937930066e-05,
      "loss": 0.2611,
      "step": 24950
    },
    {
      "epoch": 0.6576870461959381,
      "grad_norm": 1.6954147815704346,
      "learning_rate": 3.907325165004915e-05,
      "loss": 0.2573,
      "step": 25000
    },
    {
      "epoch": 0.65900242028833,
      "grad_norm": 1.4420475959777832,
      "learning_rate": 3.9051309507091705e-05,
      "loss": 0.2534,
      "step": 25050
    },
    {
      "epoch": 0.6603177943807219,
      "grad_norm": 1.5518141984939575,
      "learning_rate": 3.902936736413425e-05,
      "loss": 0.2535,
      "step": 25100
    },
    {
      "epoch": 0.6616331684731137,
      "grad_norm": 1.3949103355407715,
      "learning_rate": 3.90074252211768e-05,
      "loss": 0.2512,
      "step": 25150
    },
    {
      "epoch": 0.6629485425655056,
      "grad_norm": 1.4094144105911255,
      "learning_rate": 3.8985483078219354e-05,
      "loss": 0.2501,
      "step": 25200
    },
    {
      "epoch": 0.6642639166578975,
      "grad_norm": 1.528144359588623,
      "learning_rate": 3.896354093526191e-05,
      "loss": 0.2513,
      "step": 25250
    },
    {
      "epoch": 0.6655792907502894,
      "grad_norm": 1.6837157011032104,
      "learning_rate": 3.894159879230445e-05,
      "loss": 0.246,
      "step": 25300
    },
    {
      "epoch": 0.6668946648426812,
      "grad_norm": 1.6290473937988281,
      "learning_rate": 3.8919656649347e-05,
      "loss": 0.2549,
      "step": 25350
    },
    {
      "epoch": 0.6682100389350731,
      "grad_norm": 1.598894715309143,
      "learning_rate": 3.889771450638956e-05,
      "loss": 0.2596,
      "step": 25400
    },
    {
      "epoch": 0.669525413027465,
      "grad_norm": 1.4909968376159668,
      "learning_rate": 3.8875772363432105e-05,
      "loss": 0.2511,
      "step": 25450
    },
    {
      "epoch": 0.6708407871198568,
      "grad_norm": 1.7484205961227417,
      "learning_rate": 3.885383022047465e-05,
      "loss": 0.2453,
      "step": 25500
    },
    {
      "epoch": 0.6721561612122487,
      "grad_norm": 1.5330302715301514,
      "learning_rate": 3.883188807751721e-05,
      "loss": 0.2464,
      "step": 25550
    },
    {
      "epoch": 0.6734715353046407,
      "grad_norm": 1.5516866445541382,
      "learning_rate": 3.8809945934559754e-05,
      "loss": 0.2556,
      "step": 25600
    },
    {
      "epoch": 0.6747869093970326,
      "grad_norm": 1.4336796998977661,
      "learning_rate": 3.878800379160231e-05,
      "loss": 0.2524,
      "step": 25650
    },
    {
      "epoch": 0.6761022834894244,
      "grad_norm": 1.3561077117919922,
      "learning_rate": 3.876606164864485e-05,
      "loss": 0.2532,
      "step": 25700
    },
    {
      "epoch": 0.6774176575818163,
      "grad_norm": 1.5972862243652344,
      "learning_rate": 3.87441195056874e-05,
      "loss": 0.2491,
      "step": 25750
    },
    {
      "epoch": 0.6787330316742082,
      "grad_norm": 1.6115376949310303,
      "learning_rate": 3.872217736272996e-05,
      "loss": 0.2485,
      "step": 25800
    },
    {
      "epoch": 0.6800484057666,
      "grad_norm": 1.505363941192627,
      "learning_rate": 3.8700235219772505e-05,
      "loss": 0.2442,
      "step": 25850
    },
    {
      "epoch": 0.6813637798589919,
      "grad_norm": 1.4930856227874756,
      "learning_rate": 3.867829307681506e-05,
      "loss": 0.2504,
      "step": 25900
    },
    {
      "epoch": 0.6826791539513838,
      "grad_norm": 1.516725778579712,
      "learning_rate": 3.865635093385761e-05,
      "loss": 0.2433,
      "step": 25950
    },
    {
      "epoch": 0.6839945280437757,
      "grad_norm": 1.289876103401184,
      "learning_rate": 3.8634408790900154e-05,
      "loss": 0.2467,
      "step": 26000
    },
    {
      "epoch": 0.6853099021361675,
      "grad_norm": 2.2135581970214844,
      "learning_rate": 3.861246664794271e-05,
      "loss": 0.243,
      "step": 26050
    },
    {
      "epoch": 0.6866252762285594,
      "grad_norm": 1.6540606021881104,
      "learning_rate": 3.8590524504985256e-05,
      "loss": 0.2394,
      "step": 26100
    },
    {
      "epoch": 0.6879406503209513,
      "grad_norm": 1.564978003501892,
      "learning_rate": 3.8568582362027804e-05,
      "loss": 0.2449,
      "step": 26150
    },
    {
      "epoch": 0.6892560244133431,
      "grad_norm": 1.5420438051223755,
      "learning_rate": 3.854664021907036e-05,
      "loss": 0.2421,
      "step": 26200
    },
    {
      "epoch": 0.690571398505735,
      "grad_norm": 1.3560776710510254,
      "learning_rate": 3.8524698076112905e-05,
      "loss": 0.2449,
      "step": 26250
    },
    {
      "epoch": 0.6918867725981269,
      "grad_norm": 1.3327021598815918,
      "learning_rate": 3.850275593315546e-05,
      "loss": 0.2424,
      "step": 26300
    },
    {
      "epoch": 0.6932021466905188,
      "grad_norm": 1.6014200448989868,
      "learning_rate": 3.848081379019801e-05,
      "loss": 0.2367,
      "step": 26350
    },
    {
      "epoch": 0.6945175207829106,
      "grad_norm": 1.259813666343689,
      "learning_rate": 3.8458871647240554e-05,
      "loss": 0.2412,
      "step": 26400
    },
    {
      "epoch": 0.6958328948753025,
      "grad_norm": 1.4896916151046753,
      "learning_rate": 3.843692950428311e-05,
      "loss": 0.2448,
      "step": 26450
    },
    {
      "epoch": 0.6971482689676944,
      "grad_norm": 1.3749687671661377,
      "learning_rate": 3.841498736132566e-05,
      "loss": 0.2367,
      "step": 26500
    },
    {
      "epoch": 0.6984636430600862,
      "grad_norm": 1.5548001527786255,
      "learning_rate": 3.8393045218368204e-05,
      "loss": 0.2413,
      "step": 26550
    },
    {
      "epoch": 0.6997790171524781,
      "grad_norm": 1.4649909734725952,
      "learning_rate": 3.837110307541076e-05,
      "loss": 0.2344,
      "step": 26600
    },
    {
      "epoch": 0.70109439124487,
      "grad_norm": 1.2575244903564453,
      "learning_rate": 3.834916093245331e-05,
      "loss": 0.2343,
      "step": 26650
    },
    {
      "epoch": 0.702409765337262,
      "grad_norm": 1.5206961631774902,
      "learning_rate": 3.832721878949586e-05,
      "loss": 0.2425,
      "step": 26700
    },
    {
      "epoch": 0.7037251394296538,
      "grad_norm": 1.4650866985321045,
      "learning_rate": 3.830527664653841e-05,
      "loss": 0.2386,
      "step": 26750
    },
    {
      "epoch": 0.7050405135220457,
      "grad_norm": 1.512247920036316,
      "learning_rate": 3.828333450358096e-05,
      "loss": 0.2384,
      "step": 26800
    },
    {
      "epoch": 0.7063558876144376,
      "grad_norm": 1.4857094287872314,
      "learning_rate": 3.826139236062351e-05,
      "loss": 0.2345,
      "step": 26850
    },
    {
      "epoch": 0.7076712617068294,
      "grad_norm": 1.304590106010437,
      "learning_rate": 3.823945021766606e-05,
      "loss": 0.2383,
      "step": 26900
    },
    {
      "epoch": 0.7089866357992213,
      "grad_norm": 1.5496232509613037,
      "learning_rate": 3.821750807470861e-05,
      "loss": 0.2432,
      "step": 26950
    },
    {
      "epoch": 0.7103020098916132,
      "grad_norm": 1.6933072805404663,
      "learning_rate": 3.819556593175116e-05,
      "loss": 0.2366,
      "step": 27000
    },
    {
      "epoch": 0.7116173839840051,
      "grad_norm": 1.4763221740722656,
      "learning_rate": 3.817362378879371e-05,
      "loss": 0.2381,
      "step": 27050
    },
    {
      "epoch": 0.7129327580763969,
      "grad_norm": 1.402864933013916,
      "learning_rate": 3.815168164583626e-05,
      "loss": 0.2395,
      "step": 27100
    },
    {
      "epoch": 0.7142481321687888,
      "grad_norm": 1.5428673028945923,
      "learning_rate": 3.812973950287881e-05,
      "loss": 0.233,
      "step": 27150
    },
    {
      "epoch": 0.7155635062611807,
      "grad_norm": 1.5514343976974487,
      "learning_rate": 3.810779735992136e-05,
      "loss": 0.2356,
      "step": 27200
    },
    {
      "epoch": 0.7168788803535725,
      "grad_norm": 1.481351613998413,
      "learning_rate": 3.808585521696391e-05,
      "loss": 0.2329,
      "step": 27250
    },
    {
      "epoch": 0.7181942544459644,
      "grad_norm": 1.3305065631866455,
      "learning_rate": 3.8063913074006463e-05,
      "loss": 0.2326,
      "step": 27300
    },
    {
      "epoch": 0.7195096285383563,
      "grad_norm": 1.5479484796524048,
      "learning_rate": 3.804197093104901e-05,
      "loss": 0.2302,
      "step": 27350
    },
    {
      "epoch": 0.7208250026307482,
      "grad_norm": 1.275923728942871,
      "learning_rate": 3.802002878809156e-05,
      "loss": 0.2345,
      "step": 27400
    },
    {
      "epoch": 0.72214037672314,
      "grad_norm": 1.5070092678070068,
      "learning_rate": 3.799808664513411e-05,
      "loss": 0.2346,
      "step": 27450
    },
    {
      "epoch": 0.7234557508155319,
      "grad_norm": 1.2950198650360107,
      "learning_rate": 3.797614450217667e-05,
      "loss": 0.2289,
      "step": 27500
    },
    {
      "epoch": 0.7247711249079238,
      "grad_norm": 1.5114476680755615,
      "learning_rate": 3.7954202359219214e-05,
      "loss": 0.2367,
      "step": 27550
    },
    {
      "epoch": 0.7260864990003157,
      "grad_norm": 1.6777265071868896,
      "learning_rate": 3.793226021626176e-05,
      "loss": 0.229,
      "step": 27600
    },
    {
      "epoch": 0.7274018730927075,
      "grad_norm": 1.5052834749221802,
      "learning_rate": 3.7910318073304316e-05,
      "loss": 0.2334,
      "step": 27650
    },
    {
      "epoch": 0.7287172471850994,
      "grad_norm": 1.3025734424591064,
      "learning_rate": 3.7888375930346864e-05,
      "loss": 0.2287,
      "step": 27700
    },
    {
      "epoch": 0.7300326212774914,
      "grad_norm": 1.3658720254898071,
      "learning_rate": 3.786643378738942e-05,
      "loss": 0.2337,
      "step": 27750
    },
    {
      "epoch": 0.7313479953698832,
      "grad_norm": 1.6001559495925903,
      "learning_rate": 3.784449164443196e-05,
      "loss": 0.2332,
      "step": 27800
    },
    {
      "epoch": 0.7326633694622751,
      "grad_norm": 1.6664940118789673,
      "learning_rate": 3.782254950147451e-05,
      "loss": 0.2224,
      "step": 27850
    },
    {
      "epoch": 0.733978743554667,
      "grad_norm": 1.4877828359603882,
      "learning_rate": 3.780060735851707e-05,
      "loss": 0.2276,
      "step": 27900
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 1.5198370218276978,
      "learning_rate": 3.7778665215559615e-05,
      "loss": 0.2348,
      "step": 27950
    },
    {
      "epoch": 0.7366094917394507,
      "grad_norm": 1.2868990898132324,
      "learning_rate": 3.775672307260216e-05,
      "loss": 0.2304,
      "step": 28000
    },
    {
      "epoch": 0.7379248658318426,
      "grad_norm": 1.9097658395767212,
      "learning_rate": 3.7734780929644716e-05,
      "loss": 0.229,
      "step": 28050
    },
    {
      "epoch": 0.7392402399242345,
      "grad_norm": 1.5354472398757935,
      "learning_rate": 3.7712838786687264e-05,
      "loss": 0.2328,
      "step": 28100
    },
    {
      "epoch": 0.7405556140166263,
      "grad_norm": 1.5528086423873901,
      "learning_rate": 3.769089664372982e-05,
      "loss": 0.23,
      "step": 28150
    },
    {
      "epoch": 0.7418709881090182,
      "grad_norm": 1.209334373474121,
      "learning_rate": 3.7668954500772366e-05,
      "loss": 0.2219,
      "step": 28200
    },
    {
      "epoch": 0.7431863622014101,
      "grad_norm": 1.4459067583084106,
      "learning_rate": 3.764701235781491e-05,
      "loss": 0.2249,
      "step": 28250
    },
    {
      "epoch": 0.744501736293802,
      "grad_norm": 1.399046778678894,
      "learning_rate": 3.762507021485747e-05,
      "loss": 0.2244,
      "step": 28300
    },
    {
      "epoch": 0.7458171103861938,
      "grad_norm": 1.1845703125,
      "learning_rate": 3.7603128071900015e-05,
      "loss": 0.2221,
      "step": 28350
    },
    {
      "epoch": 0.7471324844785857,
      "grad_norm": 1.4761308431625366,
      "learning_rate": 3.758118592894256e-05,
      "loss": 0.2261,
      "step": 28400
    },
    {
      "epoch": 0.7484478585709776,
      "grad_norm": 1.4994251728057861,
      "learning_rate": 3.7559243785985116e-05,
      "loss": 0.2259,
      "step": 28450
    },
    {
      "epoch": 0.7497632326633694,
      "grad_norm": 1.4318406581878662,
      "learning_rate": 3.7537301643027664e-05,
      "loss": 0.2259,
      "step": 28500
    },
    {
      "epoch": 0.7510786067557613,
      "grad_norm": 1.4317981004714966,
      "learning_rate": 3.751535950007022e-05,
      "loss": 0.2245,
      "step": 28550
    },
    {
      "epoch": 0.7523939808481532,
      "grad_norm": 1.5322518348693848,
      "learning_rate": 3.7493417357112766e-05,
      "loss": 0.2237,
      "step": 28600
    },
    {
      "epoch": 0.7537093549405451,
      "grad_norm": 1.423736572265625,
      "learning_rate": 3.747147521415531e-05,
      "loss": 0.2249,
      "step": 28650
    },
    {
      "epoch": 0.7550247290329369,
      "grad_norm": 1.3104647397994995,
      "learning_rate": 3.744953307119787e-05,
      "loss": 0.2285,
      "step": 28700
    },
    {
      "epoch": 0.7563401031253288,
      "grad_norm": 1.5418859720230103,
      "learning_rate": 3.742759092824042e-05,
      "loss": 0.2251,
      "step": 28750
    },
    {
      "epoch": 0.7576554772177208,
      "grad_norm": 1.4737013578414917,
      "learning_rate": 3.740564878528296e-05,
      "loss": 0.2193,
      "step": 28800
    },
    {
      "epoch": 0.7589708513101125,
      "grad_norm": 1.3537907600402832,
      "learning_rate": 3.738370664232552e-05,
      "loss": 0.2271,
      "step": 28850
    },
    {
      "epoch": 0.7602862254025045,
      "grad_norm": 1.589633822441101,
      "learning_rate": 3.736176449936807e-05,
      "loss": 0.2255,
      "step": 28900
    },
    {
      "epoch": 0.7616015994948964,
      "grad_norm": 1.4409420490264893,
      "learning_rate": 3.733982235641062e-05,
      "loss": 0.2218,
      "step": 28950
    },
    {
      "epoch": 0.7629169735872883,
      "grad_norm": 1.5808807611465454,
      "learning_rate": 3.7317880213453166e-05,
      "loss": 0.2211,
      "step": 29000
    },
    {
      "epoch": 0.7642323476796801,
      "grad_norm": 1.4966373443603516,
      "learning_rate": 3.729593807049572e-05,
      "loss": 0.2184,
      "step": 29050
    },
    {
      "epoch": 0.765547721772072,
      "grad_norm": 1.309859275817871,
      "learning_rate": 3.727399592753827e-05,
      "loss": 0.222,
      "step": 29100
    },
    {
      "epoch": 0.7668630958644639,
      "grad_norm": 1.1867746114730835,
      "learning_rate": 3.725205378458082e-05,
      "loss": 0.2223,
      "step": 29150
    },
    {
      "epoch": 0.7681784699568557,
      "grad_norm": 1.3319302797317505,
      "learning_rate": 3.723011164162337e-05,
      "loss": 0.2206,
      "step": 29200
    },
    {
      "epoch": 0.7694938440492476,
      "grad_norm": 1.1193069219589233,
      "learning_rate": 3.720816949866592e-05,
      "loss": 0.2241,
      "step": 29250
    },
    {
      "epoch": 0.7708092181416395,
      "grad_norm": 1.4509193897247314,
      "learning_rate": 3.718622735570847e-05,
      "loss": 0.2266,
      "step": 29300
    },
    {
      "epoch": 0.7721245922340314,
      "grad_norm": 1.372885823249817,
      "learning_rate": 3.716428521275102e-05,
      "loss": 0.2112,
      "step": 29350
    },
    {
      "epoch": 0.7734399663264232,
      "grad_norm": 1.4212762117385864,
      "learning_rate": 3.714234306979357e-05,
      "loss": 0.215,
      "step": 29400
    },
    {
      "epoch": 0.7747553404188151,
      "grad_norm": 1.5498815774917603,
      "learning_rate": 3.712040092683612e-05,
      "loss": 0.2193,
      "step": 29450
    },
    {
      "epoch": 0.776070714511207,
      "grad_norm": 1.4057356119155884,
      "learning_rate": 3.709845878387867e-05,
      "loss": 0.2175,
      "step": 29500
    },
    {
      "epoch": 0.7773860886035988,
      "grad_norm": 1.2793346643447876,
      "learning_rate": 3.707651664092122e-05,
      "loss": 0.2188,
      "step": 29550
    },
    {
      "epoch": 0.7787014626959907,
      "grad_norm": 1.5365190505981445,
      "learning_rate": 3.7054574497963776e-05,
      "loss": 0.2171,
      "step": 29600
    },
    {
      "epoch": 0.7800168367883826,
      "grad_norm": 1.5036096572875977,
      "learning_rate": 3.703263235500632e-05,
      "loss": 0.2153,
      "step": 29650
    },
    {
      "epoch": 0.7813322108807745,
      "grad_norm": 1.4750510454177856,
      "learning_rate": 3.701069021204887e-05,
      "loss": 0.2156,
      "step": 29700
    },
    {
      "epoch": 0.7826475849731663,
      "grad_norm": 1.2545689344406128,
      "learning_rate": 3.6988748069091426e-05,
      "loss": 0.2134,
      "step": 29750
    },
    {
      "epoch": 0.7839629590655582,
      "grad_norm": 1.0998144149780273,
      "learning_rate": 3.696680592613397e-05,
      "loss": 0.2151,
      "step": 29800
    },
    {
      "epoch": 0.7852783331579501,
      "grad_norm": 1.3475252389907837,
      "learning_rate": 3.694486378317652e-05,
      "loss": 0.2155,
      "step": 29850
    },
    {
      "epoch": 0.786593707250342,
      "grad_norm": 1.3635571002960205,
      "learning_rate": 3.6922921640219075e-05,
      "loss": 0.2134,
      "step": 29900
    },
    {
      "epoch": 0.7879090813427339,
      "grad_norm": 1.2907626628875732,
      "learning_rate": 3.690097949726162e-05,
      "loss": 0.2135,
      "step": 29950
    },
    {
      "epoch": 0.7892244554351258,
      "grad_norm": 1.3989061117172241,
      "learning_rate": 3.6879037354304177e-05,
      "loss": 0.2151,
      "step": 30000
    },
    {
      "epoch": 0.7905398295275177,
      "grad_norm": 1.3138611316680908,
      "learning_rate": 3.685709521134672e-05,
      "loss": 0.2171,
      "step": 30050
    },
    {
      "epoch": 0.7918552036199095,
      "grad_norm": 1.4526703357696533,
      "learning_rate": 3.683515306838927e-05,
      "loss": 0.2164,
      "step": 30100
    },
    {
      "epoch": 0.7931705777123014,
      "grad_norm": 1.5081337690353394,
      "learning_rate": 3.6813210925431826e-05,
      "loss": 0.2111,
      "step": 30150
    },
    {
      "epoch": 0.7944859518046933,
      "grad_norm": 1.2218352556228638,
      "learning_rate": 3.679126878247437e-05,
      "loss": 0.2094,
      "step": 30200
    },
    {
      "epoch": 0.7958013258970851,
      "grad_norm": 1.4066965579986572,
      "learning_rate": 3.676932663951692e-05,
      "loss": 0.2087,
      "step": 30250
    },
    {
      "epoch": 0.797116699989477,
      "grad_norm": 1.4382795095443726,
      "learning_rate": 3.6747384496559475e-05,
      "loss": 0.2124,
      "step": 30300
    },
    {
      "epoch": 0.7984320740818689,
      "grad_norm": 1.2626020908355713,
      "learning_rate": 3.672544235360202e-05,
      "loss": 0.2126,
      "step": 30350
    },
    {
      "epoch": 0.7997474481742608,
      "grad_norm": 1.2194044589996338,
      "learning_rate": 3.670350021064458e-05,
      "loss": 0.2143,
      "step": 30400
    },
    {
      "epoch": 0.8010628222666526,
      "grad_norm": 1.5255317687988281,
      "learning_rate": 3.6681558067687124e-05,
      "loss": 0.2102,
      "step": 30450
    },
    {
      "epoch": 0.8023781963590445,
      "grad_norm": 1.340876817703247,
      "learning_rate": 3.665961592472967e-05,
      "loss": 0.2089,
      "step": 30500
    },
    {
      "epoch": 0.8036935704514364,
      "grad_norm": 1.4102455377578735,
      "learning_rate": 3.6637673781772226e-05,
      "loss": 0.2092,
      "step": 30550
    },
    {
      "epoch": 0.8050089445438283,
      "grad_norm": 1.4836194515228271,
      "learning_rate": 3.6615731638814773e-05,
      "loss": 0.2088,
      "step": 30600
    },
    {
      "epoch": 0.8063243186362201,
      "grad_norm": 1.3274449110031128,
      "learning_rate": 3.659378949585732e-05,
      "loss": 0.2103,
      "step": 30650
    },
    {
      "epoch": 0.807639692728612,
      "grad_norm": 1.4111276865005493,
      "learning_rate": 3.6571847352899875e-05,
      "loss": 0.2138,
      "step": 30700
    },
    {
      "epoch": 0.8089550668210039,
      "grad_norm": 1.6452361345291138,
      "learning_rate": 3.654990520994242e-05,
      "loss": 0.2105,
      "step": 30750
    },
    {
      "epoch": 0.8102704409133957,
      "grad_norm": 1.4636495113372803,
      "learning_rate": 3.652796306698498e-05,
      "loss": 0.2099,
      "step": 30800
    },
    {
      "epoch": 0.8115858150057876,
      "grad_norm": 1.2849977016448975,
      "learning_rate": 3.650602092402753e-05,
      "loss": 0.205,
      "step": 30850
    },
    {
      "epoch": 0.8129011890981795,
      "grad_norm": 1.3005255460739136,
      "learning_rate": 3.648407878107007e-05,
      "loss": 0.2103,
      "step": 30900
    },
    {
      "epoch": 0.8142165631905715,
      "grad_norm": 1.5462877750396729,
      "learning_rate": 3.6462136638112626e-05,
      "loss": 0.2085,
      "step": 30950
    },
    {
      "epoch": 0.8155319372829632,
      "grad_norm": 1.3298474550247192,
      "learning_rate": 3.644019449515518e-05,
      "loss": 0.2087,
      "step": 31000
    },
    {
      "epoch": 0.8168473113753552,
      "grad_norm": 1.445278286933899,
      "learning_rate": 3.641825235219773e-05,
      "loss": 0.2061,
      "step": 31050
    },
    {
      "epoch": 0.8181626854677471,
      "grad_norm": 1.414857029914856,
      "learning_rate": 3.6396310209240275e-05,
      "loss": 0.2155,
      "step": 31100
    },
    {
      "epoch": 0.8194780595601389,
      "grad_norm": 1.205337643623352,
      "learning_rate": 3.637436806628283e-05,
      "loss": 0.207,
      "step": 31150
    },
    {
      "epoch": 0.8207934336525308,
      "grad_norm": 1.4612895250320435,
      "learning_rate": 3.635242592332538e-05,
      "loss": 0.212,
      "step": 31200
    },
    {
      "epoch": 0.8221088077449227,
      "grad_norm": 1.298245906829834,
      "learning_rate": 3.633048378036793e-05,
      "loss": 0.2103,
      "step": 31250
    },
    {
      "epoch": 0.8234241818373146,
      "grad_norm": 1.5288702249526978,
      "learning_rate": 3.630854163741048e-05,
      "loss": 0.2103,
      "step": 31300
    },
    {
      "epoch": 0.8247395559297064,
      "grad_norm": 1.259883165359497,
      "learning_rate": 3.6286599494453026e-05,
      "loss": 0.2053,
      "step": 31350
    },
    {
      "epoch": 0.8260549300220983,
      "grad_norm": 1.4051945209503174,
      "learning_rate": 3.626465735149558e-05,
      "loss": 0.2068,
      "step": 31400
    },
    {
      "epoch": 0.8273703041144902,
      "grad_norm": 1.3686202764511108,
      "learning_rate": 3.624271520853813e-05,
      "loss": 0.2065,
      "step": 31450
    },
    {
      "epoch": 0.828685678206882,
      "grad_norm": 1.242853045463562,
      "learning_rate": 3.6220773065580676e-05,
      "loss": 0.2051,
      "step": 31500
    },
    {
      "epoch": 0.8300010522992739,
      "grad_norm": 1.322052240371704,
      "learning_rate": 3.619883092262323e-05,
      "loss": 0.2067,
      "step": 31550
    },
    {
      "epoch": 0.8313164263916658,
      "grad_norm": 1.3101176023483276,
      "learning_rate": 3.617688877966578e-05,
      "loss": 0.2042,
      "step": 31600
    },
    {
      "epoch": 0.8326318004840577,
      "grad_norm": 1.33831787109375,
      "learning_rate": 3.615494663670833e-05,
      "loss": 0.2096,
      "step": 31650
    },
    {
      "epoch": 0.8339471745764495,
      "grad_norm": 1.0935665369033813,
      "learning_rate": 3.613300449375088e-05,
      "loss": 0.2015,
      "step": 31700
    },
    {
      "epoch": 0.8352625486688414,
      "grad_norm": 1.2025262117385864,
      "learning_rate": 3.6111062350793427e-05,
      "loss": 0.1976,
      "step": 31750
    },
    {
      "epoch": 0.8365779227612333,
      "grad_norm": 1.3160079717636108,
      "learning_rate": 3.608912020783598e-05,
      "loss": 0.2076,
      "step": 31800
    },
    {
      "epoch": 0.8378932968536251,
      "grad_norm": 1.4128391742706299,
      "learning_rate": 3.6067178064878535e-05,
      "loss": 0.2055,
      "step": 31850
    },
    {
      "epoch": 0.839208670946017,
      "grad_norm": 1.1828373670578003,
      "learning_rate": 3.6045235921921076e-05,
      "loss": 0.206,
      "step": 31900
    },
    {
      "epoch": 0.8405240450384089,
      "grad_norm": 1.3821349143981934,
      "learning_rate": 3.602329377896363e-05,
      "loss": 0.2098,
      "step": 31950
    },
    {
      "epoch": 0.8418394191308008,
      "grad_norm": 1.2148597240447998,
      "learning_rate": 3.6001351636006184e-05,
      "loss": 0.2113,
      "step": 32000
    },
    {
      "epoch": 0.8431547932231926,
      "grad_norm": 1.1587308645248413,
      "learning_rate": 3.597940949304873e-05,
      "loss": 0.2031,
      "step": 32050
    },
    {
      "epoch": 0.8444701673155846,
      "grad_norm": 1.1996526718139648,
      "learning_rate": 3.595746735009128e-05,
      "loss": 0.2062,
      "step": 32100
    },
    {
      "epoch": 0.8457855414079765,
      "grad_norm": 1.4276763200759888,
      "learning_rate": 3.593552520713383e-05,
      "loss": 0.2019,
      "step": 32150
    },
    {
      "epoch": 0.8471009155003683,
      "grad_norm": 1.317507028579712,
      "learning_rate": 3.591358306417638e-05,
      "loss": 0.2037,
      "step": 32200
    },
    {
      "epoch": 0.8484162895927602,
      "grad_norm": 1.2798491716384888,
      "learning_rate": 3.5891640921218935e-05,
      "loss": 0.2045,
      "step": 32250
    },
    {
      "epoch": 0.8497316636851521,
      "grad_norm": 1.3740891218185425,
      "learning_rate": 3.586969877826148e-05,
      "loss": 0.2065,
      "step": 32300
    },
    {
      "epoch": 0.851047037777544,
      "grad_norm": 1.2482198476791382,
      "learning_rate": 3.584775663530403e-05,
      "loss": 0.2031,
      "step": 32350
    },
    {
      "epoch": 0.8523624118699358,
      "grad_norm": 1.3078798055648804,
      "learning_rate": 3.5825814492346584e-05,
      "loss": 0.2051,
      "step": 32400
    },
    {
      "epoch": 0.8536777859623277,
      "grad_norm": 1.3674304485321045,
      "learning_rate": 3.580387234938913e-05,
      "loss": 0.197,
      "step": 32450
    },
    {
      "epoch": 0.8549931600547196,
      "grad_norm": 1.21657133102417,
      "learning_rate": 3.5781930206431686e-05,
      "loss": 0.2013,
      "step": 32500
    },
    {
      "epoch": 0.8563085341471114,
      "grad_norm": 1.2016575336456299,
      "learning_rate": 3.5759988063474234e-05,
      "loss": 0.2073,
      "step": 32550
    },
    {
      "epoch": 0.8576239082395033,
      "grad_norm": 1.3549972772598267,
      "learning_rate": 3.573804592051678e-05,
      "loss": 0.2024,
      "step": 32600
    },
    {
      "epoch": 0.8589392823318952,
      "grad_norm": 1.557024359703064,
      "learning_rate": 3.5716103777559335e-05,
      "loss": 0.2033,
      "step": 32650
    },
    {
      "epoch": 0.8602546564242871,
      "grad_norm": 1.239909291267395,
      "learning_rate": 3.569416163460188e-05,
      "loss": 0.1998,
      "step": 32700
    },
    {
      "epoch": 0.8615700305166789,
      "grad_norm": 1.2465022802352905,
      "learning_rate": 3.567221949164443e-05,
      "loss": 0.2028,
      "step": 32750
    },
    {
      "epoch": 0.8628854046090708,
      "grad_norm": 1.3709639310836792,
      "learning_rate": 3.5650277348686985e-05,
      "loss": 0.2065,
      "step": 32800
    },
    {
      "epoch": 0.8642007787014627,
      "grad_norm": 1.2136300802230835,
      "learning_rate": 3.562833520572953e-05,
      "loss": 0.1979,
      "step": 32850
    },
    {
      "epoch": 0.8655161527938545,
      "grad_norm": 1.2808932065963745,
      "learning_rate": 3.5606393062772086e-05,
      "loss": 0.2038,
      "step": 32900
    },
    {
      "epoch": 0.8668315268862464,
      "grad_norm": 1.2611876726150513,
      "learning_rate": 3.5584450919814634e-05,
      "loss": 0.1982,
      "step": 32950
    },
    {
      "epoch": 0.8681469009786383,
      "grad_norm": 1.3160368204116821,
      "learning_rate": 3.556250877685718e-05,
      "loss": 0.2004,
      "step": 33000
    },
    {
      "epoch": 0.8694622750710302,
      "grad_norm": 1.3118915557861328,
      "learning_rate": 3.5540566633899736e-05,
      "loss": 0.1984,
      "step": 33050
    },
    {
      "epoch": 0.870777649163422,
      "grad_norm": 1.347971796989441,
      "learning_rate": 3.551862449094229e-05,
      "loss": 0.2031,
      "step": 33100
    },
    {
      "epoch": 0.872093023255814,
      "grad_norm": 1.2347850799560547,
      "learning_rate": 3.549668234798483e-05,
      "loss": 0.1935,
      "step": 33150
    },
    {
      "epoch": 0.8734083973482059,
      "grad_norm": 1.2981187105178833,
      "learning_rate": 3.5474740205027385e-05,
      "loss": 0.2007,
      "step": 33200
    },
    {
      "epoch": 0.8747237714405977,
      "grad_norm": 1.3842333555221558,
      "learning_rate": 3.545279806206994e-05,
      "loss": 0.2021,
      "step": 33250
    },
    {
      "epoch": 0.8760391455329896,
      "grad_norm": 1.047545313835144,
      "learning_rate": 3.5430855919112487e-05,
      "loss": 0.1983,
      "step": 33300
    },
    {
      "epoch": 0.8773545196253815,
      "grad_norm": 1.223337173461914,
      "learning_rate": 3.5408913776155034e-05,
      "loss": 0.1996,
      "step": 33350
    },
    {
      "epoch": 0.8786698937177734,
      "grad_norm": 1.3049265146255493,
      "learning_rate": 3.538697163319759e-05,
      "loss": 0.1997,
      "step": 33400
    },
    {
      "epoch": 0.8799852678101652,
      "grad_norm": 1.3683602809906006,
      "learning_rate": 3.5365029490240136e-05,
      "loss": 0.1994,
      "step": 33450
    },
    {
      "epoch": 0.8813006419025571,
      "grad_norm": 1.3818162679672241,
      "learning_rate": 3.534308734728269e-05,
      "loss": 0.2014,
      "step": 33500
    },
    {
      "epoch": 0.882616015994949,
      "grad_norm": 1.372527837753296,
      "learning_rate": 3.532114520432524e-05,
      "loss": 0.2052,
      "step": 33550
    },
    {
      "epoch": 0.8839313900873408,
      "grad_norm": 1.563276767730713,
      "learning_rate": 3.5299203061367785e-05,
      "loss": 0.1942,
      "step": 33600
    },
    {
      "epoch": 0.8852467641797327,
      "grad_norm": 1.0585793256759644,
      "learning_rate": 3.527726091841034e-05,
      "loss": 0.1931,
      "step": 33650
    },
    {
      "epoch": 0.8865621382721246,
      "grad_norm": 1.1828054189682007,
      "learning_rate": 3.525531877545289e-05,
      "loss": 0.1942,
      "step": 33700
    },
    {
      "epoch": 0.8878775123645165,
      "grad_norm": 1.0284289121627808,
      "learning_rate": 3.5233376632495434e-05,
      "loss": 0.1934,
      "step": 33750
    },
    {
      "epoch": 0.8891928864569083,
      "grad_norm": 1.4205950498580933,
      "learning_rate": 3.521143448953799e-05,
      "loss": 0.1935,
      "step": 33800
    },
    {
      "epoch": 0.8905082605493002,
      "grad_norm": 1.1342103481292725,
      "learning_rate": 3.5189492346580536e-05,
      "loss": 0.1937,
      "step": 33850
    },
    {
      "epoch": 0.8918236346416921,
      "grad_norm": 1.0391541719436646,
      "learning_rate": 3.516755020362309e-05,
      "loss": 0.1941,
      "step": 33900
    },
    {
      "epoch": 0.893139008734084,
      "grad_norm": 1.195397138595581,
      "learning_rate": 3.5145608060665644e-05,
      "loss": 0.1923,
      "step": 33950
    },
    {
      "epoch": 0.8944543828264758,
      "grad_norm": 1.1887108087539673,
      "learning_rate": 3.5123665917708185e-05,
      "loss": 0.1974,
      "step": 34000
    },
    {
      "epoch": 0.8957697569188677,
      "grad_norm": 1.2915072441101074,
      "learning_rate": 3.510172377475074e-05,
      "loss": 0.1956,
      "step": 34050
    },
    {
      "epoch": 0.8970851310112596,
      "grad_norm": 1.249222993850708,
      "learning_rate": 3.5079781631793294e-05,
      "loss": 0.1965,
      "step": 34100
    },
    {
      "epoch": 0.8984005051036514,
      "grad_norm": 0.9826666712760925,
      "learning_rate": 3.505783948883584e-05,
      "loss": 0.1923,
      "step": 34150
    },
    {
      "epoch": 0.8997158791960433,
      "grad_norm": 1.3113675117492676,
      "learning_rate": 3.503589734587839e-05,
      "loss": 0.1913,
      "step": 34200
    },
    {
      "epoch": 0.9010312532884353,
      "grad_norm": 1.0489717721939087,
      "learning_rate": 3.5013955202920936e-05,
      "loss": 0.1932,
      "step": 34250
    },
    {
      "epoch": 0.9023466273808272,
      "grad_norm": 1.1398568153381348,
      "learning_rate": 3.499201305996349e-05,
      "loss": 0.1928,
      "step": 34300
    },
    {
      "epoch": 0.903662001473219,
      "grad_norm": 1.3217543363571167,
      "learning_rate": 3.4970070917006045e-05,
      "loss": 0.1934,
      "step": 34350
    },
    {
      "epoch": 0.9049773755656109,
      "grad_norm": 1.261696696281433,
      "learning_rate": 3.4948128774048585e-05,
      "loss": 0.1911,
      "step": 34400
    },
    {
      "epoch": 0.9062927496580028,
      "grad_norm": 1.248612403869629,
      "learning_rate": 3.492618663109114e-05,
      "loss": 0.1928,
      "step": 34450
    },
    {
      "epoch": 0.9076081237503946,
      "grad_norm": 1.1871839761734009,
      "learning_rate": 3.4904244488133694e-05,
      "loss": 0.1917,
      "step": 34500
    },
    {
      "epoch": 0.9089234978427865,
      "grad_norm": 1.3049687147140503,
      "learning_rate": 3.488230234517624e-05,
      "loss": 0.1934,
      "step": 34550
    },
    {
      "epoch": 0.9102388719351784,
      "grad_norm": 1.2583932876586914,
      "learning_rate": 3.486036020221879e-05,
      "loss": 0.1935,
      "step": 34600
    },
    {
      "epoch": 0.9115542460275703,
      "grad_norm": 1.0998022556304932,
      "learning_rate": 3.483841805926134e-05,
      "loss": 0.1926,
      "step": 34650
    },
    {
      "epoch": 0.9128696201199621,
      "grad_norm": 1.1814453601837158,
      "learning_rate": 3.481647591630389e-05,
      "loss": 0.1903,
      "step": 34700
    },
    {
      "epoch": 0.914184994212354,
      "grad_norm": 1.2882890701293945,
      "learning_rate": 3.4794533773346445e-05,
      "loss": 0.1935,
      "step": 34750
    },
    {
      "epoch": 0.9155003683047459,
      "grad_norm": 1.0318336486816406,
      "learning_rate": 3.477259163038899e-05,
      "loss": 0.1956,
      "step": 34800
    },
    {
      "epoch": 0.9168157423971377,
      "grad_norm": 1.1288602352142334,
      "learning_rate": 3.475064948743154e-05,
      "loss": 0.1928,
      "step": 34850
    },
    {
      "epoch": 0.9181311164895296,
      "grad_norm": 1.3140262365341187,
      "learning_rate": 3.4728707344474094e-05,
      "loss": 0.1893,
      "step": 34900
    },
    {
      "epoch": 0.9194464905819215,
      "grad_norm": 1.262315273284912,
      "learning_rate": 3.470676520151664e-05,
      "loss": 0.1943,
      "step": 34950
    },
    {
      "epoch": 0.9207618646743134,
      "grad_norm": 1.3068312406539917,
      "learning_rate": 3.468482305855919e-05,
      "loss": 0.1919,
      "step": 35000
    },
    {
      "epoch": 0.9220772387667052,
      "grad_norm": 1.2146130800247192,
      "learning_rate": 3.466288091560174e-05,
      "loss": 0.1889,
      "step": 35050
    },
    {
      "epoch": 0.9233926128590971,
      "grad_norm": 1.3800610303878784,
      "learning_rate": 3.464093877264429e-05,
      "loss": 0.1909,
      "step": 35100
    },
    {
      "epoch": 0.924707986951489,
      "grad_norm": 1.3551758527755737,
      "learning_rate": 3.4618996629686845e-05,
      "loss": 0.1902,
      "step": 35150
    },
    {
      "epoch": 0.9260233610438808,
      "grad_norm": 1.7657475471496582,
      "learning_rate": 3.459705448672939e-05,
      "loss": 0.1903,
      "step": 35200
    },
    {
      "epoch": 0.9273387351362727,
      "grad_norm": 1.0584728717803955,
      "learning_rate": 3.457511234377194e-05,
      "loss": 0.1908,
      "step": 35250
    },
    {
      "epoch": 0.9286541092286646,
      "grad_norm": 1.3232899904251099,
      "learning_rate": 3.4553170200814494e-05,
      "loss": 0.1931,
      "step": 35300
    },
    {
      "epoch": 0.9299694833210566,
      "grad_norm": 1.0142565965652466,
      "learning_rate": 3.453122805785705e-05,
      "loss": 0.1854,
      "step": 35350
    },
    {
      "epoch": 0.9312848574134484,
      "grad_norm": 1.2711678743362427,
      "learning_rate": 3.450928591489959e-05,
      "loss": 0.1819,
      "step": 35400
    },
    {
      "epoch": 0.9326002315058403,
      "grad_norm": 1.08943772315979,
      "learning_rate": 3.4487343771942144e-05,
      "loss": 0.1911,
      "step": 35450
    },
    {
      "epoch": 0.9339156055982322,
      "grad_norm": 1.5161677598953247,
      "learning_rate": 3.44654016289847e-05,
      "loss": 0.192,
      "step": 35500
    },
    {
      "epoch": 0.935230979690624,
      "grad_norm": 1.3469947576522827,
      "learning_rate": 3.4443459486027245e-05,
      "loss": 0.1897,
      "step": 35550
    },
    {
      "epoch": 0.9365463537830159,
      "grad_norm": 1.162487268447876,
      "learning_rate": 3.44215173430698e-05,
      "loss": 0.1896,
      "step": 35600
    },
    {
      "epoch": 0.9378617278754078,
      "grad_norm": 1.3664369583129883,
      "learning_rate": 3.439957520011235e-05,
      "loss": 0.1889,
      "step": 35650
    },
    {
      "epoch": 0.9391771019677997,
      "grad_norm": 1.3918752670288086,
      "learning_rate": 3.4377633057154894e-05,
      "loss": 0.1881,
      "step": 35700
    },
    {
      "epoch": 0.9404924760601915,
      "grad_norm": 1.1998114585876465,
      "learning_rate": 3.435569091419745e-05,
      "loss": 0.1855,
      "step": 35750
    },
    {
      "epoch": 0.9418078501525834,
      "grad_norm": 1.252682089805603,
      "learning_rate": 3.4333748771239996e-05,
      "loss": 0.1892,
      "step": 35800
    },
    {
      "epoch": 0.9431232242449753,
      "grad_norm": 0.971422016620636,
      "learning_rate": 3.4311806628282544e-05,
      "loss": 0.1883,
      "step": 35850
    },
    {
      "epoch": 0.9444385983373671,
      "grad_norm": 1.2468091249465942,
      "learning_rate": 3.42898644853251e-05,
      "loss": 0.1873,
      "step": 35900
    },
    {
      "epoch": 0.945753972429759,
      "grad_norm": 1.2218097448349,
      "learning_rate": 3.4267922342367645e-05,
      "loss": 0.1873,
      "step": 35950
    },
    {
      "epoch": 0.9470693465221509,
      "grad_norm": 1.0063563585281372,
      "learning_rate": 3.42459801994102e-05,
      "loss": 0.1783,
      "step": 36000
    },
    {
      "epoch": 0.9483847206145428,
      "grad_norm": 1.2725980281829834,
      "learning_rate": 3.422403805645275e-05,
      "loss": 0.1875,
      "step": 36050
    },
    {
      "epoch": 0.9497000947069346,
      "grad_norm": 1.2903658151626587,
      "learning_rate": 3.4202095913495295e-05,
      "loss": 0.19,
      "step": 36100
    },
    {
      "epoch": 0.9510154687993265,
      "grad_norm": 1.109824776649475,
      "learning_rate": 3.418015377053785e-05,
      "loss": 0.193,
      "step": 36150
    },
    {
      "epoch": 0.9523308428917184,
      "grad_norm": 1.200801968574524,
      "learning_rate": 3.41582116275804e-05,
      "loss": 0.1893,
      "step": 36200
    },
    {
      "epoch": 0.9536462169841102,
      "grad_norm": 1.2068402767181396,
      "learning_rate": 3.4136269484622944e-05,
      "loss": 0.1883,
      "step": 36250
    },
    {
      "epoch": 0.9549615910765021,
      "grad_norm": 1.3524584770202637,
      "learning_rate": 3.41143273416655e-05,
      "loss": 0.1805,
      "step": 36300
    },
    {
      "epoch": 0.956276965168894,
      "grad_norm": 1.0126203298568726,
      "learning_rate": 3.4092385198708046e-05,
      "loss": 0.1817,
      "step": 36350
    },
    {
      "epoch": 0.957592339261286,
      "grad_norm": 1.2051589488983154,
      "learning_rate": 3.40704430557506e-05,
      "loss": 0.1846,
      "step": 36400
    },
    {
      "epoch": 0.9589077133536777,
      "grad_norm": 1.188600778579712,
      "learning_rate": 3.404850091279315e-05,
      "loss": 0.1841,
      "step": 36450
    },
    {
      "epoch": 0.9602230874460697,
      "grad_norm": 1.2156893014907837,
      "learning_rate": 3.4026558769835695e-05,
      "loss": 0.184,
      "step": 36500
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 1.171922206878662,
      "learning_rate": 3.400461662687825e-05,
      "loss": 0.1843,
      "step": 36550
    },
    {
      "epoch": 0.9628538356308534,
      "grad_norm": 1.25690758228302,
      "learning_rate": 3.39826744839208e-05,
      "loss": 0.1873,
      "step": 36600
    },
    {
      "epoch": 0.9641692097232453,
      "grad_norm": 1.158801555633545,
      "learning_rate": 3.3960732340963344e-05,
      "loss": 0.1823,
      "step": 36650
    },
    {
      "epoch": 0.9654845838156372,
      "grad_norm": 1.0365734100341797,
      "learning_rate": 3.39387901980059e-05,
      "loss": 0.1858,
      "step": 36700
    },
    {
      "epoch": 0.9667999579080291,
      "grad_norm": 1.1824887990951538,
      "learning_rate": 3.391684805504845e-05,
      "loss": 0.1796,
      "step": 36750
    },
    {
      "epoch": 0.9681153320004209,
      "grad_norm": 1.1878081560134888,
      "learning_rate": 3.3894905912091e-05,
      "loss": 0.1809,
      "step": 36800
    },
    {
      "epoch": 0.9694307060928128,
      "grad_norm": 1.0375075340270996,
      "learning_rate": 3.387296376913355e-05,
      "loss": 0.1907,
      "step": 36850
    },
    {
      "epoch": 0.9707460801852047,
      "grad_norm": 1.112040638923645,
      "learning_rate": 3.38510216261761e-05,
      "loss": 0.1825,
      "step": 36900
    },
    {
      "epoch": 0.9720614542775966,
      "grad_norm": 1.159608244895935,
      "learning_rate": 3.382907948321865e-05,
      "loss": 0.183,
      "step": 36950
    },
    {
      "epoch": 0.9733768283699884,
      "grad_norm": 1.2944369316101074,
      "learning_rate": 3.3807137340261204e-05,
      "loss": 0.1818,
      "step": 37000
    },
    {
      "epoch": 0.9746922024623803,
      "grad_norm": 1.2007259130477905,
      "learning_rate": 3.378519519730375e-05,
      "loss": 0.1806,
      "step": 37050
    },
    {
      "epoch": 0.9760075765547722,
      "grad_norm": 0.9759324789047241,
      "learning_rate": 3.37632530543463e-05,
      "loss": 0.1824,
      "step": 37100
    },
    {
      "epoch": 0.977322950647164,
      "grad_norm": 1.0390849113464355,
      "learning_rate": 3.374131091138885e-05,
      "loss": 0.1839,
      "step": 37150
    },
    {
      "epoch": 0.9786383247395559,
      "grad_norm": 1.0453037023544312,
      "learning_rate": 3.37193687684314e-05,
      "loss": 0.1828,
      "step": 37200
    },
    {
      "epoch": 0.9799536988319478,
      "grad_norm": 1.1156375408172607,
      "learning_rate": 3.3697426625473955e-05,
      "loss": 0.1845,
      "step": 37250
    },
    {
      "epoch": 0.9812690729243397,
      "grad_norm": 1.3912349939346313,
      "learning_rate": 3.36754844825165e-05,
      "loss": 0.1864,
      "step": 37300
    },
    {
      "epoch": 0.9825844470167315,
      "grad_norm": 1.2116177082061768,
      "learning_rate": 3.365354233955905e-05,
      "loss": 0.1809,
      "step": 37350
    },
    {
      "epoch": 0.9838998211091234,
      "grad_norm": 0.9651437997817993,
      "learning_rate": 3.3631600196601604e-05,
      "loss": 0.1826,
      "step": 37400
    },
    {
      "epoch": 0.9852151952015153,
      "grad_norm": 1.1004703044891357,
      "learning_rate": 3.360965805364416e-05,
      "loss": 0.1861,
      "step": 37450
    },
    {
      "epoch": 0.9865305692939071,
      "grad_norm": 1.1253503561019897,
      "learning_rate": 3.35877159106867e-05,
      "loss": 0.1794,
      "step": 37500
    },
    {
      "epoch": 0.987845943386299,
      "grad_norm": 1.036530613899231,
      "learning_rate": 3.356577376772925e-05,
      "loss": 0.1831,
      "step": 37550
    },
    {
      "epoch": 0.989161317478691,
      "grad_norm": 1.0404479503631592,
      "learning_rate": 3.354383162477181e-05,
      "loss": 0.1833,
      "step": 37600
    },
    {
      "epoch": 0.9904766915710829,
      "grad_norm": 0.8470432758331299,
      "learning_rate": 3.3521889481814355e-05,
      "loss": 0.1813,
      "step": 37650
    },
    {
      "epoch": 0.9917920656634747,
      "grad_norm": 1.0628939867019653,
      "learning_rate": 3.34999473388569e-05,
      "loss": 0.1781,
      "step": 37700
    },
    {
      "epoch": 0.9931074397558666,
      "grad_norm": 1.092995524406433,
      "learning_rate": 3.3478005195899456e-05,
      "loss": 0.1839,
      "step": 37750
    },
    {
      "epoch": 0.9944228138482585,
      "grad_norm": 1.1659321784973145,
      "learning_rate": 3.3456063052942004e-05,
      "loss": 0.1764,
      "step": 37800
    },
    {
      "epoch": 0.9957381879406503,
      "grad_norm": 1.166887879371643,
      "learning_rate": 3.343412090998456e-05,
      "loss": 0.1792,
      "step": 37850
    },
    {
      "epoch": 0.9970535620330422,
      "grad_norm": 1.1123865842819214,
      "learning_rate": 3.3412178767027106e-05,
      "loss": 0.1792,
      "step": 37900
    },
    {
      "epoch": 0.9983689361254341,
      "grad_norm": 1.1532608270645142,
      "learning_rate": 3.339023662406965e-05,
      "loss": 0.1825,
      "step": 37950
    },
    {
      "epoch": 0.999684310217826,
      "grad_norm": 1.1581355333328247,
      "learning_rate": 3.336829448111221e-05,
      "loss": 0.1844,
      "step": 38000
    },
    {
      "epoch": 1.0,
      "eval_loss": 7.296446323394775,
      "eval_runtime": 224.39,
      "eval_samples_per_second": 150.074,
      "eval_steps_per_second": 18.762,
      "step": 38012
    },
    {
      "epoch": 1.0009996843102178,
      "grad_norm": 1.201670527458191,
      "learning_rate": 3.3346352338154755e-05,
      "loss": 0.1735,
      "step": 38050
    },
    {
      "epoch": 1.0023150584026097,
      "grad_norm": 1.2556730508804321,
      "learning_rate": 3.33244101951973e-05,
      "loss": 0.1746,
      "step": 38100
    },
    {
      "epoch": 1.0036304324950016,
      "grad_norm": 1.433695673942566,
      "learning_rate": 3.330246805223986e-05,
      "loss": 0.1797,
      "step": 38150
    },
    {
      "epoch": 1.0049458065873935,
      "grad_norm": 1.125531554222107,
      "learning_rate": 3.3280525909282404e-05,
      "loss": 0.1717,
      "step": 38200
    },
    {
      "epoch": 1.0062611806797854,
      "grad_norm": 1.4191380739212036,
      "learning_rate": 3.325858376632496e-05,
      "loss": 0.1722,
      "step": 38250
    },
    {
      "epoch": 1.0075765547721771,
      "grad_norm": 1.1148126125335693,
      "learning_rate": 3.3236641623367506e-05,
      "loss": 0.1723,
      "step": 38300
    },
    {
      "epoch": 1.008891928864569,
      "grad_norm": 0.9763450026512146,
      "learning_rate": 3.321469948041005e-05,
      "loss": 0.1748,
      "step": 38350
    },
    {
      "epoch": 1.010207302956961,
      "grad_norm": 1.0491636991500854,
      "learning_rate": 3.319275733745261e-05,
      "loss": 0.1743,
      "step": 38400
    },
    {
      "epoch": 1.0115226770493528,
      "grad_norm": 1.3364648818969727,
      "learning_rate": 3.3170815194495155e-05,
      "loss": 0.1743,
      "step": 38450
    },
    {
      "epoch": 1.0128380511417447,
      "grad_norm": 1.0690538883209229,
      "learning_rate": 3.31488730515377e-05,
      "loss": 0.1753,
      "step": 38500
    },
    {
      "epoch": 1.0141534252341367,
      "grad_norm": 0.9704387784004211,
      "learning_rate": 3.312693090858026e-05,
      "loss": 0.1746,
      "step": 38550
    },
    {
      "epoch": 1.0154687993265286,
      "grad_norm": 1.211246132850647,
      "learning_rate": 3.3104988765622804e-05,
      "loss": 0.1719,
      "step": 38600
    },
    {
      "epoch": 1.0167841734189202,
      "grad_norm": 1.0334097146987915,
      "learning_rate": 3.308304662266536e-05,
      "loss": 0.1708,
      "step": 38650
    },
    {
      "epoch": 1.0180995475113122,
      "grad_norm": 1.1910300254821777,
      "learning_rate": 3.3061104479707906e-05,
      "loss": 0.1712,
      "step": 38700
    },
    {
      "epoch": 1.019414921603704,
      "grad_norm": 1.1408567428588867,
      "learning_rate": 3.3039162336750454e-05,
      "loss": 0.1708,
      "step": 38750
    },
    {
      "epoch": 1.020730295696096,
      "grad_norm": 1.1719821691513062,
      "learning_rate": 3.301722019379301e-05,
      "loss": 0.1713,
      "step": 38800
    },
    {
      "epoch": 1.0220456697884879,
      "grad_norm": 1.1365604400634766,
      "learning_rate": 3.299527805083556e-05,
      "loss": 0.1716,
      "step": 38850
    },
    {
      "epoch": 1.0233610438808798,
      "grad_norm": 0.9706376791000366,
      "learning_rate": 3.297333590787811e-05,
      "loss": 0.1714,
      "step": 38900
    },
    {
      "epoch": 1.0246764179732717,
      "grad_norm": 1.317041277885437,
      "learning_rate": 3.295139376492066e-05,
      "loss": 0.1743,
      "step": 38950
    },
    {
      "epoch": 1.0259917920656634,
      "grad_norm": 0.9003663063049316,
      "learning_rate": 3.292945162196321e-05,
      "loss": 0.1672,
      "step": 39000
    },
    {
      "epoch": 1.0273071661580553,
      "grad_norm": 1.2567710876464844,
      "learning_rate": 3.290750947900576e-05,
      "loss": 0.1713,
      "step": 39050
    },
    {
      "epoch": 1.0286225402504472,
      "grad_norm": 1.2091902494430542,
      "learning_rate": 3.288556733604831e-05,
      "loss": 0.1746,
      "step": 39100
    },
    {
      "epoch": 1.029937914342839,
      "grad_norm": 1.1326812505722046,
      "learning_rate": 3.286362519309086e-05,
      "loss": 0.1713,
      "step": 39150
    },
    {
      "epoch": 1.031253288435231,
      "grad_norm": 1.3144848346710205,
      "learning_rate": 3.284168305013341e-05,
      "loss": 0.1728,
      "step": 39200
    },
    {
      "epoch": 1.032568662527623,
      "grad_norm": 1.3224029541015625,
      "learning_rate": 3.281974090717596e-05,
      "loss": 0.1707,
      "step": 39250
    },
    {
      "epoch": 1.0338840366200148,
      "grad_norm": 1.083817481994629,
      "learning_rate": 3.279779876421851e-05,
      "loss": 0.1698,
      "step": 39300
    },
    {
      "epoch": 1.0351994107124065,
      "grad_norm": 1.207207202911377,
      "learning_rate": 3.277585662126106e-05,
      "loss": 0.1678,
      "step": 39350
    },
    {
      "epoch": 1.0365147848047984,
      "grad_norm": 1.1478729248046875,
      "learning_rate": 3.275391447830361e-05,
      "loss": 0.1718,
      "step": 39400
    },
    {
      "epoch": 1.0378301588971903,
      "grad_norm": 0.9564632177352905,
      "learning_rate": 3.273197233534616e-05,
      "loss": 0.176,
      "step": 39450
    },
    {
      "epoch": 1.0391455329895822,
      "grad_norm": 1.2616506814956665,
      "learning_rate": 3.271003019238871e-05,
      "loss": 0.1687,
      "step": 39500
    },
    {
      "epoch": 1.0404609070819741,
      "grad_norm": 1.0794907808303833,
      "learning_rate": 3.268808804943126e-05,
      "loss": 0.1693,
      "step": 39550
    },
    {
      "epoch": 1.041776281174366,
      "grad_norm": 1.0350213050842285,
      "learning_rate": 3.266614590647381e-05,
      "loss": 0.1698,
      "step": 39600
    },
    {
      "epoch": 1.043091655266758,
      "grad_norm": 1.1738402843475342,
      "learning_rate": 3.264420376351636e-05,
      "loss": 0.1707,
      "step": 39650
    },
    {
      "epoch": 1.0444070293591496,
      "grad_norm": 0.9652705788612366,
      "learning_rate": 3.262226162055892e-05,
      "loss": 0.1745,
      "step": 39700
    },
    {
      "epoch": 1.0457224034515415,
      "grad_norm": 1.3691023588180542,
      "learning_rate": 3.260031947760146e-05,
      "loss": 0.1714,
      "step": 39750
    },
    {
      "epoch": 1.0470377775439335,
      "grad_norm": 1.0696982145309448,
      "learning_rate": 3.257837733464401e-05,
      "loss": 0.1699,
      "step": 39800
    },
    {
      "epoch": 1.0483531516363254,
      "grad_norm": 0.9011470675468445,
      "learning_rate": 3.2556435191686566e-05,
      "loss": 0.1646,
      "step": 39850
    },
    {
      "epoch": 1.0496685257287173,
      "grad_norm": 1.1649671792984009,
      "learning_rate": 3.2534493048729113e-05,
      "loss": 0.1743,
      "step": 39900
    },
    {
      "epoch": 1.0509838998211092,
      "grad_norm": 1.1454126834869385,
      "learning_rate": 3.251255090577166e-05,
      "loss": 0.173,
      "step": 39950
    },
    {
      "epoch": 1.052299273913501,
      "grad_norm": 1.2398905754089355,
      "learning_rate": 3.2490608762814215e-05,
      "loss": 0.1736,
      "step": 40000
    },
    {
      "epoch": 1.0536146480058928,
      "grad_norm": 0.9336620569229126,
      "learning_rate": 3.246866661985676e-05,
      "loss": 0.1681,
      "step": 40050
    },
    {
      "epoch": 1.0549300220982847,
      "grad_norm": 1.0319385528564453,
      "learning_rate": 3.244672447689932e-05,
      "loss": 0.1656,
      "step": 40100
    },
    {
      "epoch": 1.0562453961906766,
      "grad_norm": 0.8421949148178101,
      "learning_rate": 3.2424782333941864e-05,
      "loss": 0.1681,
      "step": 40150
    },
    {
      "epoch": 1.0575607702830685,
      "grad_norm": 1.0583643913269043,
      "learning_rate": 3.240284019098441e-05,
      "loss": 0.1679,
      "step": 40200
    },
    {
      "epoch": 1.0588761443754604,
      "grad_norm": 1.0428086519241333,
      "learning_rate": 3.2380898048026966e-05,
      "loss": 0.1697,
      "step": 40250
    },
    {
      "epoch": 1.0601915184678523,
      "grad_norm": 1.1015836000442505,
      "learning_rate": 3.2358955905069514e-05,
      "loss": 0.1744,
      "step": 40300
    },
    {
      "epoch": 1.0615068925602442,
      "grad_norm": 1.0395901203155518,
      "learning_rate": 3.233701376211207e-05,
      "loss": 0.1686,
      "step": 40350
    },
    {
      "epoch": 1.0628222666526361,
      "grad_norm": 1.1909723281860352,
      "learning_rate": 3.2315071619154615e-05,
      "loss": 0.1728,
      "step": 40400
    },
    {
      "epoch": 1.0641376407450278,
      "grad_norm": 1.0692815780639648,
      "learning_rate": 3.229312947619716e-05,
      "loss": 0.1665,
      "step": 40450
    },
    {
      "epoch": 1.0654530148374197,
      "grad_norm": 1.0521398782730103,
      "learning_rate": 3.227118733323972e-05,
      "loss": 0.1678,
      "step": 40500
    },
    {
      "epoch": 1.0667683889298116,
      "grad_norm": 0.9877378940582275,
      "learning_rate": 3.2249245190282265e-05,
      "loss": 0.168,
      "step": 40550
    },
    {
      "epoch": 1.0680837630222035,
      "grad_norm": 0.9098696112632751,
      "learning_rate": 3.222730304732481e-05,
      "loss": 0.1663,
      "step": 40600
    },
    {
      "epoch": 1.0693991371145954,
      "grad_norm": 1.4575923681259155,
      "learning_rate": 3.2205360904367366e-05,
      "loss": 0.1661,
      "step": 40650
    },
    {
      "epoch": 1.0707145112069874,
      "grad_norm": 1.0827263593673706,
      "learning_rate": 3.2183418761409914e-05,
      "loss": 0.1688,
      "step": 40700
    },
    {
      "epoch": 1.0720298852993793,
      "grad_norm": 1.286302924156189,
      "learning_rate": 3.216147661845247e-05,
      "loss": 0.1683,
      "step": 40750
    },
    {
      "epoch": 1.073345259391771,
      "grad_norm": 1.212870478630066,
      "learning_rate": 3.2139534475495016e-05,
      "loss": 0.1658,
      "step": 40800
    },
    {
      "epoch": 1.0746606334841629,
      "grad_norm": 1.2812117338180542,
      "learning_rate": 3.211759233253756e-05,
      "loss": 0.1672,
      "step": 40850
    },
    {
      "epoch": 1.0759760075765548,
      "grad_norm": 1.0878828763961792,
      "learning_rate": 3.209565018958012e-05,
      "loss": 0.1684,
      "step": 40900
    },
    {
      "epoch": 1.0772913816689467,
      "grad_norm": 1.1116279363632202,
      "learning_rate": 3.207370804662267e-05,
      "loss": 0.1625,
      "step": 40950
    },
    {
      "epoch": 1.0786067557613386,
      "grad_norm": 1.0707614421844482,
      "learning_rate": 3.205176590366521e-05,
      "loss": 0.1651,
      "step": 41000
    },
    {
      "epoch": 1.0799221298537305,
      "grad_norm": 1.157305121421814,
      "learning_rate": 3.2029823760707766e-05,
      "loss": 0.1658,
      "step": 41050
    },
    {
      "epoch": 1.0812375039461224,
      "grad_norm": 0.9711253643035889,
      "learning_rate": 3.200788161775032e-05,
      "loss": 0.1663,
      "step": 41100
    },
    {
      "epoch": 1.082552878038514,
      "grad_norm": 0.9871724843978882,
      "learning_rate": 3.198593947479287e-05,
      "loss": 0.1669,
      "step": 41150
    },
    {
      "epoch": 1.083868252130906,
      "grad_norm": 1.3289629220962524,
      "learning_rate": 3.1963997331835416e-05,
      "loss": 0.1655,
      "step": 41200
    },
    {
      "epoch": 1.085183626223298,
      "grad_norm": 0.9907355308532715,
      "learning_rate": 3.194205518887797e-05,
      "loss": 0.1619,
      "step": 41250
    },
    {
      "epoch": 1.0864990003156898,
      "grad_norm": 0.9695514440536499,
      "learning_rate": 3.192011304592052e-05,
      "loss": 0.1641,
      "step": 41300
    },
    {
      "epoch": 1.0878143744080817,
      "grad_norm": 0.8892281651496887,
      "learning_rate": 3.189817090296307e-05,
      "loss": 0.1664,
      "step": 41350
    },
    {
      "epoch": 1.0891297485004736,
      "grad_norm": 1.189336895942688,
      "learning_rate": 3.187622876000562e-05,
      "loss": 0.1638,
      "step": 41400
    },
    {
      "epoch": 1.0904451225928655,
      "grad_norm": 1.1427723169326782,
      "learning_rate": 3.185428661704817e-05,
      "loss": 0.167,
      "step": 41450
    },
    {
      "epoch": 1.0917604966852572,
      "grad_norm": 1.1402803659439087,
      "learning_rate": 3.183234447409072e-05,
      "loss": 0.1696,
      "step": 41500
    },
    {
      "epoch": 1.0930758707776491,
      "grad_norm": 1.0723052024841309,
      "learning_rate": 3.181040233113327e-05,
      "loss": 0.1635,
      "step": 41550
    },
    {
      "epoch": 1.094391244870041,
      "grad_norm": 1.0648932456970215,
      "learning_rate": 3.1788460188175816e-05,
      "loss": 0.1643,
      "step": 41600
    },
    {
      "epoch": 1.095706618962433,
      "grad_norm": 1.2348583936691284,
      "learning_rate": 3.176651804521837e-05,
      "loss": 0.1702,
      "step": 41650
    },
    {
      "epoch": 1.0970219930548248,
      "grad_norm": 1.1289721727371216,
      "learning_rate": 3.174457590226092e-05,
      "loss": 0.1659,
      "step": 41700
    },
    {
      "epoch": 1.0983373671472167,
      "grad_norm": 0.9454443454742432,
      "learning_rate": 3.172263375930347e-05,
      "loss": 0.1671,
      "step": 41750
    },
    {
      "epoch": 1.0996527412396087,
      "grad_norm": 1.0701260566711426,
      "learning_rate": 3.170069161634602e-05,
      "loss": 0.1642,
      "step": 41800
    },
    {
      "epoch": 1.1009681153320003,
      "grad_norm": 1.1411327123641968,
      "learning_rate": 3.167874947338857e-05,
      "loss": 0.1649,
      "step": 41850
    },
    {
      "epoch": 1.1022834894243922,
      "grad_norm": 1.241459608078003,
      "learning_rate": 3.165680733043112e-05,
      "loss": 0.169,
      "step": 41900
    },
    {
      "epoch": 1.1035988635167842,
      "grad_norm": 1.3560683727264404,
      "learning_rate": 3.1634865187473675e-05,
      "loss": 0.1686,
      "step": 41950
    },
    {
      "epoch": 1.104914237609176,
      "grad_norm": 1.2054353952407837,
      "learning_rate": 3.161292304451622e-05,
      "loss": 0.1649,
      "step": 42000
    },
    {
      "epoch": 1.106229611701568,
      "grad_norm": 0.6471219062805176,
      "learning_rate": 3.159098090155877e-05,
      "loss": 0.1646,
      "step": 42050
    },
    {
      "epoch": 1.1075449857939599,
      "grad_norm": 1.156136155128479,
      "learning_rate": 3.1569038758601325e-05,
      "loss": 0.1651,
      "step": 42100
    },
    {
      "epoch": 1.1088603598863518,
      "grad_norm": 1.2340970039367676,
      "learning_rate": 3.154709661564387e-05,
      "loss": 0.167,
      "step": 42150
    },
    {
      "epoch": 1.1101757339787435,
      "grad_norm": 1.0365841388702393,
      "learning_rate": 3.1525154472686426e-05,
      "loss": 0.1629,
      "step": 42200
    },
    {
      "epoch": 1.1114911080711354,
      "grad_norm": 1.1122151613235474,
      "learning_rate": 3.1503212329728974e-05,
      "loss": 0.1669,
      "step": 42250
    },
    {
      "epoch": 1.1128064821635273,
      "grad_norm": 0.9756410717964172,
      "learning_rate": 3.148127018677152e-05,
      "loss": 0.1653,
      "step": 42300
    },
    {
      "epoch": 1.1141218562559192,
      "grad_norm": 1.0238264799118042,
      "learning_rate": 3.1459328043814076e-05,
      "loss": 0.1669,
      "step": 42350
    },
    {
      "epoch": 1.115437230348311,
      "grad_norm": 1.188447117805481,
      "learning_rate": 3.143738590085662e-05,
      "loss": 0.1668,
      "step": 42400
    },
    {
      "epoch": 1.116752604440703,
      "grad_norm": 0.9803797602653503,
      "learning_rate": 3.141544375789917e-05,
      "loss": 0.1636,
      "step": 42450
    },
    {
      "epoch": 1.118067978533095,
      "grad_norm": 1.1802401542663574,
      "learning_rate": 3.1393501614941725e-05,
      "loss": 0.1659,
      "step": 42500
    },
    {
      "epoch": 1.1193833526254866,
      "grad_norm": 1.0958470106124878,
      "learning_rate": 3.137155947198427e-05,
      "loss": 0.1655,
      "step": 42550
    },
    {
      "epoch": 1.1206987267178785,
      "grad_norm": 0.9617664217948914,
      "learning_rate": 3.1349617329026827e-05,
      "loss": 0.1615,
      "step": 42600
    },
    {
      "epoch": 1.1220141008102704,
      "grad_norm": 0.9637055993080139,
      "learning_rate": 3.1327675186069374e-05,
      "loss": 0.1615,
      "step": 42650
    },
    {
      "epoch": 1.1233294749026623,
      "grad_norm": 0.8937731981277466,
      "learning_rate": 3.130573304311192e-05,
      "loss": 0.1623,
      "step": 42700
    },
    {
      "epoch": 1.1246448489950542,
      "grad_norm": 1.0552880764007568,
      "learning_rate": 3.1283790900154476e-05,
      "loss": 0.1637,
      "step": 42750
    },
    {
      "epoch": 1.1259602230874461,
      "grad_norm": 1.0623481273651123,
      "learning_rate": 3.126184875719702e-05,
      "loss": 0.1607,
      "step": 42800
    },
    {
      "epoch": 1.127275597179838,
      "grad_norm": 0.9953087568283081,
      "learning_rate": 3.123990661423957e-05,
      "loss": 0.1599,
      "step": 42850
    },
    {
      "epoch": 1.1285909712722297,
      "grad_norm": 0.9428156614303589,
      "learning_rate": 3.1217964471282125e-05,
      "loss": 0.1642,
      "step": 42900
    },
    {
      "epoch": 1.1299063453646216,
      "grad_norm": 0.9608006477355957,
      "learning_rate": 3.119602232832467e-05,
      "loss": 0.1605,
      "step": 42950
    },
    {
      "epoch": 1.1312217194570136,
      "grad_norm": 0.9085056781768799,
      "learning_rate": 3.117408018536723e-05,
      "loss": 0.1617,
      "step": 43000
    },
    {
      "epoch": 1.1325370935494055,
      "grad_norm": 0.9404754638671875,
      "learning_rate": 3.1152138042409774e-05,
      "loss": 0.1635,
      "step": 43050
    },
    {
      "epoch": 1.1338524676417974,
      "grad_norm": 0.9521843194961548,
      "learning_rate": 3.113019589945232e-05,
      "loss": 0.1648,
      "step": 43100
    },
    {
      "epoch": 1.1351678417341893,
      "grad_norm": 1.154984712600708,
      "learning_rate": 3.1108253756494876e-05,
      "loss": 0.1611,
      "step": 43150
    },
    {
      "epoch": 1.1364832158265812,
      "grad_norm": 0.8717416524887085,
      "learning_rate": 3.108631161353743e-05,
      "loss": 0.1646,
      "step": 43200
    },
    {
      "epoch": 1.1377985899189729,
      "grad_norm": 1.0400547981262207,
      "learning_rate": 3.106436947057997e-05,
      "loss": 0.1643,
      "step": 43250
    },
    {
      "epoch": 1.1391139640113648,
      "grad_norm": 1.0665446519851685,
      "learning_rate": 3.1042427327622525e-05,
      "loss": 0.1599,
      "step": 43300
    },
    {
      "epoch": 1.1404293381037567,
      "grad_norm": 1.1770247220993042,
      "learning_rate": 3.102048518466508e-05,
      "loss": 0.1643,
      "step": 43350
    },
    {
      "epoch": 1.1417447121961486,
      "grad_norm": 0.9984362721443176,
      "learning_rate": 3.099854304170763e-05,
      "loss": 0.1642,
      "step": 43400
    },
    {
      "epoch": 1.1430600862885405,
      "grad_norm": 0.770164430141449,
      "learning_rate": 3.0976600898750174e-05,
      "loss": 0.1632,
      "step": 43450
    },
    {
      "epoch": 1.1443754603809324,
      "grad_norm": 0.9277551174163818,
      "learning_rate": 3.095465875579273e-05,
      "loss": 0.1659,
      "step": 43500
    },
    {
      "epoch": 1.1456908344733243,
      "grad_norm": 1.1025245189666748,
      "learning_rate": 3.0932716612835276e-05,
      "loss": 0.1618,
      "step": 43550
    },
    {
      "epoch": 1.147006208565716,
      "grad_norm": 1.129996418952942,
      "learning_rate": 3.091077446987783e-05,
      "loss": 0.1614,
      "step": 43600
    },
    {
      "epoch": 1.148321582658108,
      "grad_norm": 1.1127893924713135,
      "learning_rate": 3.088883232692038e-05,
      "loss": 0.1613,
      "step": 43650
    },
    {
      "epoch": 1.1496369567504998,
      "grad_norm": 0.8719285726547241,
      "learning_rate": 3.0866890183962925e-05,
      "loss": 0.1633,
      "step": 43700
    },
    {
      "epoch": 1.1509523308428917,
      "grad_norm": 0.8554839491844177,
      "learning_rate": 3.084494804100548e-05,
      "loss": 0.1579,
      "step": 43750
    },
    {
      "epoch": 1.1522677049352836,
      "grad_norm": 0.9070244431495667,
      "learning_rate": 3.082300589804803e-05,
      "loss": 0.1616,
      "step": 43800
    },
    {
      "epoch": 1.1535830790276755,
      "grad_norm": 1.6587778329849243,
      "learning_rate": 3.080106375509058e-05,
      "loss": 0.1603,
      "step": 43850
    },
    {
      "epoch": 1.1548984531200674,
      "grad_norm": 1.0791664123535156,
      "learning_rate": 3.077912161213313e-05,
      "loss": 0.1636,
      "step": 43900
    },
    {
      "epoch": 1.1562138272124591,
      "grad_norm": 0.925179660320282,
      "learning_rate": 3.0757179469175676e-05,
      "loss": 0.1616,
      "step": 43950
    },
    {
      "epoch": 1.157529201304851,
      "grad_norm": 0.8908378481864929,
      "learning_rate": 3.073523732621823e-05,
      "loss": 0.1706,
      "step": 44000
    },
    {
      "epoch": 1.158844575397243,
      "grad_norm": 1.0093233585357666,
      "learning_rate": 3.0713295183260785e-05,
      "loss": 0.1589,
      "step": 44050
    },
    {
      "epoch": 1.1601599494896349,
      "grad_norm": 1.1290124654769897,
      "learning_rate": 3.0691353040303326e-05,
      "loss": 0.1548,
      "step": 44100
    },
    {
      "epoch": 1.1614753235820268,
      "grad_norm": 1.121600866317749,
      "learning_rate": 3.066941089734588e-05,
      "loss": 0.1577,
      "step": 44150
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 0.8853895664215088,
      "learning_rate": 3.0647468754388434e-05,
      "loss": 0.1578,
      "step": 44200
    },
    {
      "epoch": 1.1641060717668106,
      "grad_norm": 1.0865181684494019,
      "learning_rate": 3.062552661143098e-05,
      "loss": 0.1576,
      "step": 44250
    },
    {
      "epoch": 1.1654214458592023,
      "grad_norm": 1.0074573755264282,
      "learning_rate": 3.060358446847353e-05,
      "loss": 0.1595,
      "step": 44300
    },
    {
      "epoch": 1.1667368199515942,
      "grad_norm": 0.9695482850074768,
      "learning_rate": 3.058164232551608e-05,
      "loss": 0.1599,
      "step": 44350
    },
    {
      "epoch": 1.168052194043986,
      "grad_norm": 0.9406322836875916,
      "learning_rate": 3.055970018255863e-05,
      "loss": 0.1566,
      "step": 44400
    },
    {
      "epoch": 1.169367568136378,
      "grad_norm": 0.8838417530059814,
      "learning_rate": 3.0537758039601185e-05,
      "loss": 0.1551,
      "step": 44450
    },
    {
      "epoch": 1.17068294222877,
      "grad_norm": 0.9295815825462341,
      "learning_rate": 3.051581589664373e-05,
      "loss": 0.1605,
      "step": 44500
    },
    {
      "epoch": 1.1719983163211618,
      "grad_norm": 0.9999038577079773,
      "learning_rate": 3.049387375368628e-05,
      "loss": 0.1572,
      "step": 44550
    },
    {
      "epoch": 1.1733136904135537,
      "grad_norm": 1.0244075059890747,
      "learning_rate": 3.047193161072883e-05,
      "loss": 0.1645,
      "step": 44600
    },
    {
      "epoch": 1.1746290645059454,
      "grad_norm": 1.2183558940887451,
      "learning_rate": 3.0449989467771385e-05,
      "loss": 0.1602,
      "step": 44650
    },
    {
      "epoch": 1.1759444385983373,
      "grad_norm": 1.3656878471374512,
      "learning_rate": 3.042804732481393e-05,
      "loss": 0.159,
      "step": 44700
    },
    {
      "epoch": 1.1772598126907292,
      "grad_norm": 0.9703453779220581,
      "learning_rate": 3.040610518185648e-05,
      "loss": 0.1603,
      "step": 44750
    },
    {
      "epoch": 1.1785751867831211,
      "grad_norm": 0.8407846093177795,
      "learning_rate": 3.0384163038899034e-05,
      "loss": 0.1586,
      "step": 44800
    },
    {
      "epoch": 1.179890560875513,
      "grad_norm": 1.1694490909576416,
      "learning_rate": 3.0362220895941585e-05,
      "loss": 0.1604,
      "step": 44850
    },
    {
      "epoch": 1.181205934967905,
      "grad_norm": 0.9483301043510437,
      "learning_rate": 3.034027875298413e-05,
      "loss": 0.1571,
      "step": 44900
    },
    {
      "epoch": 1.1825213090602968,
      "grad_norm": 1.288693904876709,
      "learning_rate": 3.0318336610026684e-05,
      "loss": 0.1615,
      "step": 44950
    },
    {
      "epoch": 1.1838366831526885,
      "grad_norm": 0.8874190449714661,
      "learning_rate": 3.0296394467069234e-05,
      "loss": 0.1589,
      "step": 45000
    },
    {
      "epoch": 1.1851520572450804,
      "grad_norm": 0.986948549747467,
      "learning_rate": 3.0274452324111785e-05,
      "loss": 0.1541,
      "step": 45050
    },
    {
      "epoch": 1.1864674313374723,
      "grad_norm": 1.0908255577087402,
      "learning_rate": 3.025251018115433e-05,
      "loss": 0.1576,
      "step": 45100
    },
    {
      "epoch": 1.1877828054298643,
      "grad_norm": 0.9975973963737488,
      "learning_rate": 3.0230568038196884e-05,
      "loss": 0.1543,
      "step": 45150
    },
    {
      "epoch": 1.1890981795222562,
      "grad_norm": 1.110509991645813,
      "learning_rate": 3.0208625895239435e-05,
      "loss": 0.1577,
      "step": 45200
    },
    {
      "epoch": 1.190413553614648,
      "grad_norm": 1.0732120275497437,
      "learning_rate": 3.0186683752281985e-05,
      "loss": 0.1611,
      "step": 45250
    },
    {
      "epoch": 1.19172892770704,
      "grad_norm": 1.0789010524749756,
      "learning_rate": 3.0164741609324536e-05,
      "loss": 0.1576,
      "step": 45300
    },
    {
      "epoch": 1.1930443017994317,
      "grad_norm": 1.0066882371902466,
      "learning_rate": 3.0142799466367084e-05,
      "loss": 0.1567,
      "step": 45350
    },
    {
      "epoch": 1.1943596758918236,
      "grad_norm": 1.1492011547088623,
      "learning_rate": 3.0120857323409635e-05,
      "loss": 0.1625,
      "step": 45400
    },
    {
      "epoch": 1.1956750499842155,
      "grad_norm": 1.0816702842712402,
      "learning_rate": 3.0098915180452186e-05,
      "loss": 0.159,
      "step": 45450
    },
    {
      "epoch": 1.1969904240766074,
      "grad_norm": 1.0667585134506226,
      "learning_rate": 3.0076973037494736e-05,
      "loss": 0.1566,
      "step": 45500
    },
    {
      "epoch": 1.1983057981689993,
      "grad_norm": 1.2146189212799072,
      "learning_rate": 3.0055030894537284e-05,
      "loss": 0.1597,
      "step": 45550
    },
    {
      "epoch": 1.1996211722613912,
      "grad_norm": 1.1908122301101685,
      "learning_rate": 3.0033088751579835e-05,
      "loss": 0.1569,
      "step": 45600
    },
    {
      "epoch": 1.200936546353783,
      "grad_norm": 1.0188839435577393,
      "learning_rate": 3.0011146608622386e-05,
      "loss": 0.1593,
      "step": 45650
    },
    {
      "epoch": 1.2022519204461748,
      "grad_norm": 0.9437041282653809,
      "learning_rate": 2.998920446566494e-05,
      "loss": 0.1575,
      "step": 45700
    },
    {
      "epoch": 1.2035672945385667,
      "grad_norm": 0.9217172265052795,
      "learning_rate": 2.9967262322707484e-05,
      "loss": 0.1543,
      "step": 45750
    },
    {
      "epoch": 1.2048826686309586,
      "grad_norm": 1.0062241554260254,
      "learning_rate": 2.9945320179750035e-05,
      "loss": 0.1562,
      "step": 45800
    },
    {
      "epoch": 1.2061980427233505,
      "grad_norm": 0.9980316162109375,
      "learning_rate": 2.992337803679259e-05,
      "loss": 0.1551,
      "step": 45850
    },
    {
      "epoch": 1.2075134168157424,
      "grad_norm": 1.2763514518737793,
      "learning_rate": 2.990143589383514e-05,
      "loss": 0.1575,
      "step": 45900
    },
    {
      "epoch": 1.2088287909081343,
      "grad_norm": 1.038847804069519,
      "learning_rate": 2.9879493750877684e-05,
      "loss": 0.1574,
      "step": 45950
    },
    {
      "epoch": 1.2101441650005262,
      "grad_norm": 1.0528459548950195,
      "learning_rate": 2.985755160792024e-05,
      "loss": 0.1577,
      "step": 46000
    },
    {
      "epoch": 1.211459539092918,
      "grad_norm": 0.9058197736740112,
      "learning_rate": 2.983560946496279e-05,
      "loss": 0.1559,
      "step": 46050
    },
    {
      "epoch": 1.2127749131853098,
      "grad_norm": 1.0597907304763794,
      "learning_rate": 2.981366732200534e-05,
      "loss": 0.1594,
      "step": 46100
    },
    {
      "epoch": 1.2140902872777017,
      "grad_norm": 0.826898992061615,
      "learning_rate": 2.9791725179047884e-05,
      "loss": 0.1562,
      "step": 46150
    },
    {
      "epoch": 1.2154056613700936,
      "grad_norm": 0.9661151170730591,
      "learning_rate": 2.976978303609044e-05,
      "loss": 0.1584,
      "step": 46200
    },
    {
      "epoch": 1.2167210354624856,
      "grad_norm": 0.9359726309776306,
      "learning_rate": 2.974784089313299e-05,
      "loss": 0.156,
      "step": 46250
    },
    {
      "epoch": 1.2180364095548775,
      "grad_norm": 1.2658275365829468,
      "learning_rate": 2.972589875017554e-05,
      "loss": 0.1558,
      "step": 46300
    },
    {
      "epoch": 1.2193517836472694,
      "grad_norm": 1.0094558000564575,
      "learning_rate": 2.9703956607218088e-05,
      "loss": 0.1529,
      "step": 46350
    },
    {
      "epoch": 1.220667157739661,
      "grad_norm": 1.074832558631897,
      "learning_rate": 2.968201446426064e-05,
      "loss": 0.1555,
      "step": 46400
    },
    {
      "epoch": 1.221982531832053,
      "grad_norm": 0.9482503533363342,
      "learning_rate": 2.966007232130319e-05,
      "loss": 0.1565,
      "step": 46450
    },
    {
      "epoch": 1.2232979059244449,
      "grad_norm": 1.018404483795166,
      "learning_rate": 2.963813017834574e-05,
      "loss": 0.1594,
      "step": 46500
    },
    {
      "epoch": 1.2246132800168368,
      "grad_norm": 1.0048930644989014,
      "learning_rate": 2.9616188035388288e-05,
      "loss": 0.1593,
      "step": 46550
    },
    {
      "epoch": 1.2259286541092287,
      "grad_norm": 0.9962112307548523,
      "learning_rate": 2.959424589243084e-05,
      "loss": 0.1521,
      "step": 46600
    },
    {
      "epoch": 1.2272440282016206,
      "grad_norm": 1.107738971710205,
      "learning_rate": 2.957230374947339e-05,
      "loss": 0.1589,
      "step": 46650
    },
    {
      "epoch": 1.2285594022940125,
      "grad_norm": 0.9476718306541443,
      "learning_rate": 2.955036160651594e-05,
      "loss": 0.1568,
      "step": 46700
    },
    {
      "epoch": 1.2298747763864042,
      "grad_norm": 1.0620049238204956,
      "learning_rate": 2.9528419463558488e-05,
      "loss": 0.1546,
      "step": 46750
    },
    {
      "epoch": 1.231190150478796,
      "grad_norm": 1.1812210083007812,
      "learning_rate": 2.950647732060104e-05,
      "loss": 0.1551,
      "step": 46800
    },
    {
      "epoch": 1.232505524571188,
      "grad_norm": 0.8258987665176392,
      "learning_rate": 2.948453517764359e-05,
      "loss": 0.1547,
      "step": 46850
    },
    {
      "epoch": 1.23382089866358,
      "grad_norm": 1.1167329549789429,
      "learning_rate": 2.9462593034686144e-05,
      "loss": 0.1505,
      "step": 46900
    },
    {
      "epoch": 1.2351362727559718,
      "grad_norm": 0.8422911763191223,
      "learning_rate": 2.9440650891728695e-05,
      "loss": 0.1535,
      "step": 46950
    },
    {
      "epoch": 1.2364516468483637,
      "grad_norm": 1.0808820724487305,
      "learning_rate": 2.941870874877124e-05,
      "loss": 0.1561,
      "step": 47000
    },
    {
      "epoch": 1.2377670209407556,
      "grad_norm": 0.8933836817741394,
      "learning_rate": 2.9396766605813793e-05,
      "loss": 0.1529,
      "step": 47050
    },
    {
      "epoch": 1.2390823950331473,
      "grad_norm": 1.081068515777588,
      "learning_rate": 2.9374824462856344e-05,
      "loss": 0.1532,
      "step": 47100
    },
    {
      "epoch": 1.2403977691255392,
      "grad_norm": 1.2690644264221191,
      "learning_rate": 2.9352882319898895e-05,
      "loss": 0.1578,
      "step": 47150
    },
    {
      "epoch": 1.2417131432179311,
      "grad_norm": 1.0214771032333374,
      "learning_rate": 2.933094017694144e-05,
      "loss": 0.1515,
      "step": 47200
    },
    {
      "epoch": 1.243028517310323,
      "grad_norm": 0.8180447220802307,
      "learning_rate": 2.9308998033983993e-05,
      "loss": 0.1561,
      "step": 47250
    },
    {
      "epoch": 1.244343891402715,
      "grad_norm": 1.0663989782333374,
      "learning_rate": 2.9287055891026544e-05,
      "loss": 0.1523,
      "step": 47300
    },
    {
      "epoch": 1.2456592654951069,
      "grad_norm": 0.9830995202064514,
      "learning_rate": 2.9265113748069095e-05,
      "loss": 0.1536,
      "step": 47350
    },
    {
      "epoch": 1.2469746395874988,
      "grad_norm": 0.809492290019989,
      "learning_rate": 2.9243171605111642e-05,
      "loss": 0.1559,
      "step": 47400
    },
    {
      "epoch": 1.2482900136798905,
      "grad_norm": 0.8618049025535583,
      "learning_rate": 2.9221229462154193e-05,
      "loss": 0.156,
      "step": 47450
    },
    {
      "epoch": 1.2496053877722824,
      "grad_norm": 0.8989296555519104,
      "learning_rate": 2.9199287319196744e-05,
      "loss": 0.1537,
      "step": 47500
    },
    {
      "epoch": 1.2509207618646743,
      "grad_norm": 1.0367321968078613,
      "learning_rate": 2.9177345176239295e-05,
      "loss": 0.1533,
      "step": 47550
    },
    {
      "epoch": 1.2522361359570662,
      "grad_norm": 1.0499892234802246,
      "learning_rate": 2.9155403033281842e-05,
      "loss": 0.1542,
      "step": 47600
    },
    {
      "epoch": 1.253551510049458,
      "grad_norm": 0.8576756119728088,
      "learning_rate": 2.9133460890324393e-05,
      "loss": 0.1552,
      "step": 47650
    },
    {
      "epoch": 1.25486688414185,
      "grad_norm": 1.0113424062728882,
      "learning_rate": 2.9111518747366944e-05,
      "loss": 0.1538,
      "step": 47700
    },
    {
      "epoch": 1.256182258234242,
      "grad_norm": 0.7786657810211182,
      "learning_rate": 2.9089576604409495e-05,
      "loss": 0.1533,
      "step": 47750
    },
    {
      "epoch": 1.2574976323266336,
      "grad_norm": 0.9980323314666748,
      "learning_rate": 2.9067634461452043e-05,
      "loss": 0.153,
      "step": 47800
    },
    {
      "epoch": 1.2588130064190255,
      "grad_norm": 0.8797523379325867,
      "learning_rate": 2.9045692318494593e-05,
      "loss": 0.1543,
      "step": 47850
    },
    {
      "epoch": 1.2601283805114174,
      "grad_norm": 0.8760188221931458,
      "learning_rate": 2.9023750175537144e-05,
      "loss": 0.1535,
      "step": 47900
    },
    {
      "epoch": 1.2614437546038093,
      "grad_norm": 0.880312979221344,
      "learning_rate": 2.90018080325797e-05,
      "loss": 0.157,
      "step": 47950
    },
    {
      "epoch": 1.2627591286962012,
      "grad_norm": 0.7198721170425415,
      "learning_rate": 2.8979865889622243e-05,
      "loss": 0.1533,
      "step": 48000
    },
    {
      "epoch": 1.2640745027885931,
      "grad_norm": 1.1920157670974731,
      "learning_rate": 2.8957923746664794e-05,
      "loss": 0.1532,
      "step": 48050
    },
    {
      "epoch": 1.265389876880985,
      "grad_norm": 0.9747650027275085,
      "learning_rate": 2.8935981603707348e-05,
      "loss": 0.1538,
      "step": 48100
    },
    {
      "epoch": 1.2667052509733767,
      "grad_norm": 1.013368010520935,
      "learning_rate": 2.89140394607499e-05,
      "loss": 0.1549,
      "step": 48150
    },
    {
      "epoch": 1.2680206250657686,
      "grad_norm": 0.9858626127243042,
      "learning_rate": 2.8892097317792443e-05,
      "loss": 0.1481,
      "step": 48200
    },
    {
      "epoch": 1.2693359991581605,
      "grad_norm": 0.7824344635009766,
      "learning_rate": 2.8870155174834994e-05,
      "loss": 0.1548,
      "step": 48250
    },
    {
      "epoch": 1.2706513732505524,
      "grad_norm": 1.057827353477478,
      "learning_rate": 2.8848213031877548e-05,
      "loss": 0.1505,
      "step": 48300
    },
    {
      "epoch": 1.2719667473429443,
      "grad_norm": 1.0092413425445557,
      "learning_rate": 2.88262708889201e-05,
      "loss": 0.1528,
      "step": 48350
    },
    {
      "epoch": 1.2732821214353363,
      "grad_norm": 0.9085078835487366,
      "learning_rate": 2.8804328745962643e-05,
      "loss": 0.1536,
      "step": 48400
    },
    {
      "epoch": 1.2745974955277282,
      "grad_norm": 0.9405611157417297,
      "learning_rate": 2.8782386603005197e-05,
      "loss": 0.1494,
      "step": 48450
    },
    {
      "epoch": 1.2759128696201198,
      "grad_norm": 0.841082751750946,
      "learning_rate": 2.8760444460047748e-05,
      "loss": 0.1528,
      "step": 48500
    },
    {
      "epoch": 1.2772282437125118,
      "grad_norm": 1.026342511177063,
      "learning_rate": 2.87385023170903e-05,
      "loss": 0.155,
      "step": 48550
    },
    {
      "epoch": 1.2785436178049037,
      "grad_norm": 0.9542421698570251,
      "learning_rate": 2.871656017413285e-05,
      "loss": 0.1488,
      "step": 48600
    },
    {
      "epoch": 1.2798589918972956,
      "grad_norm": 0.8361756801605225,
      "learning_rate": 2.8694618031175397e-05,
      "loss": 0.1535,
      "step": 48650
    },
    {
      "epoch": 1.2811743659896875,
      "grad_norm": 1.0164505243301392,
      "learning_rate": 2.8672675888217948e-05,
      "loss": 0.1517,
      "step": 48700
    },
    {
      "epoch": 1.2824897400820794,
      "grad_norm": 0.9690994024276733,
      "learning_rate": 2.86507337452605e-05,
      "loss": 0.1532,
      "step": 48750
    },
    {
      "epoch": 1.2838051141744713,
      "grad_norm": 1.0682802200317383,
      "learning_rate": 2.862879160230305e-05,
      "loss": 0.1531,
      "step": 48800
    },
    {
      "epoch": 1.285120488266863,
      "grad_norm": 0.9379490613937378,
      "learning_rate": 2.8606849459345597e-05,
      "loss": 0.154,
      "step": 48850
    },
    {
      "epoch": 1.286435862359255,
      "grad_norm": 1.0642677545547485,
      "learning_rate": 2.8584907316388148e-05,
      "loss": 0.15,
      "step": 48900
    },
    {
      "epoch": 1.2877512364516468,
      "grad_norm": 1.0018858909606934,
      "learning_rate": 2.85629651734307e-05,
      "loss": 0.1545,
      "step": 48950
    },
    {
      "epoch": 1.2890666105440387,
      "grad_norm": 1.0168185234069824,
      "learning_rate": 2.8541023030473253e-05,
      "loss": 0.152,
      "step": 49000
    },
    {
      "epoch": 1.2903819846364306,
      "grad_norm": 0.8382869958877563,
      "learning_rate": 2.8519080887515797e-05,
      "loss": 0.1505,
      "step": 49050
    },
    {
      "epoch": 1.2916973587288225,
      "grad_norm": 0.9270265102386475,
      "learning_rate": 2.8497138744558348e-05,
      "loss": 0.1527,
      "step": 49100
    },
    {
      "epoch": 1.2930127328212144,
      "grad_norm": 1.1447460651397705,
      "learning_rate": 2.8475196601600903e-05,
      "loss": 0.1554,
      "step": 49150
    },
    {
      "epoch": 1.2943281069136061,
      "grad_norm": 0.8563233017921448,
      "learning_rate": 2.8453254458643453e-05,
      "loss": 0.154,
      "step": 49200
    },
    {
      "epoch": 1.2956434810059982,
      "grad_norm": 1.105120301246643,
      "learning_rate": 2.8431312315685997e-05,
      "loss": 0.1507,
      "step": 49250
    },
    {
      "epoch": 1.29695885509839,
      "grad_norm": 0.7036333084106445,
      "learning_rate": 2.840937017272855e-05,
      "loss": 0.1504,
      "step": 49300
    },
    {
      "epoch": 1.2982742291907818,
      "grad_norm": 1.0103378295898438,
      "learning_rate": 2.8387428029771103e-05,
      "loss": 0.1516,
      "step": 49350
    },
    {
      "epoch": 1.2995896032831737,
      "grad_norm": 0.8387330174446106,
      "learning_rate": 2.8365485886813653e-05,
      "loss": 0.1464,
      "step": 49400
    },
    {
      "epoch": 1.3009049773755657,
      "grad_norm": 1.0943602323532104,
      "learning_rate": 2.8343543743856198e-05,
      "loss": 0.1512,
      "step": 49450
    },
    {
      "epoch": 1.3022203514679576,
      "grad_norm": 0.8152624368667603,
      "learning_rate": 2.8321601600898752e-05,
      "loss": 0.1509,
      "step": 49500
    },
    {
      "epoch": 1.3035357255603492,
      "grad_norm": 0.9051714539527893,
      "learning_rate": 2.8299659457941303e-05,
      "loss": 0.1486,
      "step": 49550
    },
    {
      "epoch": 1.3048510996527414,
      "grad_norm": 1.0410863161087036,
      "learning_rate": 2.8277717314983854e-05,
      "loss": 0.1524,
      "step": 49600
    },
    {
      "epoch": 1.306166473745133,
      "grad_norm": 0.6655199527740479,
      "learning_rate": 2.82557751720264e-05,
      "loss": 0.1488,
      "step": 49650
    },
    {
      "epoch": 1.307481847837525,
      "grad_norm": 1.110061764717102,
      "learning_rate": 2.8233833029068952e-05,
      "loss": 0.1496,
      "step": 49700
    },
    {
      "epoch": 1.3087972219299169,
      "grad_norm": 0.8540835380554199,
      "learning_rate": 2.8211890886111503e-05,
      "loss": 0.152,
      "step": 49750
    },
    {
      "epoch": 1.3101125960223088,
      "grad_norm": 0.9215279221534729,
      "learning_rate": 2.8189948743154054e-05,
      "loss": 0.1504,
      "step": 49800
    },
    {
      "epoch": 1.3114279701147007,
      "grad_norm": 0.8706726431846619,
      "learning_rate": 2.81680066001966e-05,
      "loss": 0.1478,
      "step": 49850
    },
    {
      "epoch": 1.3127433442070924,
      "grad_norm": 1.0352104902267456,
      "learning_rate": 2.8146064457239152e-05,
      "loss": 0.1495,
      "step": 49900
    },
    {
      "epoch": 1.3140587182994845,
      "grad_norm": 1.171282172203064,
      "learning_rate": 2.8124122314281703e-05,
      "loss": 0.1499,
      "step": 49950
    },
    {
      "epoch": 1.3153740923918762,
      "grad_norm": 0.960197925567627,
      "learning_rate": 2.8102180171324254e-05,
      "loss": 0.1502,
      "step": 50000
    },
    {
      "epoch": 1.316689466484268,
      "grad_norm": 0.6548452973365784,
      "learning_rate": 2.8080238028366808e-05,
      "loss": 0.1519,
      "step": 50050
    },
    {
      "epoch": 1.31800484057666,
      "grad_norm": 0.9351620078086853,
      "learning_rate": 2.8058295885409352e-05,
      "loss": 0.1506,
      "step": 50100
    },
    {
      "epoch": 1.319320214669052,
      "grad_norm": 0.9459943175315857,
      "learning_rate": 2.8036353742451903e-05,
      "loss": 0.1505,
      "step": 50150
    },
    {
      "epoch": 1.3206355887614438,
      "grad_norm": 0.8621542453765869,
      "learning_rate": 2.8014411599494457e-05,
      "loss": 0.1487,
      "step": 50200
    },
    {
      "epoch": 1.3219509628538355,
      "grad_norm": 0.8377644419670105,
      "learning_rate": 2.7992469456537008e-05,
      "loss": 0.1484,
      "step": 50250
    },
    {
      "epoch": 1.3232663369462276,
      "grad_norm": 0.8695969581604004,
      "learning_rate": 2.7970527313579552e-05,
      "loss": 0.1503,
      "step": 50300
    },
    {
      "epoch": 1.3245817110386193,
      "grad_norm": 0.9226061105728149,
      "learning_rate": 2.7948585170622103e-05,
      "loss": 0.1485,
      "step": 50350
    },
    {
      "epoch": 1.3258970851310112,
      "grad_norm": 1.0903797149658203,
      "learning_rate": 2.7926643027664657e-05,
      "loss": 0.1523,
      "step": 50400
    },
    {
      "epoch": 1.3272124592234031,
      "grad_norm": 0.9974648356437683,
      "learning_rate": 2.7904700884707208e-05,
      "loss": 0.148,
      "step": 50450
    },
    {
      "epoch": 1.328527833315795,
      "grad_norm": 0.9391694664955139,
      "learning_rate": 2.7882758741749752e-05,
      "loss": 0.1514,
      "step": 50500
    },
    {
      "epoch": 1.329843207408187,
      "grad_norm": 0.9673158526420593,
      "learning_rate": 2.7860816598792307e-05,
      "loss": 0.1446,
      "step": 50550
    },
    {
      "epoch": 1.3311585815005786,
      "grad_norm": 0.8056926131248474,
      "learning_rate": 2.7838874455834857e-05,
      "loss": 0.1492,
      "step": 50600
    },
    {
      "epoch": 1.3324739555929708,
      "grad_norm": 0.8779159188270569,
      "learning_rate": 2.7816932312877408e-05,
      "loss": 0.1479,
      "step": 50650
    },
    {
      "epoch": 1.3337893296853625,
      "grad_norm": 0.8425381183624268,
      "learning_rate": 2.7794990169919956e-05,
      "loss": 0.1452,
      "step": 50700
    },
    {
      "epoch": 1.3351047037777544,
      "grad_norm": 1.2330763339996338,
      "learning_rate": 2.7773048026962507e-05,
      "loss": 0.1477,
      "step": 50750
    },
    {
      "epoch": 1.3364200778701463,
      "grad_norm": 0.8718551397323608,
      "learning_rate": 2.7751105884005058e-05,
      "loss": 0.1504,
      "step": 50800
    },
    {
      "epoch": 1.3377354519625382,
      "grad_norm": 1.0896048545837402,
      "learning_rate": 2.772916374104761e-05,
      "loss": 0.1503,
      "step": 50850
    },
    {
      "epoch": 1.33905082605493,
      "grad_norm": 1.2556390762329102,
      "learning_rate": 2.7707221598090156e-05,
      "loss": 0.1452,
      "step": 50900
    },
    {
      "epoch": 1.3403662001473218,
      "grad_norm": 0.9168617725372314,
      "learning_rate": 2.7685279455132707e-05,
      "loss": 0.1545,
      "step": 50950
    },
    {
      "epoch": 1.341681574239714,
      "grad_norm": 1.0115910768508911,
      "learning_rate": 2.7663337312175258e-05,
      "loss": 0.155,
      "step": 51000
    },
    {
      "epoch": 1.3429969483321056,
      "grad_norm": 0.903318464756012,
      "learning_rate": 2.764139516921781e-05,
      "loss": 0.1485,
      "step": 51050
    },
    {
      "epoch": 1.3443123224244975,
      "grad_norm": 1.0477598905563354,
      "learning_rate": 2.7619453026260356e-05,
      "loss": 0.1529,
      "step": 51100
    },
    {
      "epoch": 1.3456276965168894,
      "grad_norm": 0.75255286693573,
      "learning_rate": 2.7597510883302907e-05,
      "loss": 0.1473,
      "step": 51150
    },
    {
      "epoch": 1.3469430706092813,
      "grad_norm": 0.8791103959083557,
      "learning_rate": 2.7575568740345458e-05,
      "loss": 0.1526,
      "step": 51200
    },
    {
      "epoch": 1.3482584447016732,
      "grad_norm": 0.762332558631897,
      "learning_rate": 2.7553626597388012e-05,
      "loss": 0.1458,
      "step": 51250
    },
    {
      "epoch": 1.349573818794065,
      "grad_norm": 0.7584619522094727,
      "learning_rate": 2.7531684454430556e-05,
      "loss": 0.1469,
      "step": 51300
    },
    {
      "epoch": 1.350889192886457,
      "grad_norm": 1.1708624362945557,
      "learning_rate": 2.7509742311473107e-05,
      "loss": 0.1454,
      "step": 51350
    },
    {
      "epoch": 1.3522045669788487,
      "grad_norm": 0.9095537662506104,
      "learning_rate": 2.7487800168515658e-05,
      "loss": 0.147,
      "step": 51400
    },
    {
      "epoch": 1.3535199410712406,
      "grad_norm": 0.9278393387794495,
      "learning_rate": 2.7465858025558212e-05,
      "loss": 0.1487,
      "step": 51450
    },
    {
      "epoch": 1.3548353151636325,
      "grad_norm": 0.8519412875175476,
      "learning_rate": 2.7443915882600756e-05,
      "loss": 0.1503,
      "step": 51500
    },
    {
      "epoch": 1.3561506892560244,
      "grad_norm": 0.9595417380332947,
      "learning_rate": 2.7421973739643307e-05,
      "loss": 0.1466,
      "step": 51550
    },
    {
      "epoch": 1.3574660633484164,
      "grad_norm": 0.8100731372833252,
      "learning_rate": 2.740003159668586e-05,
      "loss": 0.1445,
      "step": 51600
    },
    {
      "epoch": 1.358781437440808,
      "grad_norm": 0.7409395575523376,
      "learning_rate": 2.7378089453728412e-05,
      "loss": 0.1491,
      "step": 51650
    },
    {
      "epoch": 1.3600968115332002,
      "grad_norm": 1.077859878540039,
      "learning_rate": 2.7356147310770963e-05,
      "loss": 0.1479,
      "step": 51700
    },
    {
      "epoch": 1.3614121856255919,
      "grad_norm": 0.8996695876121521,
      "learning_rate": 2.733420516781351e-05,
      "loss": 0.1505,
      "step": 51750
    },
    {
      "epoch": 1.3627275597179838,
      "grad_norm": 0.9890121817588806,
      "learning_rate": 2.731226302485606e-05,
      "loss": 0.1485,
      "step": 51800
    },
    {
      "epoch": 1.3640429338103757,
      "grad_norm": 1.1183459758758545,
      "learning_rate": 2.7290320881898612e-05,
      "loss": 0.1494,
      "step": 51850
    },
    {
      "epoch": 1.3653583079027676,
      "grad_norm": 0.977103590965271,
      "learning_rate": 2.7268378738941163e-05,
      "loss": 0.1448,
      "step": 51900
    },
    {
      "epoch": 1.3666736819951595,
      "grad_norm": 1.7246251106262207,
      "learning_rate": 2.724643659598371e-05,
      "loss": 0.1463,
      "step": 51950
    },
    {
      "epoch": 1.3679890560875512,
      "grad_norm": 0.9187456369400024,
      "learning_rate": 2.722449445302626e-05,
      "loss": 0.1462,
      "step": 52000
    },
    {
      "epoch": 1.3693044301799433,
      "grad_norm": 1.1060092449188232,
      "learning_rate": 2.7202552310068812e-05,
      "loss": 0.1466,
      "step": 52050
    },
    {
      "epoch": 1.370619804272335,
      "grad_norm": 0.9051899313926697,
      "learning_rate": 2.7180610167111363e-05,
      "loss": 0.1482,
      "step": 52100
    },
    {
      "epoch": 1.371935178364727,
      "grad_norm": 0.9900051951408386,
      "learning_rate": 2.715866802415391e-05,
      "loss": 0.1464,
      "step": 52150
    },
    {
      "epoch": 1.3732505524571188,
      "grad_norm": 0.8413346409797668,
      "learning_rate": 2.713672588119646e-05,
      "loss": 0.1478,
      "step": 52200
    },
    {
      "epoch": 1.3745659265495107,
      "grad_norm": 0.7406297922134399,
      "learning_rate": 2.7114783738239012e-05,
      "loss": 0.1478,
      "step": 52250
    },
    {
      "epoch": 1.3758813006419026,
      "grad_norm": 0.7123023271560669,
      "learning_rate": 2.7092841595281567e-05,
      "loss": 0.1451,
      "step": 52300
    },
    {
      "epoch": 1.3771966747342943,
      "grad_norm": 1.186208963394165,
      "learning_rate": 2.707089945232411e-05,
      "loss": 0.1453,
      "step": 52350
    },
    {
      "epoch": 1.3785120488266864,
      "grad_norm": 1.0533497333526611,
      "learning_rate": 2.704895730936666e-05,
      "loss": 0.1479,
      "step": 52400
    },
    {
      "epoch": 1.3798274229190781,
      "grad_norm": 0.834550142288208,
      "learning_rate": 2.7027015166409213e-05,
      "loss": 0.1438,
      "step": 52450
    },
    {
      "epoch": 1.38114279701147,
      "grad_norm": 0.8432106375694275,
      "learning_rate": 2.7005073023451767e-05,
      "loss": 0.1462,
      "step": 52500
    },
    {
      "epoch": 1.382458171103862,
      "grad_norm": 1.126179575920105,
      "learning_rate": 2.698313088049431e-05,
      "loss": 0.1475,
      "step": 52550
    },
    {
      "epoch": 1.3837735451962538,
      "grad_norm": 1.0784944295883179,
      "learning_rate": 2.6961188737536862e-05,
      "loss": 0.1451,
      "step": 52600
    },
    {
      "epoch": 1.3850889192886457,
      "grad_norm": 0.7745890617370605,
      "learning_rate": 2.6939246594579416e-05,
      "loss": 0.1459,
      "step": 52650
    },
    {
      "epoch": 1.3864042933810374,
      "grad_norm": 0.8734515905380249,
      "learning_rate": 2.6917304451621967e-05,
      "loss": 0.1489,
      "step": 52700
    },
    {
      "epoch": 1.3877196674734296,
      "grad_norm": 0.7262606620788574,
      "learning_rate": 2.689536230866451e-05,
      "loss": 0.148,
      "step": 52750
    },
    {
      "epoch": 1.3890350415658212,
      "grad_norm": 0.9875137209892273,
      "learning_rate": 2.6873420165707065e-05,
      "loss": 0.1468,
      "step": 52800
    },
    {
      "epoch": 1.3903504156582132,
      "grad_norm": 0.8786176443099976,
      "learning_rate": 2.6851478022749616e-05,
      "loss": 0.1449,
      "step": 52850
    },
    {
      "epoch": 1.391665789750605,
      "grad_norm": 0.8606345653533936,
      "learning_rate": 2.6829535879792167e-05,
      "loss": 0.1497,
      "step": 52900
    },
    {
      "epoch": 1.392981163842997,
      "grad_norm": 0.7612438201904297,
      "learning_rate": 2.6807593736834714e-05,
      "loss": 0.1434,
      "step": 52950
    },
    {
      "epoch": 1.3942965379353889,
      "grad_norm": 0.8855509757995605,
      "learning_rate": 2.6785651593877265e-05,
      "loss": 0.1426,
      "step": 53000
    },
    {
      "epoch": 1.3956119120277806,
      "grad_norm": 0.9782301187515259,
      "learning_rate": 2.6763709450919816e-05,
      "loss": 0.1442,
      "step": 53050
    },
    {
      "epoch": 1.3969272861201727,
      "grad_norm": 1.0293757915496826,
      "learning_rate": 2.6741767307962367e-05,
      "loss": 0.1437,
      "step": 53100
    },
    {
      "epoch": 1.3982426602125644,
      "grad_norm": 0.7649818658828735,
      "learning_rate": 2.6719825165004915e-05,
      "loss": 0.1428,
      "step": 53150
    },
    {
      "epoch": 1.3995580343049563,
      "grad_norm": 0.8309119939804077,
      "learning_rate": 2.6697883022047465e-05,
      "loss": 0.1457,
      "step": 53200
    },
    {
      "epoch": 1.4008734083973482,
      "grad_norm": 1.0252660512924194,
      "learning_rate": 2.6675940879090016e-05,
      "loss": 0.146,
      "step": 53250
    },
    {
      "epoch": 1.40218878248974,
      "grad_norm": 0.9824946522712708,
      "learning_rate": 2.6653998736132567e-05,
      "loss": 0.1436,
      "step": 53300
    },
    {
      "epoch": 1.403504156582132,
      "grad_norm": 0.9605703949928284,
      "learning_rate": 2.663205659317512e-05,
      "loss": 0.1469,
      "step": 53350
    },
    {
      "epoch": 1.4048195306745237,
      "grad_norm": 0.7898823022842407,
      "learning_rate": 2.6610114450217666e-05,
      "loss": 0.1498,
      "step": 53400
    },
    {
      "epoch": 1.4061349047669158,
      "grad_norm": 0.970212459564209,
      "learning_rate": 2.6588172307260216e-05,
      "loss": 0.1456,
      "step": 53450
    },
    {
      "epoch": 1.4074502788593075,
      "grad_norm": 0.9827090501785278,
      "learning_rate": 2.6566230164302767e-05,
      "loss": 0.1431,
      "step": 53500
    },
    {
      "epoch": 1.4087656529516994,
      "grad_norm": 0.8954074382781982,
      "learning_rate": 2.654428802134532e-05,
      "loss": 0.1429,
      "step": 53550
    },
    {
      "epoch": 1.4100810270440913,
      "grad_norm": 0.832019567489624,
      "learning_rate": 2.6522345878387866e-05,
      "loss": 0.1449,
      "step": 53600
    },
    {
      "epoch": 1.4113964011364832,
      "grad_norm": 0.9637121558189392,
      "learning_rate": 2.6500403735430417e-05,
      "loss": 0.1471,
      "step": 53650
    },
    {
      "epoch": 1.4127117752288751,
      "grad_norm": 0.970429003238678,
      "learning_rate": 2.647846159247297e-05,
      "loss": 0.1401,
      "step": 53700
    },
    {
      "epoch": 1.4140271493212668,
      "grad_norm": 0.6324987411499023,
      "learning_rate": 2.645651944951552e-05,
      "loss": 0.1448,
      "step": 53750
    },
    {
      "epoch": 1.415342523413659,
      "grad_norm": 0.9193448424339294,
      "learning_rate": 2.6434577306558066e-05,
      "loss": 0.145,
      "step": 53800
    },
    {
      "epoch": 1.4166578975060506,
      "grad_norm": 0.9640066623687744,
      "learning_rate": 2.641263516360062e-05,
      "loss": 0.1464,
      "step": 53850
    },
    {
      "epoch": 1.4179732715984426,
      "grad_norm": 0.9399828314781189,
      "learning_rate": 2.639069302064317e-05,
      "loss": 0.1437,
      "step": 53900
    },
    {
      "epoch": 1.4192886456908345,
      "grad_norm": 0.963674783706665,
      "learning_rate": 2.6368750877685722e-05,
      "loss": 0.1425,
      "step": 53950
    },
    {
      "epoch": 1.4206040197832264,
      "grad_norm": 1.0343341827392578,
      "learning_rate": 2.634680873472827e-05,
      "loss": 0.1504,
      "step": 54000
    },
    {
      "epoch": 1.4219193938756183,
      "grad_norm": 0.8110983371734619,
      "learning_rate": 2.632486659177082e-05,
      "loss": 0.1455,
      "step": 54050
    },
    {
      "epoch": 1.4232347679680102,
      "grad_norm": 0.853410005569458,
      "learning_rate": 2.630292444881337e-05,
      "loss": 0.1443,
      "step": 54100
    },
    {
      "epoch": 1.424550142060402,
      "grad_norm": 0.8322981595993042,
      "learning_rate": 2.6280982305855922e-05,
      "loss": 0.1446,
      "step": 54150
    },
    {
      "epoch": 1.4258655161527938,
      "grad_norm": 0.9756702184677124,
      "learning_rate": 2.625904016289847e-05,
      "loss": 0.1436,
      "step": 54200
    },
    {
      "epoch": 1.4271808902451857,
      "grad_norm": 0.8724592924118042,
      "learning_rate": 2.623709801994102e-05,
      "loss": 0.1463,
      "step": 54250
    },
    {
      "epoch": 1.4284962643375776,
      "grad_norm": 1.0516709089279175,
      "learning_rate": 2.621515587698357e-05,
      "loss": 0.1473,
      "step": 54300
    },
    {
      "epoch": 1.4298116384299695,
      "grad_norm": 0.9024180769920349,
      "learning_rate": 2.6193213734026122e-05,
      "loss": 0.1442,
      "step": 54350
    },
    {
      "epoch": 1.4311270125223614,
      "grad_norm": 0.7459668517112732,
      "learning_rate": 2.617127159106867e-05,
      "loss": 0.1434,
      "step": 54400
    },
    {
      "epoch": 1.4324423866147533,
      "grad_norm": 1.0231541395187378,
      "learning_rate": 2.614932944811122e-05,
      "loss": 0.1434,
      "step": 54450
    },
    {
      "epoch": 1.4337577607071452,
      "grad_norm": 0.8064700961112976,
      "learning_rate": 2.612738730515377e-05,
      "loss": 0.1461,
      "step": 54500
    },
    {
      "epoch": 1.435073134799537,
      "grad_norm": 0.9358168244361877,
      "learning_rate": 2.6105445162196322e-05,
      "loss": 0.1455,
      "step": 54550
    },
    {
      "epoch": 1.4363885088919288,
      "grad_norm": 0.8915771842002869,
      "learning_rate": 2.608350301923887e-05,
      "loss": 0.1385,
      "step": 54600
    },
    {
      "epoch": 1.4377038829843207,
      "grad_norm": 1.0088918209075928,
      "learning_rate": 2.606156087628142e-05,
      "loss": 0.142,
      "step": 54650
    },
    {
      "epoch": 1.4390192570767126,
      "grad_norm": 0.8546068668365479,
      "learning_rate": 2.603961873332397e-05,
      "loss": 0.1429,
      "step": 54700
    },
    {
      "epoch": 1.4403346311691045,
      "grad_norm": 1.0364890098571777,
      "learning_rate": 2.6017676590366525e-05,
      "loss": 0.1433,
      "step": 54750
    },
    {
      "epoch": 1.4416500052614964,
      "grad_norm": 0.892755389213562,
      "learning_rate": 2.599573444740907e-05,
      "loss": 0.1413,
      "step": 54800
    },
    {
      "epoch": 1.4429653793538884,
      "grad_norm": 1.108627438545227,
      "learning_rate": 2.597379230445162e-05,
      "loss": 0.1437,
      "step": 54850
    },
    {
      "epoch": 1.44428075344628,
      "grad_norm": 0.9452323913574219,
      "learning_rate": 2.5951850161494175e-05,
      "loss": 0.1415,
      "step": 54900
    },
    {
      "epoch": 1.445596127538672,
      "grad_norm": 0.8889461755752563,
      "learning_rate": 2.5929908018536726e-05,
      "loss": 0.1425,
      "step": 54950
    },
    {
      "epoch": 1.4469115016310639,
      "grad_norm": 0.9981086254119873,
      "learning_rate": 2.5907965875579276e-05,
      "loss": 0.1423,
      "step": 55000
    },
    {
      "epoch": 1.4482268757234558,
      "grad_norm": 0.7203033566474915,
      "learning_rate": 2.5886023732621824e-05,
      "loss": 0.1458,
      "step": 55050
    },
    {
      "epoch": 1.4495422498158477,
      "grad_norm": 0.8360198736190796,
      "learning_rate": 2.5864081589664375e-05,
      "loss": 0.1444,
      "step": 55100
    },
    {
      "epoch": 1.4508576239082396,
      "grad_norm": 0.8731533885002136,
      "learning_rate": 2.5842139446706926e-05,
      "loss": 0.1421,
      "step": 55150
    },
    {
      "epoch": 1.4521729980006315,
      "grad_norm": 1.236410140991211,
      "learning_rate": 2.5820197303749477e-05,
      "loss": 0.1414,
      "step": 55200
    },
    {
      "epoch": 1.4534883720930232,
      "grad_norm": 0.9223853945732117,
      "learning_rate": 2.5798255160792024e-05,
      "loss": 0.1393,
      "step": 55250
    },
    {
      "epoch": 1.454803746185415,
      "grad_norm": 0.9480034112930298,
      "learning_rate": 2.5776313017834575e-05,
      "loss": 0.1405,
      "step": 55300
    },
    {
      "epoch": 1.456119120277807,
      "grad_norm": 0.9531430006027222,
      "learning_rate": 2.5754370874877126e-05,
      "loss": 0.1424,
      "step": 55350
    },
    {
      "epoch": 1.457434494370199,
      "grad_norm": 0.9932374954223633,
      "learning_rate": 2.5732428731919677e-05,
      "loss": 0.1418,
      "step": 55400
    },
    {
      "epoch": 1.4587498684625908,
      "grad_norm": 0.8894773721694946,
      "learning_rate": 2.5710486588962224e-05,
      "loss": 0.1387,
      "step": 55450
    },
    {
      "epoch": 1.4600652425549827,
      "grad_norm": 1.0270172357559204,
      "learning_rate": 2.5688544446004775e-05,
      "loss": 0.1401,
      "step": 55500
    },
    {
      "epoch": 1.4613806166473746,
      "grad_norm": 0.7353922128677368,
      "learning_rate": 2.5666602303047326e-05,
      "loss": 0.1413,
      "step": 55550
    },
    {
      "epoch": 1.4626959907397663,
      "grad_norm": 0.8693498373031616,
      "learning_rate": 2.5644660160089877e-05,
      "loss": 0.1446,
      "step": 55600
    },
    {
      "epoch": 1.4640113648321582,
      "grad_norm": 0.8838018774986267,
      "learning_rate": 2.5622718017132424e-05,
      "loss": 0.1438,
      "step": 55650
    },
    {
      "epoch": 1.4653267389245501,
      "grad_norm": 0.8793303370475769,
      "learning_rate": 2.5600775874174975e-05,
      "loss": 0.144,
      "step": 55700
    },
    {
      "epoch": 1.466642113016942,
      "grad_norm": 0.7809419631958008,
      "learning_rate": 2.5578833731217526e-05,
      "loss": 0.143,
      "step": 55750
    },
    {
      "epoch": 1.467957487109334,
      "grad_norm": 0.9410657286643982,
      "learning_rate": 2.555689158826008e-05,
      "loss": 0.1402,
      "step": 55800
    },
    {
      "epoch": 1.4692728612017258,
      "grad_norm": 1.0794154405593872,
      "learning_rate": 2.5534949445302624e-05,
      "loss": 0.1434,
      "step": 55850
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.030908226966858,
      "learning_rate": 2.5513007302345175e-05,
      "loss": 0.139,
      "step": 55900
    },
    {
      "epoch": 1.4719036093865094,
      "grad_norm": 0.8652946352958679,
      "learning_rate": 2.549106515938773e-05,
      "loss": 0.144,
      "step": 55950
    },
    {
      "epoch": 1.4732189834789013,
      "grad_norm": 0.9445880651473999,
      "learning_rate": 2.546912301643028e-05,
      "loss": 0.1406,
      "step": 56000
    },
    {
      "epoch": 1.4745343575712933,
      "grad_norm": 0.9325875043869019,
      "learning_rate": 2.5447180873472824e-05,
      "loss": 0.1424,
      "step": 56050
    },
    {
      "epoch": 1.4758497316636852,
      "grad_norm": 0.8805993795394897,
      "learning_rate": 2.542523873051538e-05,
      "loss": 0.141,
      "step": 56100
    },
    {
      "epoch": 1.477165105756077,
      "grad_norm": 1.0815074443817139,
      "learning_rate": 2.540329658755793e-05,
      "loss": 0.14,
      "step": 56150
    },
    {
      "epoch": 1.478480479848469,
      "grad_norm": 0.8912800550460815,
      "learning_rate": 2.538135444460048e-05,
      "loss": 0.1432,
      "step": 56200
    },
    {
      "epoch": 1.4797958539408609,
      "grad_norm": 1.0961273908615112,
      "learning_rate": 2.5359412301643028e-05,
      "loss": 0.1421,
      "step": 56250
    },
    {
      "epoch": 1.4811112280332526,
      "grad_norm": 1.6123508214950562,
      "learning_rate": 2.533747015868558e-05,
      "loss": 0.1408,
      "step": 56300
    },
    {
      "epoch": 1.4824266021256445,
      "grad_norm": 0.8893880844116211,
      "learning_rate": 2.531552801572813e-05,
      "loss": 0.1417,
      "step": 56350
    },
    {
      "epoch": 1.4837419762180364,
      "grad_norm": 0.772720992565155,
      "learning_rate": 2.529358587277068e-05,
      "loss": 0.1389,
      "step": 56400
    },
    {
      "epoch": 1.4850573503104283,
      "grad_norm": 0.9478281140327454,
      "learning_rate": 2.5271643729813228e-05,
      "loss": 0.143,
      "step": 56450
    },
    {
      "epoch": 1.4863727244028202,
      "grad_norm": 1.0275975465774536,
      "learning_rate": 2.524970158685578e-05,
      "loss": 0.1425,
      "step": 56500
    },
    {
      "epoch": 1.487688098495212,
      "grad_norm": 0.9844318628311157,
      "learning_rate": 2.522775944389833e-05,
      "loss": 0.1431,
      "step": 56550
    },
    {
      "epoch": 1.489003472587604,
      "grad_norm": 0.9732376933097839,
      "learning_rate": 2.520581730094088e-05,
      "loss": 0.1413,
      "step": 56600
    },
    {
      "epoch": 1.4903188466799957,
      "grad_norm": 0.9442034959793091,
      "learning_rate": 2.518387515798343e-05,
      "loss": 0.1419,
      "step": 56650
    },
    {
      "epoch": 1.4916342207723876,
      "grad_norm": 0.9657813906669617,
      "learning_rate": 2.516193301502598e-05,
      "loss": 0.1443,
      "step": 56700
    },
    {
      "epoch": 1.4929495948647795,
      "grad_norm": 0.9220826625823975,
      "learning_rate": 2.513999087206853e-05,
      "loss": 0.1378,
      "step": 56750
    },
    {
      "epoch": 1.4942649689571714,
      "grad_norm": 0.9887006282806396,
      "learning_rate": 2.511804872911108e-05,
      "loss": 0.1407,
      "step": 56800
    },
    {
      "epoch": 1.4955803430495633,
      "grad_norm": 1.117362141609192,
      "learning_rate": 2.5096106586153635e-05,
      "loss": 0.1401,
      "step": 56850
    },
    {
      "epoch": 1.4968957171419552,
      "grad_norm": 0.9576457142829895,
      "learning_rate": 2.507416444319618e-05,
      "loss": 0.1405,
      "step": 56900
    },
    {
      "epoch": 1.4982110912343471,
      "grad_norm": 0.8790138959884644,
      "learning_rate": 2.505222230023873e-05,
      "loss": 0.1428,
      "step": 56950
    },
    {
      "epoch": 1.4995264653267388,
      "grad_norm": 0.9742581844329834,
      "learning_rate": 2.5030280157281284e-05,
      "loss": 0.1425,
      "step": 57000
    },
    {
      "epoch": 1.500841839419131,
      "grad_norm": 0.9523540139198303,
      "learning_rate": 2.5008338014323835e-05,
      "loss": 0.1452,
      "step": 57050
    },
    {
      "epoch": 1.5021572135115226,
      "grad_norm": 0.7377769351005554,
      "learning_rate": 2.4986395871366383e-05,
      "loss": 0.1431,
      "step": 57100
    },
    {
      "epoch": 1.5034725876039146,
      "grad_norm": 0.9147819876670837,
      "learning_rate": 2.4964453728408933e-05,
      "loss": 0.1398,
      "step": 57150
    },
    {
      "epoch": 1.5047879616963065,
      "grad_norm": 0.74788898229599,
      "learning_rate": 2.4942511585451484e-05,
      "loss": 0.1424,
      "step": 57200
    },
    {
      "epoch": 1.5061033357886981,
      "grad_norm": 0.8907197713851929,
      "learning_rate": 2.4920569442494032e-05,
      "loss": 0.1394,
      "step": 57250
    },
    {
      "epoch": 1.5074187098810903,
      "grad_norm": 0.7695128321647644,
      "learning_rate": 2.4898627299536583e-05,
      "loss": 0.14,
      "step": 57300
    },
    {
      "epoch": 1.508734083973482,
      "grad_norm": 0.8451573848724365,
      "learning_rate": 2.4876685156579133e-05,
      "loss": 0.1404,
      "step": 57350
    },
    {
      "epoch": 1.510049458065874,
      "grad_norm": 0.8990734815597534,
      "learning_rate": 2.4854743013621684e-05,
      "loss": 0.1396,
      "step": 57400
    },
    {
      "epoch": 1.5113648321582658,
      "grad_norm": 0.8273406624794006,
      "learning_rate": 2.4832800870664232e-05,
      "loss": 0.1378,
      "step": 57450
    },
    {
      "epoch": 1.5126802062506577,
      "grad_norm": 0.7712962627410889,
      "learning_rate": 2.4810858727706786e-05,
      "loss": 0.1381,
      "step": 57500
    },
    {
      "epoch": 1.5139955803430496,
      "grad_norm": 0.8691213130950928,
      "learning_rate": 2.4788916584749334e-05,
      "loss": 0.1394,
      "step": 57550
    },
    {
      "epoch": 1.5153109544354413,
      "grad_norm": 0.71442711353302,
      "learning_rate": 2.4766974441791884e-05,
      "loss": 0.1383,
      "step": 57600
    },
    {
      "epoch": 1.5166263285278334,
      "grad_norm": 0.9800564646720886,
      "learning_rate": 2.4745032298834432e-05,
      "loss": 0.1384,
      "step": 57650
    },
    {
      "epoch": 1.517941702620225,
      "grad_norm": 1.2086155414581299,
      "learning_rate": 2.4723090155876986e-05,
      "loss": 0.1382,
      "step": 57700
    },
    {
      "epoch": 1.5192570767126172,
      "grad_norm": 0.7847687005996704,
      "learning_rate": 2.4701148012919534e-05,
      "loss": 0.1358,
      "step": 57750
    },
    {
      "epoch": 1.520572450805009,
      "grad_norm": 0.8204108476638794,
      "learning_rate": 2.4679205869962085e-05,
      "loss": 0.1395,
      "step": 57800
    },
    {
      "epoch": 1.5218878248974008,
      "grad_norm": 1.0349684953689575,
      "learning_rate": 2.4657263727004635e-05,
      "loss": 0.1405,
      "step": 57850
    },
    {
      "epoch": 1.5232031989897927,
      "grad_norm": 0.8464792966842651,
      "learning_rate": 2.4635321584047186e-05,
      "loss": 0.1426,
      "step": 57900
    },
    {
      "epoch": 1.5245185730821844,
      "grad_norm": 0.8783540725708008,
      "learning_rate": 2.4613379441089734e-05,
      "loss": 0.1385,
      "step": 57950
    },
    {
      "epoch": 1.5258339471745765,
      "grad_norm": 0.8956618309020996,
      "learning_rate": 2.4591437298132285e-05,
      "loss": 0.1414,
      "step": 58000
    },
    {
      "epoch": 1.5271493212669682,
      "grad_norm": 0.7827866673469543,
      "learning_rate": 2.4569495155174836e-05,
      "loss": 0.139,
      "step": 58050
    },
    {
      "epoch": 1.5284646953593604,
      "grad_norm": 0.9284054636955261,
      "learning_rate": 2.4547553012217386e-05,
      "loss": 0.1375,
      "step": 58100
    },
    {
      "epoch": 1.529780069451752,
      "grad_norm": 0.8367559909820557,
      "learning_rate": 2.4525610869259937e-05,
      "loss": 0.1408,
      "step": 58150
    },
    {
      "epoch": 1.531095443544144,
      "grad_norm": 0.8584262728691101,
      "learning_rate": 2.4503668726302488e-05,
      "loss": 0.1418,
      "step": 58200
    },
    {
      "epoch": 1.5324108176365359,
      "grad_norm": 0.6596120595932007,
      "learning_rate": 2.448172658334504e-05,
      "loss": 0.1417,
      "step": 58250
    },
    {
      "epoch": 1.5337261917289275,
      "grad_norm": 1.0512332916259766,
      "learning_rate": 2.4459784440387586e-05,
      "loss": 0.1393,
      "step": 58300
    },
    {
      "epoch": 1.5350415658213197,
      "grad_norm": 0.8768524527549744,
      "learning_rate": 2.4437842297430137e-05,
      "loss": 0.1405,
      "step": 58350
    },
    {
      "epoch": 1.5363569399137114,
      "grad_norm": 1.0783127546310425,
      "learning_rate": 2.4415900154472688e-05,
      "loss": 0.1391,
      "step": 58400
    },
    {
      "epoch": 1.5376723140061035,
      "grad_norm": 0.7491434812545776,
      "learning_rate": 2.439395801151524e-05,
      "loss": 0.1403,
      "step": 58450
    },
    {
      "epoch": 1.5389876880984952,
      "grad_norm": 0.8517662286758423,
      "learning_rate": 2.4372015868557787e-05,
      "loss": 0.1404,
      "step": 58500
    },
    {
      "epoch": 1.540303062190887,
      "grad_norm": 0.8445749878883362,
      "learning_rate": 2.435007372560034e-05,
      "loss": 0.1391,
      "step": 58550
    },
    {
      "epoch": 1.541618436283279,
      "grad_norm": 0.8932766914367676,
      "learning_rate": 2.432813158264289e-05,
      "loss": 0.1348,
      "step": 58600
    },
    {
      "epoch": 1.5429338103756707,
      "grad_norm": 1.0088155269622803,
      "learning_rate": 2.430618943968544e-05,
      "loss": 0.1406,
      "step": 58650
    },
    {
      "epoch": 1.5442491844680628,
      "grad_norm": 0.8546188473701477,
      "learning_rate": 2.4284247296727987e-05,
      "loss": 0.1381,
      "step": 58700
    },
    {
      "epoch": 1.5455645585604545,
      "grad_norm": 0.8363637924194336,
      "learning_rate": 2.426230515377054e-05,
      "loss": 0.1393,
      "step": 58750
    },
    {
      "epoch": 1.5468799326528466,
      "grad_norm": 0.6758713722229004,
      "learning_rate": 2.424036301081309e-05,
      "loss": 0.135,
      "step": 58800
    },
    {
      "epoch": 1.5481953067452383,
      "grad_norm": 1.1862316131591797,
      "learning_rate": 2.421842086785564e-05,
      "loss": 0.1369,
      "step": 58850
    },
    {
      "epoch": 1.5495106808376302,
      "grad_norm": 0.9091933965682983,
      "learning_rate": 2.419647872489819e-05,
      "loss": 0.1377,
      "step": 58900
    },
    {
      "epoch": 1.5508260549300221,
      "grad_norm": 0.8713054656982422,
      "learning_rate": 2.417453658194074e-05,
      "loss": 0.1376,
      "step": 58950
    },
    {
      "epoch": 1.5521414290224138,
      "grad_norm": 0.968087911605835,
      "learning_rate": 2.415259443898329e-05,
      "loss": 0.1393,
      "step": 59000
    },
    {
      "epoch": 1.553456803114806,
      "grad_norm": 0.9848141074180603,
      "learning_rate": 2.413065229602584e-05,
      "loss": 0.1398,
      "step": 59050
    },
    {
      "epoch": 1.5547721772071976,
      "grad_norm": 0.9275456070899963,
      "learning_rate": 2.410871015306839e-05,
      "loss": 0.1375,
      "step": 59100
    },
    {
      "epoch": 1.5560875512995898,
      "grad_norm": 0.8550410270690918,
      "learning_rate": 2.408676801011094e-05,
      "loss": 0.1402,
      "step": 59150
    },
    {
      "epoch": 1.5574029253919814,
      "grad_norm": 0.8092194199562073,
      "learning_rate": 2.406482586715349e-05,
      "loss": 0.1378,
      "step": 59200
    },
    {
      "epoch": 1.5587182994843733,
      "grad_norm": 1.0159165859222412,
      "learning_rate": 2.4042883724196043e-05,
      "loss": 0.1385,
      "step": 59250
    },
    {
      "epoch": 1.5600336735767653,
      "grad_norm": 0.8976370692253113,
      "learning_rate": 2.402094158123859e-05,
      "loss": 0.1417,
      "step": 59300
    },
    {
      "epoch": 1.561349047669157,
      "grad_norm": 0.9745861887931824,
      "learning_rate": 2.399899943828114e-05,
      "loss": 0.1405,
      "step": 59350
    },
    {
      "epoch": 1.562664421761549,
      "grad_norm": 0.8501421809196472,
      "learning_rate": 2.3977057295323692e-05,
      "loss": 0.1383,
      "step": 59400
    },
    {
      "epoch": 1.5639797958539408,
      "grad_norm": 0.9340000748634338,
      "learning_rate": 2.3955115152366243e-05,
      "loss": 0.1359,
      "step": 59450
    },
    {
      "epoch": 1.5652951699463329,
      "grad_norm": 0.8409644365310669,
      "learning_rate": 2.393317300940879e-05,
      "loss": 0.1366,
      "step": 59500
    },
    {
      "epoch": 1.5666105440387246,
      "grad_norm": 0.9962880611419678,
      "learning_rate": 2.391123086645134e-05,
      "loss": 0.1381,
      "step": 59550
    },
    {
      "epoch": 1.5679259181311165,
      "grad_norm": 0.8519137501716614,
      "learning_rate": 2.3889288723493892e-05,
      "loss": 0.1389,
      "step": 59600
    },
    {
      "epoch": 1.5692412922235084,
      "grad_norm": 0.7517113089561462,
      "learning_rate": 2.3867346580536443e-05,
      "loss": 0.1366,
      "step": 59650
    },
    {
      "epoch": 1.5705566663159003,
      "grad_norm": 0.7959763407707214,
      "learning_rate": 2.3845404437578994e-05,
      "loss": 0.1356,
      "step": 59700
    },
    {
      "epoch": 1.5718720404082922,
      "grad_norm": 0.9971494078636169,
      "learning_rate": 2.382346229462154e-05,
      "loss": 0.1368,
      "step": 59750
    },
    {
      "epoch": 1.573187414500684,
      "grad_norm": 0.9942468404769897,
      "learning_rate": 2.3801520151664096e-05,
      "loss": 0.137,
      "step": 59800
    },
    {
      "epoch": 1.574502788593076,
      "grad_norm": 0.8668666481971741,
      "learning_rate": 2.3779578008706643e-05,
      "loss": 0.1383,
      "step": 59850
    },
    {
      "epoch": 1.5758181626854677,
      "grad_norm": 0.9662542343139648,
      "learning_rate": 2.3757635865749194e-05,
      "loss": 0.139,
      "step": 59900
    },
    {
      "epoch": 1.5771335367778596,
      "grad_norm": 0.917625367641449,
      "learning_rate": 2.3735693722791745e-05,
      "loss": 0.137,
      "step": 59950
    },
    {
      "epoch": 1.5784489108702515,
      "grad_norm": 0.9919158816337585,
      "learning_rate": 2.3713751579834296e-05,
      "loss": 0.1384,
      "step": 60000
    },
    {
      "epoch": 1.5797642849626434,
      "grad_norm": 0.7073058485984802,
      "learning_rate": 2.3691809436876843e-05,
      "loss": 0.1389,
      "step": 60050
    },
    {
      "epoch": 1.5810796590550353,
      "grad_norm": 0.8695790767669678,
      "learning_rate": 2.3669867293919394e-05,
      "loss": 0.1362,
      "step": 60100
    },
    {
      "epoch": 1.582395033147427,
      "grad_norm": 0.8927817344665527,
      "learning_rate": 2.3647925150961945e-05,
      "loss": 0.135,
      "step": 60150
    },
    {
      "epoch": 1.5837104072398192,
      "grad_norm": 0.8127060532569885,
      "learning_rate": 2.3625983008004496e-05,
      "loss": 0.139,
      "step": 60200
    },
    {
      "epoch": 1.5850257813322108,
      "grad_norm": 0.8882736563682556,
      "learning_rate": 2.3604040865047043e-05,
      "loss": 0.1367,
      "step": 60250
    },
    {
      "epoch": 1.5863411554246027,
      "grad_norm": 0.7318518161773682,
      "learning_rate": 2.3582098722089598e-05,
      "loss": 0.1367,
      "step": 60300
    },
    {
      "epoch": 1.5876565295169947,
      "grad_norm": 0.7547959685325623,
      "learning_rate": 2.3560156579132145e-05,
      "loss": 0.138,
      "step": 60350
    },
    {
      "epoch": 1.5889719036093866,
      "grad_norm": 0.9773350954055786,
      "learning_rate": 2.3538214436174696e-05,
      "loss": 0.1403,
      "step": 60400
    },
    {
      "epoch": 1.5902872777017785,
      "grad_norm": 0.8035926818847656,
      "learning_rate": 2.3516272293217247e-05,
      "loss": 0.1389,
      "step": 60450
    },
    {
      "epoch": 1.5916026517941702,
      "grad_norm": 0.9874709248542786,
      "learning_rate": 2.3494330150259798e-05,
      "loss": 0.1383,
      "step": 60500
    },
    {
      "epoch": 1.5929180258865623,
      "grad_norm": 0.8035545349121094,
      "learning_rate": 2.3472388007302345e-05,
      "loss": 0.1427,
      "step": 60550
    },
    {
      "epoch": 1.594233399978954,
      "grad_norm": 1.0794596672058105,
      "learning_rate": 2.3450445864344896e-05,
      "loss": 0.1384,
      "step": 60600
    },
    {
      "epoch": 1.5955487740713459,
      "grad_norm": 0.830872654914856,
      "learning_rate": 2.3428503721387447e-05,
      "loss": 0.1378,
      "step": 60650
    },
    {
      "epoch": 1.5968641481637378,
      "grad_norm": 0.9237543344497681,
      "learning_rate": 2.3406561578429998e-05,
      "loss": 0.1344,
      "step": 60700
    },
    {
      "epoch": 1.5981795222561297,
      "grad_norm": 0.7974511981010437,
      "learning_rate": 2.3384619435472545e-05,
      "loss": 0.1395,
      "step": 60750
    },
    {
      "epoch": 1.5994948963485216,
      "grad_norm": 0.7302340865135193,
      "learning_rate": 2.3362677292515096e-05,
      "loss": 0.1385,
      "step": 60800
    },
    {
      "epoch": 1.6008102704409133,
      "grad_norm": 0.8453389406204224,
      "learning_rate": 2.3340735149557647e-05,
      "loss": 0.1381,
      "step": 60850
    },
    {
      "epoch": 1.6021256445333054,
      "grad_norm": 0.8718352913856506,
      "learning_rate": 2.3318793006600198e-05,
      "loss": 0.1356,
      "step": 60900
    },
    {
      "epoch": 1.603441018625697,
      "grad_norm": 1.1347764730453491,
      "learning_rate": 2.3296850863642745e-05,
      "loss": 0.1387,
      "step": 60950
    },
    {
      "epoch": 1.604756392718089,
      "grad_norm": 0.8015960454940796,
      "learning_rate": 2.32749087206853e-05,
      "loss": 0.1374,
      "step": 61000
    },
    {
      "epoch": 1.606071766810481,
      "grad_norm": 0.7039737105369568,
      "learning_rate": 2.3252966577727847e-05,
      "loss": 0.1342,
      "step": 61050
    },
    {
      "epoch": 1.6073871409028728,
      "grad_norm": 0.9212237596511841,
      "learning_rate": 2.3231024434770398e-05,
      "loss": 0.1363,
      "step": 61100
    },
    {
      "epoch": 1.6087025149952647,
      "grad_norm": 0.8966885805130005,
      "learning_rate": 2.320908229181295e-05,
      "loss": 0.137,
      "step": 61150
    },
    {
      "epoch": 1.6100178890876564,
      "grad_norm": 0.7469978928565979,
      "learning_rate": 2.31871401488555e-05,
      "loss": 0.1329,
      "step": 61200
    },
    {
      "epoch": 1.6113332631800485,
      "grad_norm": 0.8343100547790527,
      "learning_rate": 2.3165198005898047e-05,
      "loss": 0.1375,
      "step": 61250
    },
    {
      "epoch": 1.6126486372724402,
      "grad_norm": 0.85671466588974,
      "learning_rate": 2.3143255862940598e-05,
      "loss": 0.1355,
      "step": 61300
    },
    {
      "epoch": 1.6139640113648321,
      "grad_norm": 0.9890933036804199,
      "learning_rate": 2.3121313719983152e-05,
      "loss": 0.1357,
      "step": 61350
    },
    {
      "epoch": 1.615279385457224,
      "grad_norm": 0.8176432847976685,
      "learning_rate": 2.30993715770257e-05,
      "loss": 0.1341,
      "step": 61400
    },
    {
      "epoch": 1.616594759549616,
      "grad_norm": 0.8241105675697327,
      "learning_rate": 2.307742943406825e-05,
      "loss": 0.1348,
      "step": 61450
    },
    {
      "epoch": 1.6179101336420079,
      "grad_norm": 0.9149065017700195,
      "learning_rate": 2.30554872911108e-05,
      "loss": 0.1392,
      "step": 61500
    },
    {
      "epoch": 1.6192255077343995,
      "grad_norm": 0.7992520332336426,
      "learning_rate": 2.3033545148153352e-05,
      "loss": 0.1375,
      "step": 61550
    },
    {
      "epoch": 1.6205408818267917,
      "grad_norm": 0.8022565245628357,
      "learning_rate": 2.30116030051959e-05,
      "loss": 0.1341,
      "step": 61600
    },
    {
      "epoch": 1.6218562559191834,
      "grad_norm": 0.8796473741531372,
      "learning_rate": 2.298966086223845e-05,
      "loss": 0.1368,
      "step": 61650
    },
    {
      "epoch": 1.6231716300115753,
      "grad_norm": 0.898888349533081,
      "learning_rate": 2.2967718719281e-05,
      "loss": 0.1353,
      "step": 61700
    },
    {
      "epoch": 1.6244870041039672,
      "grad_norm": 0.7867677807807922,
      "learning_rate": 2.2945776576323553e-05,
      "loss": 0.136,
      "step": 61750
    },
    {
      "epoch": 1.625802378196359,
      "grad_norm": 0.7868123650550842,
      "learning_rate": 2.29238344333661e-05,
      "loss": 0.1328,
      "step": 61800
    },
    {
      "epoch": 1.627117752288751,
      "grad_norm": 0.9197472333908081,
      "learning_rate": 2.290189229040865e-05,
      "loss": 0.1351,
      "step": 61850
    },
    {
      "epoch": 1.6284331263811427,
      "grad_norm": 0.8260432481765747,
      "learning_rate": 2.2879950147451202e-05,
      "loss": 0.1361,
      "step": 61900
    },
    {
      "epoch": 1.6297485004735348,
      "grad_norm": 0.8668754696846008,
      "learning_rate": 2.2858008004493753e-05,
      "loss": 0.1361,
      "step": 61950
    },
    {
      "epoch": 1.6310638745659265,
      "grad_norm": 0.768106997013092,
      "learning_rate": 2.28360658615363e-05,
      "loss": 0.1355,
      "step": 62000
    },
    {
      "epoch": 1.6323792486583184,
      "grad_norm": 0.979441225528717,
      "learning_rate": 2.2814123718578854e-05,
      "loss": 0.138,
      "step": 62050
    },
    {
      "epoch": 1.6336946227507103,
      "grad_norm": 0.8409460783004761,
      "learning_rate": 2.2792181575621402e-05,
      "loss": 0.1373,
      "step": 62100
    },
    {
      "epoch": 1.6350099968431022,
      "grad_norm": 0.6632643938064575,
      "learning_rate": 2.2770239432663953e-05,
      "loss": 0.1351,
      "step": 62150
    },
    {
      "epoch": 1.6363253709354941,
      "grad_norm": 0.9772147536277771,
      "learning_rate": 2.2748297289706504e-05,
      "loss": 0.1375,
      "step": 62200
    },
    {
      "epoch": 1.6376407450278858,
      "grad_norm": 0.8367313146591187,
      "learning_rate": 2.2726355146749054e-05,
      "loss": 0.1364,
      "step": 62250
    },
    {
      "epoch": 1.638956119120278,
      "grad_norm": 1.0277482271194458,
      "learning_rate": 2.2704413003791602e-05,
      "loss": 0.1381,
      "step": 62300
    },
    {
      "epoch": 1.6402714932126696,
      "grad_norm": 0.9022959470748901,
      "learning_rate": 2.2682470860834153e-05,
      "loss": 0.1367,
      "step": 62350
    },
    {
      "epoch": 1.6415868673050615,
      "grad_norm": 0.9007865786552429,
      "learning_rate": 2.2660528717876704e-05,
      "loss": 0.1366,
      "step": 62400
    },
    {
      "epoch": 1.6429022413974534,
      "grad_norm": 0.8629292249679565,
      "learning_rate": 2.2638586574919255e-05,
      "loss": 0.1376,
      "step": 62450
    },
    {
      "epoch": 1.6442176154898454,
      "grad_norm": 0.8732835054397583,
      "learning_rate": 2.2616644431961802e-05,
      "loss": 0.135,
      "step": 62500
    },
    {
      "epoch": 1.6455329895822373,
      "grad_norm": 0.8934136033058167,
      "learning_rate": 2.2594702289004356e-05,
      "loss": 0.1322,
      "step": 62550
    },
    {
      "epoch": 1.646848363674629,
      "grad_norm": 0.8656080961227417,
      "learning_rate": 2.2572760146046904e-05,
      "loss": 0.136,
      "step": 62600
    },
    {
      "epoch": 1.648163737767021,
      "grad_norm": 0.5448434948921204,
      "learning_rate": 2.2550818003089455e-05,
      "loss": 0.1365,
      "step": 62650
    },
    {
      "epoch": 1.6494791118594128,
      "grad_norm": 0.8327257633209229,
      "learning_rate": 2.2528875860132002e-05,
      "loss": 0.1339,
      "step": 62700
    },
    {
      "epoch": 1.6507944859518047,
      "grad_norm": 0.7435446977615356,
      "learning_rate": 2.2506933717174556e-05,
      "loss": 0.1355,
      "step": 62750
    },
    {
      "epoch": 1.6521098600441966,
      "grad_norm": 0.7916914224624634,
      "learning_rate": 2.2484991574217104e-05,
      "loss": 0.1358,
      "step": 62800
    },
    {
      "epoch": 1.6534252341365885,
      "grad_norm": 0.741985023021698,
      "learning_rate": 2.2463049431259655e-05,
      "loss": 0.1329,
      "step": 62850
    },
    {
      "epoch": 1.6547406082289804,
      "grad_norm": 0.7881650924682617,
      "learning_rate": 2.2441107288302206e-05,
      "loss": 0.1339,
      "step": 62900
    },
    {
      "epoch": 1.656055982321372,
      "grad_norm": 0.7695444822311401,
      "learning_rate": 2.2419165145344756e-05,
      "loss": 0.1361,
      "step": 62950
    },
    {
      "epoch": 1.6573713564137642,
      "grad_norm": 0.7483851313591003,
      "learning_rate": 2.2397223002387307e-05,
      "loss": 0.1348,
      "step": 63000
    },
    {
      "epoch": 1.658686730506156,
      "grad_norm": 0.6738097071647644,
      "learning_rate": 2.2375280859429855e-05,
      "loss": 0.1328,
      "step": 63050
    },
    {
      "epoch": 1.6600021045985478,
      "grad_norm": 0.9114355444908142,
      "learning_rate": 2.235333871647241e-05,
      "loss": 0.1359,
      "step": 63100
    },
    {
      "epoch": 1.6613174786909397,
      "grad_norm": 0.7334577441215515,
      "learning_rate": 2.2331396573514957e-05,
      "loss": 0.1343,
      "step": 63150
    },
    {
      "epoch": 1.6626328527833316,
      "grad_norm": 0.8016119003295898,
      "learning_rate": 2.2309454430557507e-05,
      "loss": 0.134,
      "step": 63200
    },
    {
      "epoch": 1.6639482268757235,
      "grad_norm": 0.5462547540664673,
      "learning_rate": 2.228751228760006e-05,
      "loss": 0.1307,
      "step": 63250
    },
    {
      "epoch": 1.6652636009681152,
      "grad_norm": 0.952720046043396,
      "learning_rate": 2.226557014464261e-05,
      "loss": 0.1379,
      "step": 63300
    },
    {
      "epoch": 1.6665789750605073,
      "grad_norm": 0.7734595537185669,
      "learning_rate": 2.2243628001685157e-05,
      "loss": 0.1356,
      "step": 63350
    },
    {
      "epoch": 1.667894349152899,
      "grad_norm": 0.8668876886367798,
      "learning_rate": 2.2221685858727708e-05,
      "loss": 0.1361,
      "step": 63400
    },
    {
      "epoch": 1.669209723245291,
      "grad_norm": 1.077480673789978,
      "learning_rate": 2.219974371577026e-05,
      "loss": 0.1352,
      "step": 63450
    },
    {
      "epoch": 1.6705250973376828,
      "grad_norm": 0.7362070083618164,
      "learning_rate": 2.217780157281281e-05,
      "loss": 0.1349,
      "step": 63500
    },
    {
      "epoch": 1.6718404714300747,
      "grad_norm": 0.9237198829650879,
      "learning_rate": 2.2155859429855357e-05,
      "loss": 0.1309,
      "step": 63550
    },
    {
      "epoch": 1.6731558455224667,
      "grad_norm": 0.7909913659095764,
      "learning_rate": 2.213391728689791e-05,
      "loss": 0.1326,
      "step": 63600
    },
    {
      "epoch": 1.6744712196148583,
      "grad_norm": 0.6941654086112976,
      "learning_rate": 2.211197514394046e-05,
      "loss": 0.1325,
      "step": 63650
    },
    {
      "epoch": 1.6757865937072505,
      "grad_norm": 0.7984850406646729,
      "learning_rate": 2.209003300098301e-05,
      "loss": 0.1327,
      "step": 63700
    },
    {
      "epoch": 1.6771019677996422,
      "grad_norm": 0.60173100233078,
      "learning_rate": 2.2068090858025557e-05,
      "loss": 0.134,
      "step": 63750
    },
    {
      "epoch": 1.678417341892034,
      "grad_norm": 1.0209611654281616,
      "learning_rate": 2.204614871506811e-05,
      "loss": 0.1325,
      "step": 63800
    },
    {
      "epoch": 1.679732715984426,
      "grad_norm": 0.8576540350914001,
      "learning_rate": 2.202420657211066e-05,
      "loss": 0.1324,
      "step": 63850
    },
    {
      "epoch": 1.6810480900768179,
      "grad_norm": 0.7218978404998779,
      "learning_rate": 2.200226442915321e-05,
      "loss": 0.1327,
      "step": 63900
    },
    {
      "epoch": 1.6823634641692098,
      "grad_norm": 0.7716228365898132,
      "learning_rate": 2.198032228619576e-05,
      "loss": 0.1357,
      "step": 63950
    },
    {
      "epoch": 1.6836788382616015,
      "grad_norm": 0.7864187359809875,
      "learning_rate": 2.195838014323831e-05,
      "loss": 0.1362,
      "step": 64000
    },
    {
      "epoch": 1.6849942123539936,
      "grad_norm": 0.773733913898468,
      "learning_rate": 2.193643800028086e-05,
      "loss": 0.1354,
      "step": 64050
    },
    {
      "epoch": 1.6863095864463853,
      "grad_norm": 0.8853186368942261,
      "learning_rate": 2.191449585732341e-05,
      "loss": 0.1325,
      "step": 64100
    },
    {
      "epoch": 1.6876249605387772,
      "grad_norm": 0.7961658239364624,
      "learning_rate": 2.189255371436596e-05,
      "loss": 0.1331,
      "step": 64150
    },
    {
      "epoch": 1.688940334631169,
      "grad_norm": 0.8605247139930725,
      "learning_rate": 2.187061157140851e-05,
      "loss": 0.1351,
      "step": 64200
    },
    {
      "epoch": 1.690255708723561,
      "grad_norm": 0.6932883858680725,
      "learning_rate": 2.184866942845106e-05,
      "loss": 0.1325,
      "step": 64250
    },
    {
      "epoch": 1.691571082815953,
      "grad_norm": 0.8679749369621277,
      "learning_rate": 2.1826727285493613e-05,
      "loss": 0.1322,
      "step": 64300
    },
    {
      "epoch": 1.6928864569083446,
      "grad_norm": 0.9980438947677612,
      "learning_rate": 2.180478514253616e-05,
      "loss": 0.1305,
      "step": 64350
    },
    {
      "epoch": 1.6942018310007367,
      "grad_norm": 0.7926663160324097,
      "learning_rate": 2.178284299957871e-05,
      "loss": 0.1334,
      "step": 64400
    },
    {
      "epoch": 1.6955172050931284,
      "grad_norm": 0.8794835805892944,
      "learning_rate": 2.1760900856621262e-05,
      "loss": 0.1316,
      "step": 64450
    },
    {
      "epoch": 1.6968325791855203,
      "grad_norm": 0.9208669066429138,
      "learning_rate": 2.1738958713663813e-05,
      "loss": 0.1342,
      "step": 64500
    },
    {
      "epoch": 1.6981479532779122,
      "grad_norm": 0.8150193095207214,
      "learning_rate": 2.1717016570706364e-05,
      "loss": 0.1327,
      "step": 64550
    },
    {
      "epoch": 1.6994633273703041,
      "grad_norm": 0.7581997513771057,
      "learning_rate": 2.169507442774891e-05,
      "loss": 0.1342,
      "step": 64600
    },
    {
      "epoch": 1.700778701462696,
      "grad_norm": 0.6967260241508484,
      "learning_rate": 2.1673132284791466e-05,
      "loss": 0.135,
      "step": 64650
    },
    {
      "epoch": 1.7020940755550877,
      "grad_norm": 0.8777178525924683,
      "learning_rate": 2.1651190141834013e-05,
      "loss": 0.1337,
      "step": 64700
    },
    {
      "epoch": 1.7034094496474799,
      "grad_norm": 0.8048850893974304,
      "learning_rate": 2.1629247998876564e-05,
      "loss": 0.135,
      "step": 64750
    },
    {
      "epoch": 1.7047248237398716,
      "grad_norm": 0.7818888425827026,
      "learning_rate": 2.160730585591911e-05,
      "loss": 0.1337,
      "step": 64800
    },
    {
      "epoch": 1.7060401978322635,
      "grad_norm": 0.47994372248649597,
      "learning_rate": 2.1585363712961666e-05,
      "loss": 0.1337,
      "step": 64850
    },
    {
      "epoch": 1.7073555719246554,
      "grad_norm": 0.8559087514877319,
      "learning_rate": 2.1563421570004213e-05,
      "loss": 0.1332,
      "step": 64900
    },
    {
      "epoch": 1.7086709460170473,
      "grad_norm": 0.8437561988830566,
      "learning_rate": 2.1541479427046764e-05,
      "loss": 0.1325,
      "step": 64950
    },
    {
      "epoch": 1.7099863201094392,
      "grad_norm": 1.0380364656448364,
      "learning_rate": 2.1519537284089315e-05,
      "loss": 0.1345,
      "step": 65000
    },
    {
      "epoch": 1.7113016942018309,
      "grad_norm": 0.6173557043075562,
      "learning_rate": 2.1497595141131866e-05,
      "loss": 0.135,
      "step": 65050
    },
    {
      "epoch": 1.712617068294223,
      "grad_norm": 0.7482536435127258,
      "learning_rate": 2.1475652998174413e-05,
      "loss": 0.1327,
      "step": 65100
    },
    {
      "epoch": 1.7139324423866147,
      "grad_norm": 0.7287386059761047,
      "learning_rate": 2.1453710855216964e-05,
      "loss": 0.1338,
      "step": 65150
    },
    {
      "epoch": 1.7152478164790066,
      "grad_norm": 1.0518215894699097,
      "learning_rate": 2.1431768712259515e-05,
      "loss": 0.1333,
      "step": 65200
    },
    {
      "epoch": 1.7165631905713985,
      "grad_norm": 0.7235163450241089,
      "learning_rate": 2.1409826569302066e-05,
      "loss": 0.1326,
      "step": 65250
    },
    {
      "epoch": 1.7178785646637904,
      "grad_norm": 0.7618454098701477,
      "learning_rate": 2.1387884426344614e-05,
      "loss": 0.1325,
      "step": 65300
    },
    {
      "epoch": 1.7191939387561823,
      "grad_norm": 0.9009343385696411,
      "learning_rate": 2.1365942283387168e-05,
      "loss": 0.134,
      "step": 65350
    },
    {
      "epoch": 1.720509312848574,
      "grad_norm": 0.7610001564025879,
      "learning_rate": 2.1344000140429715e-05,
      "loss": 0.1312,
      "step": 65400
    },
    {
      "epoch": 1.7218246869409661,
      "grad_norm": 0.9144302606582642,
      "learning_rate": 2.1322057997472266e-05,
      "loss": 0.1359,
      "step": 65450
    },
    {
      "epoch": 1.7231400610333578,
      "grad_norm": 0.9883253574371338,
      "learning_rate": 2.1300115854514817e-05,
      "loss": 0.1321,
      "step": 65500
    },
    {
      "epoch": 1.7244554351257497,
      "grad_norm": 0.8615375757217407,
      "learning_rate": 2.1278173711557368e-05,
      "loss": 0.1304,
      "step": 65550
    },
    {
      "epoch": 1.7257708092181416,
      "grad_norm": 0.6675397753715515,
      "learning_rate": 2.1256231568599915e-05,
      "loss": 0.1327,
      "step": 65600
    },
    {
      "epoch": 1.7270861833105335,
      "grad_norm": 0.8328206539154053,
      "learning_rate": 2.1234289425642466e-05,
      "loss": 0.1326,
      "step": 65650
    },
    {
      "epoch": 1.7284015574029254,
      "grad_norm": 0.8931066393852234,
      "learning_rate": 2.1212347282685017e-05,
      "loss": 0.129,
      "step": 65700
    },
    {
      "epoch": 1.7297169314953171,
      "grad_norm": 0.6913604736328125,
      "learning_rate": 2.1190405139727568e-05,
      "loss": 0.1302,
      "step": 65750
    },
    {
      "epoch": 1.7310323055877093,
      "grad_norm": 0.7075174450874329,
      "learning_rate": 2.1168462996770115e-05,
      "loss": 0.1334,
      "step": 65800
    },
    {
      "epoch": 1.732347679680101,
      "grad_norm": 0.6680840849876404,
      "learning_rate": 2.1146520853812666e-05,
      "loss": 0.1308,
      "step": 65850
    },
    {
      "epoch": 1.7336630537724929,
      "grad_norm": 0.7877733111381531,
      "learning_rate": 2.1124578710855217e-05,
      "loss": 0.1351,
      "step": 65900
    },
    {
      "epoch": 1.7349784278648848,
      "grad_norm": 0.897516667842865,
      "learning_rate": 2.1102636567897768e-05,
      "loss": 0.1347,
      "step": 65950
    },
    {
      "epoch": 1.7362938019572767,
      "grad_norm": 0.7995032668113708,
      "learning_rate": 2.1080694424940316e-05,
      "loss": 0.1321,
      "step": 66000
    },
    {
      "epoch": 1.7376091760496686,
      "grad_norm": 0.8098055720329285,
      "learning_rate": 2.105875228198287e-05,
      "loss": 0.1331,
      "step": 66050
    },
    {
      "epoch": 1.7389245501420603,
      "grad_norm": 0.9217281937599182,
      "learning_rate": 2.1036810139025417e-05,
      "loss": 0.1287,
      "step": 66100
    },
    {
      "epoch": 1.7402399242344524,
      "grad_norm": 0.7398989200592041,
      "learning_rate": 2.1014867996067968e-05,
      "loss": 0.1311,
      "step": 66150
    },
    {
      "epoch": 1.741555298326844,
      "grad_norm": 0.8859274983406067,
      "learning_rate": 2.099292585311052e-05,
      "loss": 0.1309,
      "step": 66200
    },
    {
      "epoch": 1.742870672419236,
      "grad_norm": 0.8199785947799683,
      "learning_rate": 2.097098371015307e-05,
      "loss": 0.1301,
      "step": 66250
    },
    {
      "epoch": 1.744186046511628,
      "grad_norm": 0.8595205545425415,
      "learning_rate": 2.094904156719562e-05,
      "loss": 0.132,
      "step": 66300
    },
    {
      "epoch": 1.7455014206040198,
      "grad_norm": 0.7453927993774414,
      "learning_rate": 2.0927099424238168e-05,
      "loss": 0.1323,
      "step": 66350
    },
    {
      "epoch": 1.7468167946964117,
      "grad_norm": 0.7965542674064636,
      "learning_rate": 2.0905157281280723e-05,
      "loss": 0.1301,
      "step": 66400
    },
    {
      "epoch": 1.7481321687888034,
      "grad_norm": 0.7792550325393677,
      "learning_rate": 2.088321513832327e-05,
      "loss": 0.1306,
      "step": 66450
    },
    {
      "epoch": 1.7494475428811955,
      "grad_norm": 0.7225832939147949,
      "learning_rate": 2.086127299536582e-05,
      "loss": 0.1295,
      "step": 66500
    },
    {
      "epoch": 1.7507629169735872,
      "grad_norm": 0.9946408271789551,
      "learning_rate": 2.0839330852408372e-05,
      "loss": 0.1314,
      "step": 66550
    },
    {
      "epoch": 1.7520782910659791,
      "grad_norm": 0.8325477838516235,
      "learning_rate": 2.0817388709450923e-05,
      "loss": 0.1319,
      "step": 66600
    },
    {
      "epoch": 1.753393665158371,
      "grad_norm": 0.6599814891815186,
      "learning_rate": 2.079544656649347e-05,
      "loss": 0.1285,
      "step": 66650
    },
    {
      "epoch": 1.754709039250763,
      "grad_norm": 0.8780328631401062,
      "learning_rate": 2.077350442353602e-05,
      "loss": 0.1312,
      "step": 66700
    },
    {
      "epoch": 1.7560244133431548,
      "grad_norm": 0.6617746353149414,
      "learning_rate": 2.0751562280578572e-05,
      "loss": 0.1309,
      "step": 66750
    },
    {
      "epoch": 1.7573397874355465,
      "grad_norm": 0.740182101726532,
      "learning_rate": 2.0729620137621123e-05,
      "loss": 0.1294,
      "step": 66800
    },
    {
      "epoch": 1.7586551615279387,
      "grad_norm": 0.8752866387367249,
      "learning_rate": 2.070767799466367e-05,
      "loss": 0.1286,
      "step": 66850
    },
    {
      "epoch": 1.7599705356203303,
      "grad_norm": 0.8106902837753296,
      "learning_rate": 2.068573585170622e-05,
      "loss": 0.1304,
      "step": 66900
    },
    {
      "epoch": 1.7612859097127223,
      "grad_norm": 0.7098636031150818,
      "learning_rate": 2.0663793708748772e-05,
      "loss": 0.1346,
      "step": 66950
    },
    {
      "epoch": 1.7626012838051142,
      "grad_norm": 0.8873384594917297,
      "learning_rate": 2.0641851565791323e-05,
      "loss": 0.1321,
      "step": 67000
    },
    {
      "epoch": 1.763916657897506,
      "grad_norm": 1.0599372386932373,
      "learning_rate": 2.061990942283387e-05,
      "loss": 0.1289,
      "step": 67050
    },
    {
      "epoch": 1.765232031989898,
      "grad_norm": 0.829931914806366,
      "learning_rate": 2.0597967279876425e-05,
      "loss": 0.1376,
      "step": 67100
    },
    {
      "epoch": 1.7665474060822897,
      "grad_norm": 0.6838942170143127,
      "learning_rate": 2.0576025136918972e-05,
      "loss": 0.1332,
      "step": 67150
    },
    {
      "epoch": 1.7678627801746818,
      "grad_norm": 0.6672791242599487,
      "learning_rate": 2.0554082993961523e-05,
      "loss": 0.1329,
      "step": 67200
    },
    {
      "epoch": 1.7691781542670735,
      "grad_norm": 0.8150632977485657,
      "learning_rate": 2.0532140851004074e-05,
      "loss": 0.1322,
      "step": 67250
    },
    {
      "epoch": 1.7704935283594654,
      "grad_norm": 0.8073723316192627,
      "learning_rate": 2.0510198708046625e-05,
      "loss": 0.1317,
      "step": 67300
    },
    {
      "epoch": 1.7718089024518573,
      "grad_norm": 0.5994323492050171,
      "learning_rate": 2.0488256565089172e-05,
      "loss": 0.1327,
      "step": 67350
    },
    {
      "epoch": 1.7731242765442492,
      "grad_norm": 0.7225297093391418,
      "learning_rate": 2.0466314422131723e-05,
      "loss": 0.1281,
      "step": 67400
    },
    {
      "epoch": 1.774439650636641,
      "grad_norm": 0.7187162637710571,
      "learning_rate": 2.0444372279174274e-05,
      "loss": 0.1297,
      "step": 67450
    },
    {
      "epoch": 1.7757550247290328,
      "grad_norm": 0.7917560935020447,
      "learning_rate": 2.0422430136216825e-05,
      "loss": 0.1274,
      "step": 67500
    },
    {
      "epoch": 1.777070398821425,
      "grad_norm": 0.7503902912139893,
      "learning_rate": 2.0400487993259372e-05,
      "loss": 0.1292,
      "step": 67550
    },
    {
      "epoch": 1.7783857729138166,
      "grad_norm": 0.8886141777038574,
      "learning_rate": 2.0378545850301926e-05,
      "loss": 0.1311,
      "step": 67600
    },
    {
      "epoch": 1.7797011470062085,
      "grad_norm": 0.7026524543762207,
      "learning_rate": 2.0356603707344474e-05,
      "loss": 0.1283,
      "step": 67650
    },
    {
      "epoch": 1.7810165210986004,
      "grad_norm": 0.8579964637756348,
      "learning_rate": 2.0334661564387025e-05,
      "loss": 0.1305,
      "step": 67700
    },
    {
      "epoch": 1.7823318951909923,
      "grad_norm": 0.7160608768463135,
      "learning_rate": 2.0312719421429576e-05,
      "loss": 0.1332,
      "step": 67750
    },
    {
      "epoch": 1.7836472692833842,
      "grad_norm": 0.776068925857544,
      "learning_rate": 2.0290777278472127e-05,
      "loss": 0.1294,
      "step": 67800
    },
    {
      "epoch": 1.784962643375776,
      "grad_norm": 0.8252894878387451,
      "learning_rate": 2.0268835135514677e-05,
      "loss": 0.1325,
      "step": 67850
    },
    {
      "epoch": 1.786278017468168,
      "grad_norm": 0.7356116771697998,
      "learning_rate": 2.0246892992557225e-05,
      "loss": 0.1315,
      "step": 67900
    },
    {
      "epoch": 1.7875933915605597,
      "grad_norm": 0.8747210502624512,
      "learning_rate": 2.022495084959978e-05,
      "loss": 0.1308,
      "step": 67950
    },
    {
      "epoch": 1.7889087656529516,
      "grad_norm": 0.7861680388450623,
      "learning_rate": 2.0203008706642327e-05,
      "loss": 0.131,
      "step": 68000
    },
    {
      "epoch": 1.7902241397453436,
      "grad_norm": 0.635242223739624,
      "learning_rate": 2.0181066563684878e-05,
      "loss": 0.1279,
      "step": 68050
    },
    {
      "epoch": 1.7915395138377355,
      "grad_norm": 0.8294689059257507,
      "learning_rate": 2.0159124420727425e-05,
      "loss": 0.1311,
      "step": 68100
    },
    {
      "epoch": 1.7928548879301274,
      "grad_norm": 0.8649652004241943,
      "learning_rate": 2.013718227776998e-05,
      "loss": 0.1296,
      "step": 68150
    },
    {
      "epoch": 1.794170262022519,
      "grad_norm": 0.9286924600601196,
      "learning_rate": 2.0115240134812527e-05,
      "loss": 0.1307,
      "step": 68200
    },
    {
      "epoch": 1.7954856361149112,
      "grad_norm": 0.8837060332298279,
      "learning_rate": 2.0093297991855078e-05,
      "loss": 0.1295,
      "step": 68250
    },
    {
      "epoch": 1.7968010102073029,
      "grad_norm": 0.8763293027877808,
      "learning_rate": 2.007135584889763e-05,
      "loss": 0.1314,
      "step": 68300
    },
    {
      "epoch": 1.7981163842996948,
      "grad_norm": 0.8936929106712341,
      "learning_rate": 2.004941370594018e-05,
      "loss": 0.1301,
      "step": 68350
    },
    {
      "epoch": 1.7994317583920867,
      "grad_norm": 0.7659578919410706,
      "learning_rate": 2.0027471562982727e-05,
      "loss": 0.1285,
      "step": 68400
    },
    {
      "epoch": 1.8007471324844786,
      "grad_norm": 0.8433818817138672,
      "learning_rate": 2.0005529420025278e-05,
      "loss": 0.1329,
      "step": 68450
    },
    {
      "epoch": 1.8020625065768705,
      "grad_norm": 0.6048877239227295,
      "learning_rate": 1.998358727706783e-05,
      "loss": 0.1344,
      "step": 68500
    },
    {
      "epoch": 1.8033778806692622,
      "grad_norm": 0.8763282299041748,
      "learning_rate": 1.996164513411038e-05,
      "loss": 0.129,
      "step": 68550
    },
    {
      "epoch": 1.8046932547616543,
      "grad_norm": 0.679081916809082,
      "learning_rate": 1.9939702991152927e-05,
      "loss": 0.1309,
      "step": 68600
    },
    {
      "epoch": 1.806008628854046,
      "grad_norm": 0.7556747198104858,
      "learning_rate": 1.991776084819548e-05,
      "loss": 0.1305,
      "step": 68650
    },
    {
      "epoch": 1.807324002946438,
      "grad_norm": 0.7302646636962891,
      "learning_rate": 1.989581870523803e-05,
      "loss": 0.13,
      "step": 68700
    },
    {
      "epoch": 1.8086393770388298,
      "grad_norm": 0.6920089721679688,
      "learning_rate": 1.987387656228058e-05,
      "loss": 0.1306,
      "step": 68750
    },
    {
      "epoch": 1.8099547511312217,
      "grad_norm": 0.8517166972160339,
      "learning_rate": 1.985193441932313e-05,
      "loss": 0.1284,
      "step": 68800
    },
    {
      "epoch": 1.8112701252236136,
      "grad_norm": 0.8372563719749451,
      "learning_rate": 1.982999227636568e-05,
      "loss": 0.1295,
      "step": 68850
    },
    {
      "epoch": 1.8125854993160053,
      "grad_norm": 0.8536901473999023,
      "learning_rate": 1.980805013340823e-05,
      "loss": 0.1322,
      "step": 68900
    },
    {
      "epoch": 1.8139008734083975,
      "grad_norm": 0.6482893824577332,
      "learning_rate": 1.978610799045078e-05,
      "loss": 0.1294,
      "step": 68950
    },
    {
      "epoch": 1.8152162475007891,
      "grad_norm": 0.9168052077293396,
      "learning_rate": 1.976416584749333e-05,
      "loss": 0.1294,
      "step": 69000
    },
    {
      "epoch": 1.8165316215931813,
      "grad_norm": 0.5382362008094788,
      "learning_rate": 1.974222370453588e-05,
      "loss": 0.1286,
      "step": 69050
    },
    {
      "epoch": 1.817846995685573,
      "grad_norm": 0.8653758764266968,
      "learning_rate": 1.972028156157843e-05,
      "loss": 0.1314,
      "step": 69100
    },
    {
      "epoch": 1.8191623697779649,
      "grad_norm": 0.8995705842971802,
      "learning_rate": 1.969833941862098e-05,
      "loss": 0.1325,
      "step": 69150
    },
    {
      "epoch": 1.8204777438703568,
      "grad_norm": 0.963260293006897,
      "learning_rate": 1.967639727566353e-05,
      "loss": 0.135,
      "step": 69200
    },
    {
      "epoch": 1.8217931179627485,
      "grad_norm": 0.7692669034004211,
      "learning_rate": 1.965445513270608e-05,
      "loss": 0.1295,
      "step": 69250
    },
    {
      "epoch": 1.8231084920551406,
      "grad_norm": 0.8791475296020508,
      "learning_rate": 1.963251298974863e-05,
      "loss": 0.1293,
      "step": 69300
    },
    {
      "epoch": 1.8244238661475323,
      "grad_norm": 0.8379834294319153,
      "learning_rate": 1.9610570846791183e-05,
      "loss": 0.1295,
      "step": 69350
    },
    {
      "epoch": 1.8257392402399244,
      "grad_norm": 0.8726929426193237,
      "learning_rate": 1.9588628703833734e-05,
      "loss": 0.1274,
      "step": 69400
    },
    {
      "epoch": 1.827054614332316,
      "grad_norm": 0.7066504955291748,
      "learning_rate": 1.956668656087628e-05,
      "loss": 0.1285,
      "step": 69450
    },
    {
      "epoch": 1.828369988424708,
      "grad_norm": 0.9364104866981506,
      "learning_rate": 1.9544744417918832e-05,
      "loss": 0.1269,
      "step": 69500
    },
    {
      "epoch": 1.8296853625171,
      "grad_norm": 0.883185625076294,
      "learning_rate": 1.9522802274961383e-05,
      "loss": 0.1307,
      "step": 69550
    },
    {
      "epoch": 1.8310007366094916,
      "grad_norm": 0.9612385630607605,
      "learning_rate": 1.9500860132003934e-05,
      "loss": 0.1337,
      "step": 69600
    },
    {
      "epoch": 1.8323161107018837,
      "grad_norm": 0.6810935139656067,
      "learning_rate": 1.947891798904648e-05,
      "loss": 0.13,
      "step": 69650
    },
    {
      "epoch": 1.8336314847942754,
      "grad_norm": 0.732183575630188,
      "learning_rate": 1.9456975846089036e-05,
      "loss": 0.1286,
      "step": 69700
    },
    {
      "epoch": 1.8349468588866675,
      "grad_norm": 0.5165082216262817,
      "learning_rate": 1.9435033703131583e-05,
      "loss": 0.1265,
      "step": 69750
    },
    {
      "epoch": 1.8362622329790592,
      "grad_norm": 0.7014588713645935,
      "learning_rate": 1.9413091560174134e-05,
      "loss": 0.1287,
      "step": 69800
    },
    {
      "epoch": 1.8375776070714511,
      "grad_norm": 0.7474878430366516,
      "learning_rate": 1.9391149417216685e-05,
      "loss": 0.1275,
      "step": 69850
    },
    {
      "epoch": 1.838892981163843,
      "grad_norm": 0.8346046209335327,
      "learning_rate": 1.9369207274259236e-05,
      "loss": 0.1314,
      "step": 69900
    },
    {
      "epoch": 1.8402083552562347,
      "grad_norm": 0.7916463017463684,
      "learning_rate": 1.9347265131301784e-05,
      "loss": 0.1306,
      "step": 69950
    },
    {
      "epoch": 1.8415237293486268,
      "grad_norm": 0.7794110774993896,
      "learning_rate": 1.9325322988344334e-05,
      "loss": 0.1305,
      "step": 70000
    },
    {
      "epoch": 1.8428391034410185,
      "grad_norm": 3.0929272174835205,
      "learning_rate": 1.9303380845386885e-05,
      "loss": 0.1291,
      "step": 70050
    },
    {
      "epoch": 1.8441544775334107,
      "grad_norm": 0.7356763482093811,
      "learning_rate": 1.9281438702429436e-05,
      "loss": 0.1288,
      "step": 70100
    },
    {
      "epoch": 1.8454698516258023,
      "grad_norm": 0.6620325446128845,
      "learning_rate": 1.9259496559471984e-05,
      "loss": 0.1289,
      "step": 70150
    },
    {
      "epoch": 1.8467852257181943,
      "grad_norm": 0.8493420481681824,
      "learning_rate": 1.9237554416514534e-05,
      "loss": 0.1307,
      "step": 70200
    },
    {
      "epoch": 1.8481005998105862,
      "grad_norm": 0.7939226031303406,
      "learning_rate": 1.9215612273557085e-05,
      "loss": 0.1281,
      "step": 70250
    },
    {
      "epoch": 1.8494159739029778,
      "grad_norm": 0.9168635010719299,
      "learning_rate": 1.9193670130599636e-05,
      "loss": 0.1292,
      "step": 70300
    },
    {
      "epoch": 1.85073134799537,
      "grad_norm": 0.6927422881126404,
      "learning_rate": 1.9171727987642184e-05,
      "loss": 0.1288,
      "step": 70350
    },
    {
      "epoch": 1.8520467220877617,
      "grad_norm": 0.9696078300476074,
      "learning_rate": 1.9149785844684738e-05,
      "loss": 0.1291,
      "step": 70400
    },
    {
      "epoch": 1.8533620961801538,
      "grad_norm": 0.7933926582336426,
      "learning_rate": 1.9127843701727285e-05,
      "loss": 0.1307,
      "step": 70450
    },
    {
      "epoch": 1.8546774702725455,
      "grad_norm": 0.7860053181648254,
      "learning_rate": 1.9105901558769836e-05,
      "loss": 0.1277,
      "step": 70500
    },
    {
      "epoch": 1.8559928443649374,
      "grad_norm": 0.9417123794555664,
      "learning_rate": 1.9083959415812387e-05,
      "loss": 0.1326,
      "step": 70550
    },
    {
      "epoch": 1.8573082184573293,
      "grad_norm": 0.8356292843818665,
      "learning_rate": 1.9062017272854938e-05,
      "loss": 0.1303,
      "step": 70600
    },
    {
      "epoch": 1.858623592549721,
      "grad_norm": 0.7780823707580566,
      "learning_rate": 1.9040075129897486e-05,
      "loss": 0.1307,
      "step": 70650
    },
    {
      "epoch": 1.8599389666421131,
      "grad_norm": 0.7641283273696899,
      "learning_rate": 1.9018132986940036e-05,
      "loss": 0.1289,
      "step": 70700
    },
    {
      "epoch": 1.8612543407345048,
      "grad_norm": 0.6393649578094482,
      "learning_rate": 1.8996190843982587e-05,
      "loss": 0.1278,
      "step": 70750
    },
    {
      "epoch": 1.862569714826897,
      "grad_norm": 0.8467638492584229,
      "learning_rate": 1.8974248701025138e-05,
      "loss": 0.1291,
      "step": 70800
    },
    {
      "epoch": 1.8638850889192886,
      "grad_norm": 0.9717050194740295,
      "learning_rate": 1.8952306558067686e-05,
      "loss": 0.1267,
      "step": 70850
    },
    {
      "epoch": 1.8652004630116805,
      "grad_norm": 0.9483253359794617,
      "learning_rate": 1.893036441511024e-05,
      "loss": 0.1264,
      "step": 70900
    },
    {
      "epoch": 1.8665158371040724,
      "grad_norm": 0.6586967706680298,
      "learning_rate": 1.8908422272152787e-05,
      "loss": 0.1253,
      "step": 70950
    },
    {
      "epoch": 1.8678312111964641,
      "grad_norm": 0.6502913236618042,
      "learning_rate": 1.8886480129195338e-05,
      "loss": 0.128,
      "step": 71000
    },
    {
      "epoch": 1.8691465852888562,
      "grad_norm": 0.772470235824585,
      "learning_rate": 1.886453798623789e-05,
      "loss": 0.1268,
      "step": 71050
    },
    {
      "epoch": 1.870461959381248,
      "grad_norm": 0.8628819584846497,
      "learning_rate": 1.884259584328044e-05,
      "loss": 0.1285,
      "step": 71100
    },
    {
      "epoch": 1.87177733347364,
      "grad_norm": 0.8479979634284973,
      "learning_rate": 1.882065370032299e-05,
      "loss": 0.1279,
      "step": 71150
    },
    {
      "epoch": 1.8730927075660317,
      "grad_norm": 0.7124071717262268,
      "learning_rate": 1.879871155736554e-05,
      "loss": 0.1257,
      "step": 71200
    },
    {
      "epoch": 1.8744080816584237,
      "grad_norm": 1.041452407836914,
      "learning_rate": 1.877676941440809e-05,
      "loss": 0.1279,
      "step": 71250
    },
    {
      "epoch": 1.8757234557508156,
      "grad_norm": 0.9093173742294312,
      "learning_rate": 1.875482727145064e-05,
      "loss": 0.1262,
      "step": 71300
    },
    {
      "epoch": 1.8770388298432072,
      "grad_norm": 0.6844081282615662,
      "learning_rate": 1.873288512849319e-05,
      "loss": 0.1277,
      "step": 71350
    },
    {
      "epoch": 1.8783542039355994,
      "grad_norm": 0.8332206606864929,
      "learning_rate": 1.871094298553574e-05,
      "loss": 0.1264,
      "step": 71400
    },
    {
      "epoch": 1.879669578027991,
      "grad_norm": 1.0142900943756104,
      "learning_rate": 1.8689000842578293e-05,
      "loss": 0.13,
      "step": 71450
    },
    {
      "epoch": 1.8809849521203832,
      "grad_norm": 0.7685582637786865,
      "learning_rate": 1.866705869962084e-05,
      "loss": 0.1322,
      "step": 71500
    },
    {
      "epoch": 1.8823003262127749,
      "grad_norm": 0.8656264543533325,
      "learning_rate": 1.864511655666339e-05,
      "loss": 0.1294,
      "step": 71550
    },
    {
      "epoch": 1.8836157003051668,
      "grad_norm": 0.7194194793701172,
      "learning_rate": 1.8623174413705942e-05,
      "loss": 0.1261,
      "step": 71600
    },
    {
      "epoch": 1.8849310743975587,
      "grad_norm": 0.7784262299537659,
      "learning_rate": 1.8601232270748493e-05,
      "loss": 0.1296,
      "step": 71650
    },
    {
      "epoch": 1.8862464484899504,
      "grad_norm": 0.8324247598648071,
      "learning_rate": 1.857929012779104e-05,
      "loss": 0.1288,
      "step": 71700
    },
    {
      "epoch": 1.8875618225823425,
      "grad_norm": 0.9025150537490845,
      "learning_rate": 1.855734798483359e-05,
      "loss": 0.1246,
      "step": 71750
    },
    {
      "epoch": 1.8888771966747342,
      "grad_norm": 0.809001088142395,
      "learning_rate": 1.8535405841876142e-05,
      "loss": 0.1272,
      "step": 71800
    },
    {
      "epoch": 1.8901925707671263,
      "grad_norm": 0.6981953382492065,
      "learning_rate": 1.8513463698918693e-05,
      "loss": 0.1275,
      "step": 71850
    },
    {
      "epoch": 1.891507944859518,
      "grad_norm": 0.9307538270950317,
      "learning_rate": 1.849152155596124e-05,
      "loss": 0.1272,
      "step": 71900
    },
    {
      "epoch": 1.89282331895191,
      "grad_norm": 0.6571606993675232,
      "learning_rate": 1.8469579413003795e-05,
      "loss": 0.1256,
      "step": 71950
    },
    {
      "epoch": 1.8941386930443018,
      "grad_norm": 0.8416898250579834,
      "learning_rate": 1.8447637270046342e-05,
      "loss": 0.126,
      "step": 72000
    },
    {
      "epoch": 1.8954540671366935,
      "grad_norm": 0.7427593469619751,
      "learning_rate": 1.8425695127088893e-05,
      "loss": 0.1304,
      "step": 72050
    },
    {
      "epoch": 1.8967694412290856,
      "grad_norm": 0.8539191484451294,
      "learning_rate": 1.840375298413144e-05,
      "loss": 0.1306,
      "step": 72100
    },
    {
      "epoch": 1.8980848153214773,
      "grad_norm": 0.8754390478134155,
      "learning_rate": 1.8381810841173995e-05,
      "loss": 0.127,
      "step": 72150
    },
    {
      "epoch": 1.8994001894138695,
      "grad_norm": 0.6748302578926086,
      "learning_rate": 1.8359868698216542e-05,
      "loss": 0.1304,
      "step": 72200
    },
    {
      "epoch": 1.9007155635062611,
      "grad_norm": 0.8766530156135559,
      "learning_rate": 1.8337926555259093e-05,
      "loss": 0.1307,
      "step": 72250
    },
    {
      "epoch": 1.902030937598653,
      "grad_norm": 0.8132856488227844,
      "learning_rate": 1.8315984412301644e-05,
      "loss": 0.1282,
      "step": 72300
    },
    {
      "epoch": 1.903346311691045,
      "grad_norm": 0.9852954149246216,
      "learning_rate": 1.8294042269344195e-05,
      "loss": 0.1267,
      "step": 72350
    },
    {
      "epoch": 1.9046616857834369,
      "grad_norm": 0.7837908267974854,
      "learning_rate": 1.8272100126386742e-05,
      "loss": 0.1295,
      "step": 72400
    },
    {
      "epoch": 1.9059770598758288,
      "grad_norm": 0.7579089403152466,
      "learning_rate": 1.8250157983429293e-05,
      "loss": 0.1288,
      "step": 72450
    },
    {
      "epoch": 1.9072924339682205,
      "grad_norm": 0.98241126537323,
      "learning_rate": 1.8228215840471844e-05,
      "loss": 0.1238,
      "step": 72500
    },
    {
      "epoch": 1.9086078080606126,
      "grad_norm": 0.8505728244781494,
      "learning_rate": 1.8206273697514395e-05,
      "loss": 0.1277,
      "step": 72550
    },
    {
      "epoch": 1.9099231821530043,
      "grad_norm": 0.622664749622345,
      "learning_rate": 1.8184331554556946e-05,
      "loss": 0.1257,
      "step": 72600
    },
    {
      "epoch": 1.9112385562453962,
      "grad_norm": 0.8143844604492188,
      "learning_rate": 1.8162389411599497e-05,
      "loss": 0.1265,
      "step": 72650
    },
    {
      "epoch": 1.912553930337788,
      "grad_norm": 1.0043292045593262,
      "learning_rate": 1.8140447268642048e-05,
      "loss": 0.1259,
      "step": 72700
    },
    {
      "epoch": 1.91386930443018,
      "grad_norm": 0.7049098610877991,
      "learning_rate": 1.8118505125684595e-05,
      "loss": 0.1261,
      "step": 72750
    },
    {
      "epoch": 1.915184678522572,
      "grad_norm": 0.8392506241798401,
      "learning_rate": 1.8096562982727146e-05,
      "loss": 0.1311,
      "step": 72800
    },
    {
      "epoch": 1.9165000526149636,
      "grad_norm": 0.906463086605072,
      "learning_rate": 1.8074620839769697e-05,
      "loss": 0.1301,
      "step": 72850
    },
    {
      "epoch": 1.9178154267073557,
      "grad_norm": 0.6634032130241394,
      "learning_rate": 1.8052678696812248e-05,
      "loss": 0.132,
      "step": 72900
    },
    {
      "epoch": 1.9191308007997474,
      "grad_norm": 0.7647402882575989,
      "learning_rate": 1.8030736553854795e-05,
      "loss": 0.1255,
      "step": 72950
    },
    {
      "epoch": 1.9204461748921393,
      "grad_norm": 0.8124254941940308,
      "learning_rate": 1.800879441089735e-05,
      "loss": 0.1256,
      "step": 73000
    },
    {
      "epoch": 1.9217615489845312,
      "grad_norm": 0.7738637328147888,
      "learning_rate": 1.7986852267939897e-05,
      "loss": 0.129,
      "step": 73050
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.7995598316192627,
      "learning_rate": 1.7964910124982448e-05,
      "loss": 0.1269,
      "step": 73100
    },
    {
      "epoch": 1.924392297169315,
      "grad_norm": 0.644893229007721,
      "learning_rate": 1.7942967982024995e-05,
      "loss": 0.1297,
      "step": 73150
    },
    {
      "epoch": 1.9257076712617067,
      "grad_norm": 0.7557074427604675,
      "learning_rate": 1.792102583906755e-05,
      "loss": 0.1248,
      "step": 73200
    },
    {
      "epoch": 1.9270230453540989,
      "grad_norm": 0.6773884892463684,
      "learning_rate": 1.7899083696110097e-05,
      "loss": 0.1274,
      "step": 73250
    },
    {
      "epoch": 1.9283384194464905,
      "grad_norm": 0.8693966269493103,
      "learning_rate": 1.7877141553152648e-05,
      "loss": 0.1263,
      "step": 73300
    },
    {
      "epoch": 1.9296537935388824,
      "grad_norm": 0.7826588749885559,
      "learning_rate": 1.78551994101952e-05,
      "loss": 0.1273,
      "step": 73350
    },
    {
      "epoch": 1.9309691676312744,
      "grad_norm": 0.625239908695221,
      "learning_rate": 1.783325726723775e-05,
      "loss": 0.1276,
      "step": 73400
    },
    {
      "epoch": 1.9322845417236663,
      "grad_norm": 1.0299248695373535,
      "learning_rate": 1.7811315124280297e-05,
      "loss": 0.1257,
      "step": 73450
    },
    {
      "epoch": 1.9335999158160582,
      "grad_norm": 0.6988452076911926,
      "learning_rate": 1.7789372981322848e-05,
      "loss": 0.1259,
      "step": 73500
    },
    {
      "epoch": 1.9349152899084499,
      "grad_norm": 0.8347563743591309,
      "learning_rate": 1.77674308383654e-05,
      "loss": 0.1265,
      "step": 73550
    },
    {
      "epoch": 1.936230664000842,
      "grad_norm": 0.9237764477729797,
      "learning_rate": 1.774548869540795e-05,
      "loss": 0.1255,
      "step": 73600
    },
    {
      "epoch": 1.9375460380932337,
      "grad_norm": 0.8339546322822571,
      "learning_rate": 1.7723546552450497e-05,
      "loss": 0.1257,
      "step": 73650
    },
    {
      "epoch": 1.9388614121856256,
      "grad_norm": 0.8657035231590271,
      "learning_rate": 1.770160440949305e-05,
      "loss": 0.1265,
      "step": 73700
    },
    {
      "epoch": 1.9401767862780175,
      "grad_norm": 0.7064085006713867,
      "learning_rate": 1.76796622665356e-05,
      "loss": 0.1274,
      "step": 73750
    },
    {
      "epoch": 1.9414921603704094,
      "grad_norm": 0.6689513921737671,
      "learning_rate": 1.765772012357815e-05,
      "loss": 0.1288,
      "step": 73800
    },
    {
      "epoch": 1.9428075344628013,
      "grad_norm": 0.7834392189979553,
      "learning_rate": 1.76357779806207e-05,
      "loss": 0.1271,
      "step": 73850
    },
    {
      "epoch": 1.944122908555193,
      "grad_norm": 0.7794625759124756,
      "learning_rate": 1.761383583766325e-05,
      "loss": 0.1268,
      "step": 73900
    },
    {
      "epoch": 1.9454382826475851,
      "grad_norm": 0.7210611701011658,
      "learning_rate": 1.75918936947058e-05,
      "loss": 0.1261,
      "step": 73950
    },
    {
      "epoch": 1.9467536567399768,
      "grad_norm": 0.4866781234741211,
      "learning_rate": 1.756995155174835e-05,
      "loss": 0.1268,
      "step": 74000
    },
    {
      "epoch": 1.9480690308323687,
      "grad_norm": 0.6329237818717957,
      "learning_rate": 1.75480094087909e-05,
      "loss": 0.1241,
      "step": 74050
    },
    {
      "epoch": 1.9493844049247606,
      "grad_norm": 0.8217978477478027,
      "learning_rate": 1.752606726583345e-05,
      "loss": 0.1267,
      "step": 74100
    },
    {
      "epoch": 1.9506997790171525,
      "grad_norm": 0.8707616329193115,
      "learning_rate": 1.7504125122876e-05,
      "loss": 0.1281,
      "step": 74150
    },
    {
      "epoch": 1.9520151531095444,
      "grad_norm": 0.7960537672042847,
      "learning_rate": 1.748218297991855e-05,
      "loss": 0.1283,
      "step": 74200
    },
    {
      "epoch": 1.9533305272019361,
      "grad_norm": 0.8166034817695618,
      "learning_rate": 1.7460240836961104e-05,
      "loss": 0.1264,
      "step": 74250
    },
    {
      "epoch": 1.9546459012943282,
      "grad_norm": 0.7982218861579895,
      "learning_rate": 1.743829869400365e-05,
      "loss": 0.1248,
      "step": 74300
    },
    {
      "epoch": 1.95596127538672,
      "grad_norm": 0.8593350648880005,
      "learning_rate": 1.7416356551046203e-05,
      "loss": 0.1242,
      "step": 74350
    },
    {
      "epoch": 1.9572766494791118,
      "grad_norm": 0.7717036008834839,
      "learning_rate": 1.7394414408088753e-05,
      "loss": 0.1242,
      "step": 74400
    },
    {
      "epoch": 1.9585920235715037,
      "grad_norm": 0.8350533246994019,
      "learning_rate": 1.7372472265131304e-05,
      "loss": 0.1284,
      "step": 74450
    },
    {
      "epoch": 1.9599073976638957,
      "grad_norm": 0.8158026933670044,
      "learning_rate": 1.7350530122173852e-05,
      "loss": 0.1285,
      "step": 74500
    },
    {
      "epoch": 1.9612227717562876,
      "grad_norm": 1.3837476968765259,
      "learning_rate": 1.7328587979216403e-05,
      "loss": 0.1293,
      "step": 74550
    },
    {
      "epoch": 1.9625381458486792,
      "grad_norm": 0.831597626209259,
      "learning_rate": 1.7306645836258954e-05,
      "loss": 0.1257,
      "step": 74600
    },
    {
      "epoch": 1.9638535199410714,
      "grad_norm": 0.6280313730239868,
      "learning_rate": 1.7284703693301504e-05,
      "loss": 0.1266,
      "step": 74650
    },
    {
      "epoch": 1.965168894033463,
      "grad_norm": 0.7906882762908936,
      "learning_rate": 1.7262761550344052e-05,
      "loss": 0.1244,
      "step": 74700
    },
    {
      "epoch": 1.966484268125855,
      "grad_norm": 0.8153664469718933,
      "learning_rate": 1.7240819407386606e-05,
      "loss": 0.1231,
      "step": 74750
    },
    {
      "epoch": 1.9677996422182469,
      "grad_norm": 0.6854375004768372,
      "learning_rate": 1.7218877264429154e-05,
      "loss": 0.1263,
      "step": 74800
    },
    {
      "epoch": 1.9691150163106388,
      "grad_norm": 0.7057612538337708,
      "learning_rate": 1.7196935121471704e-05,
      "loss": 0.127,
      "step": 74850
    },
    {
      "epoch": 1.9704303904030307,
      "grad_norm": 0.8475305438041687,
      "learning_rate": 1.7174992978514255e-05,
      "loss": 0.1274,
      "step": 74900
    },
    {
      "epoch": 1.9717457644954224,
      "grad_norm": 0.7467221021652222,
      "learning_rate": 1.7153050835556806e-05,
      "loss": 0.1272,
      "step": 74950
    },
    {
      "epoch": 1.9730611385878145,
      "grad_norm": 0.8402766585350037,
      "learning_rate": 1.7131108692599354e-05,
      "loss": 0.1237,
      "step": 75000
    },
    {
      "epoch": 1.9743765126802062,
      "grad_norm": 0.8344460725784302,
      "learning_rate": 1.7109166549641905e-05,
      "loss": 0.1241,
      "step": 75050
    },
    {
      "epoch": 1.975691886772598,
      "grad_norm": 0.7841627597808838,
      "learning_rate": 1.7087224406684455e-05,
      "loss": 0.1254,
      "step": 75100
    },
    {
      "epoch": 1.97700726086499,
      "grad_norm": 0.8623273372650146,
      "learning_rate": 1.7065282263727006e-05,
      "loss": 0.1224,
      "step": 75150
    },
    {
      "epoch": 1.978322634957382,
      "grad_norm": 0.6151148676872253,
      "learning_rate": 1.7043340120769554e-05,
      "loss": 0.125,
      "step": 75200
    },
    {
      "epoch": 1.9796380090497738,
      "grad_norm": 0.9573928713798523,
      "learning_rate": 1.7021397977812105e-05,
      "loss": 0.1286,
      "step": 75250
    },
    {
      "epoch": 1.9809533831421655,
      "grad_norm": 0.7427927851676941,
      "learning_rate": 1.6999455834854656e-05,
      "loss": 0.127,
      "step": 75300
    },
    {
      "epoch": 1.9822687572345576,
      "grad_norm": 0.8405105471611023,
      "learning_rate": 1.6977513691897206e-05,
      "loss": 0.1255,
      "step": 75350
    },
    {
      "epoch": 1.9835841313269493,
      "grad_norm": 0.7107203602790833,
      "learning_rate": 1.6955571548939754e-05,
      "loss": 0.1247,
      "step": 75400
    },
    {
      "epoch": 1.9848995054193412,
      "grad_norm": 0.9056004285812378,
      "learning_rate": 1.6933629405982308e-05,
      "loss": 0.1259,
      "step": 75450
    },
    {
      "epoch": 1.9862148795117331,
      "grad_norm": 0.7112403512001038,
      "learning_rate": 1.6911687263024856e-05,
      "loss": 0.1233,
      "step": 75500
    },
    {
      "epoch": 1.987530253604125,
      "grad_norm": 0.6983407139778137,
      "learning_rate": 1.6889745120067406e-05,
      "loss": 0.1266,
      "step": 75550
    },
    {
      "epoch": 1.988845627696517,
      "grad_norm": 0.7855951189994812,
      "learning_rate": 1.6867802977109957e-05,
      "loss": 0.1222,
      "step": 75600
    },
    {
      "epoch": 1.9901610017889086,
      "grad_norm": 0.8604596853256226,
      "learning_rate": 1.6845860834152508e-05,
      "loss": 0.1238,
      "step": 75650
    },
    {
      "epoch": 1.9914763758813008,
      "grad_norm": 0.6527812480926514,
      "learning_rate": 1.6823918691195056e-05,
      "loss": 0.1243,
      "step": 75700
    },
    {
      "epoch": 1.9927917499736925,
      "grad_norm": 0.752242922782898,
      "learning_rate": 1.6801976548237607e-05,
      "loss": 0.1236,
      "step": 75750
    },
    {
      "epoch": 1.9941071240660844,
      "grad_norm": 0.7941546440124512,
      "learning_rate": 1.678003440528016e-05,
      "loss": 0.1225,
      "step": 75800
    },
    {
      "epoch": 1.9954224981584763,
      "grad_norm": 0.7093876600265503,
      "learning_rate": 1.675809226232271e-05,
      "loss": 0.1271,
      "step": 75850
    },
    {
      "epoch": 1.9967378722508682,
      "grad_norm": 0.6763779520988464,
      "learning_rate": 1.673615011936526e-05,
      "loss": 0.1243,
      "step": 75900
    },
    {
      "epoch": 1.99805324634326,
      "grad_norm": 0.7299761176109314,
      "learning_rate": 1.671420797640781e-05,
      "loss": 0.1286,
      "step": 75950
    },
    {
      "epoch": 1.9993686204356518,
      "grad_norm": 0.8280302286148071,
      "learning_rate": 1.669226583345036e-05,
      "loss": 0.1266,
      "step": 76000
    },
    {
      "epoch": 2.0,
      "eval_loss": 7.846306800842285,
      "eval_runtime": 234.1921,
      "eval_samples_per_second": 143.792,
      "eval_steps_per_second": 17.977,
      "step": 76024
    },
    {
      "epoch": 2.000683994528044,
      "grad_norm": 0.5760489106178284,
      "learning_rate": 1.667032369049291e-05,
      "loss": 0.1252,
      "step": 76050
    },
    {
      "epoch": 2.0019993686204356,
      "grad_norm": 0.7170331478118896,
      "learning_rate": 1.664838154753546e-05,
      "loss": 0.1155,
      "step": 76100
    },
    {
      "epoch": 2.0033147427128277,
      "grad_norm": 0.6133707165718079,
      "learning_rate": 1.662643940457801e-05,
      "loss": 0.1155,
      "step": 76150
    },
    {
      "epoch": 2.0046301168052194,
      "grad_norm": 0.6706072092056274,
      "learning_rate": 1.660449726162056e-05,
      "loss": 0.1175,
      "step": 76200
    },
    {
      "epoch": 2.005945490897611,
      "grad_norm": 0.5438878536224365,
      "learning_rate": 1.658255511866311e-05,
      "loss": 0.1198,
      "step": 76250
    },
    {
      "epoch": 2.0072608649900032,
      "grad_norm": 0.4641006588935852,
      "learning_rate": 1.656061297570566e-05,
      "loss": 0.1194,
      "step": 76300
    },
    {
      "epoch": 2.008576239082395,
      "grad_norm": 0.6295180320739746,
      "learning_rate": 1.653867083274821e-05,
      "loss": 0.1177,
      "step": 76350
    },
    {
      "epoch": 2.009891613174787,
      "grad_norm": 0.6209246516227722,
      "learning_rate": 1.651672868979076e-05,
      "loss": 0.1172,
      "step": 76400
    },
    {
      "epoch": 2.0112069872671787,
      "grad_norm": 0.7566696405410767,
      "learning_rate": 1.649478654683331e-05,
      "loss": 0.1195,
      "step": 76450
    },
    {
      "epoch": 2.012522361359571,
      "grad_norm": 0.9377085566520691,
      "learning_rate": 1.6472844403875863e-05,
      "loss": 0.1198,
      "step": 76500
    },
    {
      "epoch": 2.0138377354519625,
      "grad_norm": 0.6477500200271606,
      "learning_rate": 1.645090226091841e-05,
      "loss": 0.1163,
      "step": 76550
    },
    {
      "epoch": 2.0151531095443542,
      "grad_norm": 0.7257977724075317,
      "learning_rate": 1.642896011796096e-05,
      "loss": 0.1189,
      "step": 76600
    },
    {
      "epoch": 2.0164684836367464,
      "grad_norm": 0.6210934519767761,
      "learning_rate": 1.6407017975003512e-05,
      "loss": 0.1181,
      "step": 76650
    },
    {
      "epoch": 2.017783857729138,
      "grad_norm": 0.7876551151275635,
      "learning_rate": 1.6385075832046063e-05,
      "loss": 0.1213,
      "step": 76700
    },
    {
      "epoch": 2.01909923182153,
      "grad_norm": 0.74944669008255,
      "learning_rate": 1.636313368908861e-05,
      "loss": 0.1198,
      "step": 76750
    },
    {
      "epoch": 2.020414605913922,
      "grad_norm": 0.875465452671051,
      "learning_rate": 1.634119154613116e-05,
      "loss": 0.1197,
      "step": 76800
    },
    {
      "epoch": 2.021729980006314,
      "grad_norm": 0.7461525797843933,
      "learning_rate": 1.6319249403173712e-05,
      "loss": 0.1174,
      "step": 76850
    },
    {
      "epoch": 2.0230453540987057,
      "grad_norm": 0.7061991095542908,
      "learning_rate": 1.6297307260216263e-05,
      "loss": 0.1175,
      "step": 76900
    },
    {
      "epoch": 2.0243607281910974,
      "grad_norm": 0.5977601408958435,
      "learning_rate": 1.627536511725881e-05,
      "loss": 0.1163,
      "step": 76950
    },
    {
      "epoch": 2.0256761022834895,
      "grad_norm": 0.8391880393028259,
      "learning_rate": 1.6253422974301365e-05,
      "loss": 0.1182,
      "step": 77000
    },
    {
      "epoch": 2.026991476375881,
      "grad_norm": 0.8889813423156738,
      "learning_rate": 1.6231480831343912e-05,
      "loss": 0.1154,
      "step": 77050
    },
    {
      "epoch": 2.0283068504682733,
      "grad_norm": 0.9702685475349426,
      "learning_rate": 1.6209538688386463e-05,
      "loss": 0.1193,
      "step": 77100
    },
    {
      "epoch": 2.029622224560665,
      "grad_norm": 0.7639249563217163,
      "learning_rate": 1.6187596545429014e-05,
      "loss": 0.1189,
      "step": 77150
    },
    {
      "epoch": 2.030937598653057,
      "grad_norm": 0.8518871665000916,
      "learning_rate": 1.6165654402471565e-05,
      "loss": 0.116,
      "step": 77200
    },
    {
      "epoch": 2.032252972745449,
      "grad_norm": 0.8370088934898376,
      "learning_rate": 1.6143712259514112e-05,
      "loss": 0.1209,
      "step": 77250
    },
    {
      "epoch": 2.0335683468378405,
      "grad_norm": 0.6415115594863892,
      "learning_rate": 1.6121770116556663e-05,
      "loss": 0.1164,
      "step": 77300
    },
    {
      "epoch": 2.0348837209302326,
      "grad_norm": 0.8263447284698486,
      "learning_rate": 1.6099827973599214e-05,
      "loss": 0.1163,
      "step": 77350
    },
    {
      "epoch": 2.0361990950226243,
      "grad_norm": 0.6616854667663574,
      "learning_rate": 1.6077885830641765e-05,
      "loss": 0.1199,
      "step": 77400
    },
    {
      "epoch": 2.0375144691150164,
      "grad_norm": 0.6510196924209595,
      "learning_rate": 1.6055943687684316e-05,
      "loss": 0.1188,
      "step": 77450
    },
    {
      "epoch": 2.038829843207408,
      "grad_norm": 0.8910524249076843,
      "learning_rate": 1.6034001544726863e-05,
      "loss": 0.1183,
      "step": 77500
    },
    {
      "epoch": 2.0401452172998003,
      "grad_norm": 0.8276033997535706,
      "learning_rate": 1.6012059401769418e-05,
      "loss": 0.1209,
      "step": 77550
    },
    {
      "epoch": 2.041460591392192,
      "grad_norm": 0.6281507015228271,
      "learning_rate": 1.5990117258811965e-05,
      "loss": 0.1191,
      "step": 77600
    },
    {
      "epoch": 2.0427759654845836,
      "grad_norm": 0.6331636905670166,
      "learning_rate": 1.5968175115854516e-05,
      "loss": 0.1165,
      "step": 77650
    },
    {
      "epoch": 2.0440913395769758,
      "grad_norm": 0.6987155675888062,
      "learning_rate": 1.5946232972897067e-05,
      "loss": 0.1204,
      "step": 77700
    },
    {
      "epoch": 2.0454067136693674,
      "grad_norm": 0.8093588948249817,
      "learning_rate": 1.5924290829939618e-05,
      "loss": 0.1177,
      "step": 77750
    },
    {
      "epoch": 2.0467220877617596,
      "grad_norm": 0.777657687664032,
      "learning_rate": 1.5902348686982165e-05,
      "loss": 0.1177,
      "step": 77800
    },
    {
      "epoch": 2.0480374618541513,
      "grad_norm": 0.6986286640167236,
      "learning_rate": 1.5880406544024716e-05,
      "loss": 0.12,
      "step": 77850
    },
    {
      "epoch": 2.0493528359465434,
      "grad_norm": 0.8889144659042358,
      "learning_rate": 1.5858464401067267e-05,
      "loss": 0.1181,
      "step": 77900
    },
    {
      "epoch": 2.050668210038935,
      "grad_norm": 0.7240906953811646,
      "learning_rate": 1.5836522258109818e-05,
      "loss": 0.1189,
      "step": 77950
    },
    {
      "epoch": 2.0519835841313268,
      "grad_norm": 0.6872021555900574,
      "learning_rate": 1.5814580115152365e-05,
      "loss": 0.1185,
      "step": 78000
    },
    {
      "epoch": 2.053298958223719,
      "grad_norm": 0.6725361943244934,
      "learning_rate": 1.579263797219492e-05,
      "loss": 0.1174,
      "step": 78050
    },
    {
      "epoch": 2.0546143323161106,
      "grad_norm": 0.70786052942276,
      "learning_rate": 1.5770695829237467e-05,
      "loss": 0.1146,
      "step": 78100
    },
    {
      "epoch": 2.0559297064085027,
      "grad_norm": 0.7037646770477295,
      "learning_rate": 1.5748753686280018e-05,
      "loss": 0.1203,
      "step": 78150
    },
    {
      "epoch": 2.0572450805008944,
      "grad_norm": 0.8118566870689392,
      "learning_rate": 1.572681154332257e-05,
      "loss": 0.1212,
      "step": 78200
    },
    {
      "epoch": 2.0585604545932865,
      "grad_norm": 1.1049896478652954,
      "learning_rate": 1.570486940036512e-05,
      "loss": 0.1208,
      "step": 78250
    },
    {
      "epoch": 2.059875828685678,
      "grad_norm": 0.7772616744041443,
      "learning_rate": 1.5682927257407667e-05,
      "loss": 0.1146,
      "step": 78300
    },
    {
      "epoch": 2.06119120277807,
      "grad_norm": 0.7342955470085144,
      "learning_rate": 1.5660985114450218e-05,
      "loss": 0.1159,
      "step": 78350
    },
    {
      "epoch": 2.062506576870462,
      "grad_norm": 0.632373034954071,
      "learning_rate": 1.563904297149277e-05,
      "loss": 0.1179,
      "step": 78400
    },
    {
      "epoch": 2.0638219509628537,
      "grad_norm": 0.6583477854728699,
      "learning_rate": 1.561710082853532e-05,
      "loss": 0.1166,
      "step": 78450
    },
    {
      "epoch": 2.065137325055246,
      "grad_norm": 0.8991891741752625,
      "learning_rate": 1.5595158685577867e-05,
      "loss": 0.118,
      "step": 78500
    },
    {
      "epoch": 2.0664526991476375,
      "grad_norm": 0.8259248733520508,
      "learning_rate": 1.5573216542620418e-05,
      "loss": 0.1166,
      "step": 78550
    },
    {
      "epoch": 2.0677680732400296,
      "grad_norm": 0.710074245929718,
      "learning_rate": 1.555127439966297e-05,
      "loss": 0.1178,
      "step": 78600
    },
    {
      "epoch": 2.0690834473324213,
      "grad_norm": 0.7261193990707397,
      "learning_rate": 1.552933225670552e-05,
      "loss": 0.1179,
      "step": 78650
    },
    {
      "epoch": 2.070398821424813,
      "grad_norm": 0.6790871620178223,
      "learning_rate": 1.5507390113748067e-05,
      "loss": 0.1175,
      "step": 78700
    },
    {
      "epoch": 2.071714195517205,
      "grad_norm": 0.8257490396499634,
      "learning_rate": 1.548544797079062e-05,
      "loss": 0.1227,
      "step": 78750
    },
    {
      "epoch": 2.073029569609597,
      "grad_norm": 0.7630152106285095,
      "learning_rate": 1.546350582783317e-05,
      "loss": 0.1159,
      "step": 78800
    },
    {
      "epoch": 2.074344943701989,
      "grad_norm": 0.6830869317054749,
      "learning_rate": 1.544156368487572e-05,
      "loss": 0.1191,
      "step": 78850
    },
    {
      "epoch": 2.0756603177943806,
      "grad_norm": 0.8687649369239807,
      "learning_rate": 1.541962154191827e-05,
      "loss": 0.121,
      "step": 78900
    },
    {
      "epoch": 2.076975691886773,
      "grad_norm": 0.6682705879211426,
      "learning_rate": 1.539767939896082e-05,
      "loss": 0.118,
      "step": 78950
    },
    {
      "epoch": 2.0782910659791645,
      "grad_norm": 0.7606424689292908,
      "learning_rate": 1.537573725600337e-05,
      "loss": 0.1174,
      "step": 79000
    },
    {
      "epoch": 2.079606440071556,
      "grad_norm": 1.032459020614624,
      "learning_rate": 1.535379511304592e-05,
      "loss": 0.1178,
      "step": 79050
    },
    {
      "epoch": 2.0809218141639483,
      "grad_norm": 0.6595321297645569,
      "learning_rate": 1.5331852970088474e-05,
      "loss": 0.1203,
      "step": 79100
    },
    {
      "epoch": 2.08223718825634,
      "grad_norm": 0.7114269137382507,
      "learning_rate": 1.5309910827131022e-05,
      "loss": 0.118,
      "step": 79150
    },
    {
      "epoch": 2.083552562348732,
      "grad_norm": 0.7733494639396667,
      "learning_rate": 1.5287968684173573e-05,
      "loss": 0.1153,
      "step": 79200
    },
    {
      "epoch": 2.084867936441124,
      "grad_norm": 0.6712971329689026,
      "learning_rate": 1.5266026541216123e-05,
      "loss": 0.1155,
      "step": 79250
    },
    {
      "epoch": 2.086183310533516,
      "grad_norm": 0.8954846262931824,
      "learning_rate": 1.5244084398258673e-05,
      "loss": 0.1174,
      "step": 79300
    },
    {
      "epoch": 2.0874986846259076,
      "grad_norm": 0.8453094959259033,
      "learning_rate": 1.5222142255301222e-05,
      "loss": 0.1191,
      "step": 79350
    },
    {
      "epoch": 2.0888140587182993,
      "grad_norm": 0.5628310441970825,
      "learning_rate": 1.5200200112343774e-05,
      "loss": 0.1185,
      "step": 79400
    },
    {
      "epoch": 2.0901294328106914,
      "grad_norm": 0.5997951030731201,
      "learning_rate": 1.5178257969386322e-05,
      "loss": 0.1163,
      "step": 79450
    },
    {
      "epoch": 2.091444806903083,
      "grad_norm": 0.6802135109901428,
      "learning_rate": 1.5156315826428874e-05,
      "loss": 0.1186,
      "step": 79500
    },
    {
      "epoch": 2.0927601809954752,
      "grad_norm": 0.6351577043533325,
      "learning_rate": 1.5134373683471424e-05,
      "loss": 0.1168,
      "step": 79550
    },
    {
      "epoch": 2.094075555087867,
      "grad_norm": 0.6430363655090332,
      "learning_rate": 1.5112431540513975e-05,
      "loss": 0.1163,
      "step": 79600
    },
    {
      "epoch": 2.095390929180259,
      "grad_norm": 0.7804366946220398,
      "learning_rate": 1.5090489397556524e-05,
      "loss": 0.1179,
      "step": 79650
    },
    {
      "epoch": 2.0967063032726507,
      "grad_norm": 0.6919255256652832,
      "learning_rate": 1.5068547254599075e-05,
      "loss": 0.1172,
      "step": 79700
    },
    {
      "epoch": 2.0980216773650424,
      "grad_norm": 0.6918589472770691,
      "learning_rate": 1.5046605111641624e-05,
      "loss": 0.1159,
      "step": 79750
    },
    {
      "epoch": 2.0993370514574345,
      "grad_norm": 0.6433102488517761,
      "learning_rate": 1.5024662968684175e-05,
      "loss": 0.1185,
      "step": 79800
    },
    {
      "epoch": 2.1006524255498262,
      "grad_norm": 0.6187458634376526,
      "learning_rate": 1.5002720825726724e-05,
      "loss": 0.1164,
      "step": 79850
    },
    {
      "epoch": 2.1019677996422184,
      "grad_norm": 0.48280996084213257,
      "learning_rate": 1.4980778682769275e-05,
      "loss": 0.1195,
      "step": 79900
    },
    {
      "epoch": 2.10328317373461,
      "grad_norm": 0.9214876890182495,
      "learning_rate": 1.4958836539811824e-05,
      "loss": 0.1214,
      "step": 79950
    },
    {
      "epoch": 2.104598547827002,
      "grad_norm": 0.7693653702735901,
      "learning_rate": 1.4936894396854376e-05,
      "loss": 0.116,
      "step": 80000
    },
    {
      "epoch": 2.105913921919394,
      "grad_norm": 0.7865445017814636,
      "learning_rate": 1.4914952253896924e-05,
      "loss": 0.1125,
      "step": 80050
    },
    {
      "epoch": 2.1072292960117855,
      "grad_norm": 0.7696096897125244,
      "learning_rate": 1.4893010110939476e-05,
      "loss": 0.1167,
      "step": 80100
    },
    {
      "epoch": 2.1085446701041777,
      "grad_norm": 0.7276217341423035,
      "learning_rate": 1.4871067967982024e-05,
      "loss": 0.1159,
      "step": 80150
    },
    {
      "epoch": 2.1098600441965694,
      "grad_norm": 0.6557243466377258,
      "learning_rate": 1.4849125825024576e-05,
      "loss": 0.1157,
      "step": 80200
    },
    {
      "epoch": 2.1111754182889615,
      "grad_norm": 0.7123841047286987,
      "learning_rate": 1.4827183682067126e-05,
      "loss": 0.1176,
      "step": 80250
    },
    {
      "epoch": 2.112490792381353,
      "grad_norm": 0.5229874849319458,
      "learning_rate": 1.4805241539109677e-05,
      "loss": 0.1181,
      "step": 80300
    },
    {
      "epoch": 2.1138061664737453,
      "grad_norm": 0.8481717705726624,
      "learning_rate": 1.4783299396152226e-05,
      "loss": 0.1144,
      "step": 80350
    },
    {
      "epoch": 2.115121540566137,
      "grad_norm": 0.6511139273643494,
      "learning_rate": 1.4761357253194777e-05,
      "loss": 0.1195,
      "step": 80400
    },
    {
      "epoch": 2.1164369146585287,
      "grad_norm": 0.7305302619934082,
      "learning_rate": 1.4739415110237326e-05,
      "loss": 0.1144,
      "step": 80450
    },
    {
      "epoch": 2.117752288750921,
      "grad_norm": 0.6780564188957214,
      "learning_rate": 1.4717472967279877e-05,
      "loss": 0.1183,
      "step": 80500
    },
    {
      "epoch": 2.1190676628433125,
      "grad_norm": 0.6692240238189697,
      "learning_rate": 1.4695530824322426e-05,
      "loss": 0.1194,
      "step": 80550
    },
    {
      "epoch": 2.1203830369357046,
      "grad_norm": 0.6172805428504944,
      "learning_rate": 1.4673588681364978e-05,
      "loss": 0.1174,
      "step": 80600
    },
    {
      "epoch": 2.1216984110280963,
      "grad_norm": 0.7478702068328857,
      "learning_rate": 1.465164653840753e-05,
      "loss": 0.1156,
      "step": 80650
    },
    {
      "epoch": 2.1230137851204884,
      "grad_norm": 0.5522833466529846,
      "learning_rate": 1.4629704395450078e-05,
      "loss": 0.121,
      "step": 80700
    },
    {
      "epoch": 2.12432915921288,
      "grad_norm": 0.7398133277893066,
      "learning_rate": 1.460776225249263e-05,
      "loss": 0.1171,
      "step": 80750
    },
    {
      "epoch": 2.1256445333052723,
      "grad_norm": 0.6524018049240112,
      "learning_rate": 1.4585820109535178e-05,
      "loss": 0.1188,
      "step": 80800
    },
    {
      "epoch": 2.126959907397664,
      "grad_norm": 0.6451284289360046,
      "learning_rate": 1.456387796657773e-05,
      "loss": 0.1156,
      "step": 80850
    },
    {
      "epoch": 2.1282752814900556,
      "grad_norm": 0.7249531149864197,
      "learning_rate": 1.4541935823620279e-05,
      "loss": 0.1155,
      "step": 80900
    },
    {
      "epoch": 2.1295906555824478,
      "grad_norm": 0.7668550610542297,
      "learning_rate": 1.451999368066283e-05,
      "loss": 0.1152,
      "step": 80950
    },
    {
      "epoch": 2.1309060296748394,
      "grad_norm": 0.8163614869117737,
      "learning_rate": 1.4498051537705379e-05,
      "loss": 0.1151,
      "step": 81000
    },
    {
      "epoch": 2.1322214037672316,
      "grad_norm": 0.7971867918968201,
      "learning_rate": 1.4476109394747931e-05,
      "loss": 0.1185,
      "step": 81050
    },
    {
      "epoch": 2.1335367778596233,
      "grad_norm": 0.5981473922729492,
      "learning_rate": 1.4454167251790479e-05,
      "loss": 0.1177,
      "step": 81100
    },
    {
      "epoch": 2.134852151952015,
      "grad_norm": 0.7664485573768616,
      "learning_rate": 1.4432225108833031e-05,
      "loss": 0.1168,
      "step": 81150
    },
    {
      "epoch": 2.136167526044407,
      "grad_norm": 0.7744058966636658,
      "learning_rate": 1.4410282965875579e-05,
      "loss": 0.117,
      "step": 81200
    },
    {
      "epoch": 2.1374829001367988,
      "grad_norm": 0.6999581456184387,
      "learning_rate": 1.4388340822918131e-05,
      "loss": 0.1178,
      "step": 81250
    },
    {
      "epoch": 2.138798274229191,
      "grad_norm": 0.6153659224510193,
      "learning_rate": 1.436639867996068e-05,
      "loss": 0.1147,
      "step": 81300
    },
    {
      "epoch": 2.1401136483215826,
      "grad_norm": 0.7194294333457947,
      "learning_rate": 1.4344456537003231e-05,
      "loss": 0.1164,
      "step": 81350
    },
    {
      "epoch": 2.1414290224139747,
      "grad_norm": 0.7286555767059326,
      "learning_rate": 1.432251439404578e-05,
      "loss": 0.1138,
      "step": 81400
    },
    {
      "epoch": 2.1427443965063664,
      "grad_norm": 0.6193568110466003,
      "learning_rate": 1.4300572251088331e-05,
      "loss": 0.1139,
      "step": 81450
    },
    {
      "epoch": 2.1440597705987585,
      "grad_norm": 0.6704583168029785,
      "learning_rate": 1.427863010813088e-05,
      "loss": 0.1186,
      "step": 81500
    },
    {
      "epoch": 2.14537514469115,
      "grad_norm": 0.9319667816162109,
      "learning_rate": 1.4256687965173431e-05,
      "loss": 0.1171,
      "step": 81550
    },
    {
      "epoch": 2.146690518783542,
      "grad_norm": 0.7682581543922424,
      "learning_rate": 1.423474582221598e-05,
      "loss": 0.1157,
      "step": 81600
    },
    {
      "epoch": 2.148005892875934,
      "grad_norm": 0.7644827961921692,
      "learning_rate": 1.4212803679258533e-05,
      "loss": 0.1166,
      "step": 81650
    },
    {
      "epoch": 2.1493212669683257,
      "grad_norm": 0.732069194316864,
      "learning_rate": 1.419086153630108e-05,
      "loss": 0.1185,
      "step": 81700
    },
    {
      "epoch": 2.150636641060718,
      "grad_norm": 0.7708975672721863,
      "learning_rate": 1.4168919393343633e-05,
      "loss": 0.1155,
      "step": 81750
    },
    {
      "epoch": 2.1519520151531095,
      "grad_norm": 0.6585373878479004,
      "learning_rate": 1.414697725038618e-05,
      "loss": 0.1124,
      "step": 81800
    },
    {
      "epoch": 2.153267389245501,
      "grad_norm": 0.8048220276832581,
      "learning_rate": 1.4125035107428733e-05,
      "loss": 0.1182,
      "step": 81850
    },
    {
      "epoch": 2.1545827633378933,
      "grad_norm": 0.6371064782142639,
      "learning_rate": 1.4103092964471282e-05,
      "loss": 0.1179,
      "step": 81900
    },
    {
      "epoch": 2.155898137430285,
      "grad_norm": 0.6663500666618347,
      "learning_rate": 1.4081150821513833e-05,
      "loss": 0.113,
      "step": 81950
    },
    {
      "epoch": 2.157213511522677,
      "grad_norm": 0.8135324120521545,
      "learning_rate": 1.4059208678556382e-05,
      "loss": 0.1177,
      "step": 82000
    },
    {
      "epoch": 2.158528885615069,
      "grad_norm": 0.7711098194122314,
      "learning_rate": 1.4037266535598933e-05,
      "loss": 0.1165,
      "step": 82050
    },
    {
      "epoch": 2.159844259707461,
      "grad_norm": 0.6260383129119873,
      "learning_rate": 1.4015324392641482e-05,
      "loss": 0.1162,
      "step": 82100
    },
    {
      "epoch": 2.1611596337998527,
      "grad_norm": 0.7206165790557861,
      "learning_rate": 1.3993382249684033e-05,
      "loss": 0.118,
      "step": 82150
    },
    {
      "epoch": 2.162475007892245,
      "grad_norm": 0.5526609420776367,
      "learning_rate": 1.3971440106726583e-05,
      "loss": 0.1167,
      "step": 82200
    },
    {
      "epoch": 2.1637903819846365,
      "grad_norm": 0.6756032109260559,
      "learning_rate": 1.3949497963769133e-05,
      "loss": 0.1162,
      "step": 82250
    },
    {
      "epoch": 2.165105756077028,
      "grad_norm": 0.7844833731651306,
      "learning_rate": 1.3927555820811686e-05,
      "loss": 0.1184,
      "step": 82300
    },
    {
      "epoch": 2.1664211301694203,
      "grad_norm": 0.9495303630828857,
      "learning_rate": 1.3905613677854235e-05,
      "loss": 0.1117,
      "step": 82350
    },
    {
      "epoch": 2.167736504261812,
      "grad_norm": 0.6708545088768005,
      "learning_rate": 1.3883671534896786e-05,
      "loss": 0.1202,
      "step": 82400
    },
    {
      "epoch": 2.169051878354204,
      "grad_norm": 0.758560061454773,
      "learning_rate": 1.3861729391939335e-05,
      "loss": 0.119,
      "step": 82450
    },
    {
      "epoch": 2.170367252446596,
      "grad_norm": 0.7371582984924316,
      "learning_rate": 1.3839787248981886e-05,
      "loss": 0.1175,
      "step": 82500
    },
    {
      "epoch": 2.1716826265389875,
      "grad_norm": 0.8389998078346252,
      "learning_rate": 1.3817845106024435e-05,
      "loss": 0.1167,
      "step": 82550
    },
    {
      "epoch": 2.1729980006313796,
      "grad_norm": 0.7390478849411011,
      "learning_rate": 1.3795902963066986e-05,
      "loss": 0.1158,
      "step": 82600
    },
    {
      "epoch": 2.1743133747237713,
      "grad_norm": 0.7470880746841431,
      "learning_rate": 1.3773960820109535e-05,
      "loss": 0.1163,
      "step": 82650
    },
    {
      "epoch": 2.1756287488161634,
      "grad_norm": 0.7638784646987915,
      "learning_rate": 1.3752018677152088e-05,
      "loss": 0.1176,
      "step": 82700
    },
    {
      "epoch": 2.176944122908555,
      "grad_norm": 0.7472042441368103,
      "learning_rate": 1.3730076534194635e-05,
      "loss": 0.1156,
      "step": 82750
    },
    {
      "epoch": 2.1782594970009472,
      "grad_norm": 0.6832215785980225,
      "learning_rate": 1.3708134391237188e-05,
      "loss": 0.1172,
      "step": 82800
    },
    {
      "epoch": 2.179574871093339,
      "grad_norm": 0.72923743724823,
      "learning_rate": 1.3686192248279735e-05,
      "loss": 0.1178,
      "step": 82850
    },
    {
      "epoch": 2.180890245185731,
      "grad_norm": 0.6094014048576355,
      "learning_rate": 1.3664250105322288e-05,
      "loss": 0.1135,
      "step": 82900
    },
    {
      "epoch": 2.1822056192781227,
      "grad_norm": 0.625758945941925,
      "learning_rate": 1.3642307962364837e-05,
      "loss": 0.1136,
      "step": 82950
    },
    {
      "epoch": 2.1835209933705144,
      "grad_norm": 0.9417273998260498,
      "learning_rate": 1.3620365819407388e-05,
      "loss": 0.1154,
      "step": 83000
    },
    {
      "epoch": 2.1848363674629065,
      "grad_norm": 0.7585273385047913,
      "learning_rate": 1.3598423676449937e-05,
      "loss": 0.1155,
      "step": 83050
    },
    {
      "epoch": 2.1861517415552982,
      "grad_norm": 0.7158592939376831,
      "learning_rate": 1.3576481533492488e-05,
      "loss": 0.1183,
      "step": 83100
    },
    {
      "epoch": 2.1874671156476904,
      "grad_norm": 0.6243613362312317,
      "learning_rate": 1.3554539390535037e-05,
      "loss": 0.1167,
      "step": 83150
    },
    {
      "epoch": 2.188782489740082,
      "grad_norm": 0.6313419342041016,
      "learning_rate": 1.3532597247577588e-05,
      "loss": 0.1157,
      "step": 83200
    },
    {
      "epoch": 2.1900978638324737,
      "grad_norm": 0.7602099180221558,
      "learning_rate": 1.3510655104620137e-05,
      "loss": 0.1173,
      "step": 83250
    },
    {
      "epoch": 2.191413237924866,
      "grad_norm": 0.6273083090782166,
      "learning_rate": 1.3488712961662688e-05,
      "loss": 0.1169,
      "step": 83300
    },
    {
      "epoch": 2.1927286120172576,
      "grad_norm": 0.7151878476142883,
      "learning_rate": 1.3466770818705237e-05,
      "loss": 0.117,
      "step": 83350
    },
    {
      "epoch": 2.1940439861096497,
      "grad_norm": 0.7151218056678772,
      "learning_rate": 1.344482867574779e-05,
      "loss": 0.1147,
      "step": 83400
    },
    {
      "epoch": 2.1953593602020414,
      "grad_norm": 0.7109934091567993,
      "learning_rate": 1.3422886532790337e-05,
      "loss": 0.1193,
      "step": 83450
    },
    {
      "epoch": 2.1966747342944335,
      "grad_norm": 0.6620303988456726,
      "learning_rate": 1.340094438983289e-05,
      "loss": 0.1166,
      "step": 83500
    },
    {
      "epoch": 2.197990108386825,
      "grad_norm": 0.7507470846176147,
      "learning_rate": 1.3379002246875439e-05,
      "loss": 0.1187,
      "step": 83550
    },
    {
      "epoch": 2.1993054824792173,
      "grad_norm": 0.666663408279419,
      "learning_rate": 1.335706010391799e-05,
      "loss": 0.1178,
      "step": 83600
    },
    {
      "epoch": 2.200620856571609,
      "grad_norm": 0.7330395579338074,
      "learning_rate": 1.3335117960960539e-05,
      "loss": 0.1177,
      "step": 83650
    },
    {
      "epoch": 2.2019362306640007,
      "grad_norm": 0.7041341066360474,
      "learning_rate": 1.331317581800309e-05,
      "loss": 0.1161,
      "step": 83700
    },
    {
      "epoch": 2.203251604756393,
      "grad_norm": 0.808382511138916,
      "learning_rate": 1.329123367504564e-05,
      "loss": 0.1176,
      "step": 83750
    },
    {
      "epoch": 2.2045669788487845,
      "grad_norm": 0.9638981819152832,
      "learning_rate": 1.326929153208819e-05,
      "loss": 0.1136,
      "step": 83800
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 0.7381516098976135,
      "learning_rate": 1.3247349389130743e-05,
      "loss": 0.119,
      "step": 83850
    },
    {
      "epoch": 2.2071977270335683,
      "grad_norm": 0.7476189136505127,
      "learning_rate": 1.322540724617329e-05,
      "loss": 0.1163,
      "step": 83900
    },
    {
      "epoch": 2.20851310112596,
      "grad_norm": 0.6900057196617126,
      "learning_rate": 1.3203465103215843e-05,
      "loss": 0.1185,
      "step": 83950
    },
    {
      "epoch": 2.209828475218352,
      "grad_norm": 0.7623844146728516,
      "learning_rate": 1.3181522960258392e-05,
      "loss": 0.1152,
      "step": 84000
    },
    {
      "epoch": 2.211143849310744,
      "grad_norm": 0.6704246401786804,
      "learning_rate": 1.3159580817300943e-05,
      "loss": 0.1161,
      "step": 84050
    },
    {
      "epoch": 2.212459223403136,
      "grad_norm": 0.6922962665557861,
      "learning_rate": 1.3137638674343492e-05,
      "loss": 0.1163,
      "step": 84100
    },
    {
      "epoch": 2.2137745974955276,
      "grad_norm": 0.9052619934082031,
      "learning_rate": 1.3115696531386043e-05,
      "loss": 0.1161,
      "step": 84150
    },
    {
      "epoch": 2.2150899715879198,
      "grad_norm": 0.8068151473999023,
      "learning_rate": 1.3093754388428592e-05,
      "loss": 0.1139,
      "step": 84200
    },
    {
      "epoch": 2.2164053456803114,
      "grad_norm": 0.8133412003517151,
      "learning_rate": 1.3071812245471143e-05,
      "loss": 0.1187,
      "step": 84250
    },
    {
      "epoch": 2.2177207197727036,
      "grad_norm": 0.6373249888420105,
      "learning_rate": 1.3049870102513692e-05,
      "loss": 0.1191,
      "step": 84300
    },
    {
      "epoch": 2.2190360938650953,
      "grad_norm": 0.6411445140838623,
      "learning_rate": 1.3027927959556243e-05,
      "loss": 0.114,
      "step": 84350
    },
    {
      "epoch": 2.220351467957487,
      "grad_norm": 0.6908824443817139,
      "learning_rate": 1.3005985816598792e-05,
      "loss": 0.1148,
      "step": 84400
    },
    {
      "epoch": 2.221666842049879,
      "grad_norm": 0.5985629558563232,
      "learning_rate": 1.2984043673641345e-05,
      "loss": 0.1156,
      "step": 84450
    },
    {
      "epoch": 2.2229822161422708,
      "grad_norm": 0.5925891995429993,
      "learning_rate": 1.2962101530683892e-05,
      "loss": 0.1154,
      "step": 84500
    },
    {
      "epoch": 2.224297590234663,
      "grad_norm": 0.6944679021835327,
      "learning_rate": 1.2940159387726445e-05,
      "loss": 0.1146,
      "step": 84550
    },
    {
      "epoch": 2.2256129643270546,
      "grad_norm": 0.6881675720214844,
      "learning_rate": 1.2918217244768994e-05,
      "loss": 0.1174,
      "step": 84600
    },
    {
      "epoch": 2.2269283384194463,
      "grad_norm": 0.6549212336540222,
      "learning_rate": 1.2896275101811545e-05,
      "loss": 0.114,
      "step": 84650
    },
    {
      "epoch": 2.2282437125118384,
      "grad_norm": 0.621267557144165,
      "learning_rate": 1.2874332958854094e-05,
      "loss": 0.1182,
      "step": 84700
    },
    {
      "epoch": 2.22955908660423,
      "grad_norm": 0.7020729780197144,
      "learning_rate": 1.2852390815896645e-05,
      "loss": 0.1169,
      "step": 84750
    },
    {
      "epoch": 2.230874460696622,
      "grad_norm": 0.8309587836265564,
      "learning_rate": 1.2830448672939194e-05,
      "loss": 0.1161,
      "step": 84800
    },
    {
      "epoch": 2.232189834789014,
      "grad_norm": 0.7982097864151001,
      "learning_rate": 1.2808506529981745e-05,
      "loss": 0.1189,
      "step": 84850
    },
    {
      "epoch": 2.233505208881406,
      "grad_norm": 0.7559666633605957,
      "learning_rate": 1.2786564387024294e-05,
      "loss": 0.114,
      "step": 84900
    },
    {
      "epoch": 2.2348205829737977,
      "grad_norm": 0.6793925166130066,
      "learning_rate": 1.2764622244066845e-05,
      "loss": 0.1159,
      "step": 84950
    },
    {
      "epoch": 2.23613595706619,
      "grad_norm": 0.7042668461799622,
      "learning_rate": 1.2742680101109394e-05,
      "loss": 0.1129,
      "step": 85000
    },
    {
      "epoch": 2.2374513311585815,
      "grad_norm": 0.5605923533439636,
      "learning_rate": 1.2720737958151947e-05,
      "loss": 0.1152,
      "step": 85050
    },
    {
      "epoch": 2.238766705250973,
      "grad_norm": 0.6734822392463684,
      "learning_rate": 1.2698795815194494e-05,
      "loss": 0.1164,
      "step": 85100
    },
    {
      "epoch": 2.2400820793433653,
      "grad_norm": 0.5492846965789795,
      "learning_rate": 1.2676853672237047e-05,
      "loss": 0.1113,
      "step": 85150
    },
    {
      "epoch": 2.241397453435757,
      "grad_norm": 0.6765279173851013,
      "learning_rate": 1.2654911529279596e-05,
      "loss": 0.1169,
      "step": 85200
    },
    {
      "epoch": 2.242712827528149,
      "grad_norm": 0.7721644639968872,
      "learning_rate": 1.2632969386322147e-05,
      "loss": 0.1163,
      "step": 85250
    },
    {
      "epoch": 2.244028201620541,
      "grad_norm": 0.5409637093544006,
      "learning_rate": 1.2611027243364696e-05,
      "loss": 0.1151,
      "step": 85300
    },
    {
      "epoch": 2.2453435757129325,
      "grad_norm": 0.6217862367630005,
      "learning_rate": 1.2589085100407247e-05,
      "loss": 0.1144,
      "step": 85350
    },
    {
      "epoch": 2.2466589498053247,
      "grad_norm": 0.713392972946167,
      "learning_rate": 1.2567142957449796e-05,
      "loss": 0.1144,
      "step": 85400
    },
    {
      "epoch": 2.2479743238977163,
      "grad_norm": 0.7185108065605164,
      "learning_rate": 1.2545200814492347e-05,
      "loss": 0.1123,
      "step": 85450
    },
    {
      "epoch": 2.2492896979901085,
      "grad_norm": 0.6981930136680603,
      "learning_rate": 1.25232586715349e-05,
      "loss": 0.1118,
      "step": 85500
    },
    {
      "epoch": 2.2506050720825,
      "grad_norm": 0.5851852893829346,
      "learning_rate": 1.2501316528577447e-05,
      "loss": 0.1145,
      "step": 85550
    },
    {
      "epoch": 2.2519204461748923,
      "grad_norm": 0.6474440097808838,
      "learning_rate": 1.2479374385619998e-05,
      "loss": 0.1148,
      "step": 85600
    },
    {
      "epoch": 2.253235820267284,
      "grad_norm": 0.6580203175544739,
      "learning_rate": 1.2457432242662549e-05,
      "loss": 0.1179,
      "step": 85650
    },
    {
      "epoch": 2.254551194359676,
      "grad_norm": 0.7485557198524475,
      "learning_rate": 1.2435490099705098e-05,
      "loss": 0.1158,
      "step": 85700
    },
    {
      "epoch": 2.255866568452068,
      "grad_norm": 0.7495983839035034,
      "learning_rate": 1.2413547956747649e-05,
      "loss": 0.1148,
      "step": 85750
    },
    {
      "epoch": 2.2571819425444595,
      "grad_norm": 0.6977415680885315,
      "learning_rate": 1.2391605813790198e-05,
      "loss": 0.1196,
      "step": 85800
    },
    {
      "epoch": 2.2584973166368516,
      "grad_norm": 0.5674841403961182,
      "learning_rate": 1.2369663670832749e-05,
      "loss": 0.1163,
      "step": 85850
    },
    {
      "epoch": 2.2598126907292433,
      "grad_norm": 0.7895625829696655,
      "learning_rate": 1.2347721527875298e-05,
      "loss": 0.1156,
      "step": 85900
    },
    {
      "epoch": 2.2611280648216354,
      "grad_norm": 0.5374810099601746,
      "learning_rate": 1.2325779384917849e-05,
      "loss": 0.1155,
      "step": 85950
    },
    {
      "epoch": 2.262443438914027,
      "grad_norm": 0.6850084066390991,
      "learning_rate": 1.23038372419604e-05,
      "loss": 0.1154,
      "step": 86000
    },
    {
      "epoch": 2.263758813006419,
      "grad_norm": 0.7840126156806946,
      "learning_rate": 1.2281895099002949e-05,
      "loss": 0.1176,
      "step": 86050
    },
    {
      "epoch": 2.265074187098811,
      "grad_norm": 0.7127148509025574,
      "learning_rate": 1.22599529560455e-05,
      "loss": 0.1175,
      "step": 86100
    },
    {
      "epoch": 2.2663895611912026,
      "grad_norm": 0.8172913193702698,
      "learning_rate": 1.2238010813088049e-05,
      "loss": 0.1147,
      "step": 86150
    },
    {
      "epoch": 2.2677049352835947,
      "grad_norm": 0.6608052253723145,
      "learning_rate": 1.22160686701306e-05,
      "loss": 0.113,
      "step": 86200
    },
    {
      "epoch": 2.2690203093759864,
      "grad_norm": 0.7974931001663208,
      "learning_rate": 1.219412652717315e-05,
      "loss": 0.1125,
      "step": 86250
    },
    {
      "epoch": 2.2703356834683786,
      "grad_norm": 0.8178544640541077,
      "learning_rate": 1.2172184384215701e-05,
      "loss": 0.1158,
      "step": 86300
    },
    {
      "epoch": 2.2716510575607702,
      "grad_norm": 0.6650739312171936,
      "learning_rate": 1.2150242241258252e-05,
      "loss": 0.1146,
      "step": 86350
    },
    {
      "epoch": 2.2729664316531624,
      "grad_norm": 0.7851295471191406,
      "learning_rate": 1.2128300098300801e-05,
      "loss": 0.1149,
      "step": 86400
    },
    {
      "epoch": 2.274281805745554,
      "grad_norm": 0.580263078212738,
      "learning_rate": 1.2106357955343352e-05,
      "loss": 0.1162,
      "step": 86450
    },
    {
      "epoch": 2.2755971798379457,
      "grad_norm": 0.744412899017334,
      "learning_rate": 1.2084415812385901e-05,
      "loss": 0.1146,
      "step": 86500
    },
    {
      "epoch": 2.276912553930338,
      "grad_norm": 0.9065245389938354,
      "learning_rate": 1.2062473669428452e-05,
      "loss": 0.1152,
      "step": 86550
    },
    {
      "epoch": 2.2782279280227296,
      "grad_norm": 0.6788362264633179,
      "learning_rate": 1.2040531526471002e-05,
      "loss": 0.1154,
      "step": 86600
    },
    {
      "epoch": 2.2795433021151217,
      "grad_norm": 0.6551957130432129,
      "learning_rate": 1.2018589383513552e-05,
      "loss": 0.1161,
      "step": 86650
    },
    {
      "epoch": 2.2808586762075134,
      "grad_norm": 0.6398953795433044,
      "learning_rate": 1.1996647240556103e-05,
      "loss": 0.1162,
      "step": 86700
    },
    {
      "epoch": 2.282174050299905,
      "grad_norm": 0.7980324625968933,
      "learning_rate": 1.1974705097598652e-05,
      "loss": 0.1164,
      "step": 86750
    },
    {
      "epoch": 2.283489424392297,
      "grad_norm": 0.6669034361839294,
      "learning_rate": 1.1952762954641203e-05,
      "loss": 0.1141,
      "step": 86800
    },
    {
      "epoch": 2.284804798484689,
      "grad_norm": 0.5935550928115845,
      "learning_rate": 1.1930820811683752e-05,
      "loss": 0.1159,
      "step": 86850
    },
    {
      "epoch": 2.286120172577081,
      "grad_norm": 0.803534209728241,
      "learning_rate": 1.1908878668726303e-05,
      "loss": 0.116,
      "step": 86900
    },
    {
      "epoch": 2.2874355466694727,
      "grad_norm": 0.771018922328949,
      "learning_rate": 1.1886936525768853e-05,
      "loss": 0.115,
      "step": 86950
    },
    {
      "epoch": 2.288750920761865,
      "grad_norm": 0.6356111764907837,
      "learning_rate": 1.1864994382811403e-05,
      "loss": 0.1118,
      "step": 87000
    },
    {
      "epoch": 2.2900662948542565,
      "grad_norm": 0.8538355827331543,
      "learning_rate": 1.1843052239853954e-05,
      "loss": 0.1169,
      "step": 87050
    },
    {
      "epoch": 2.2913816689466486,
      "grad_norm": 0.6131211519241333,
      "learning_rate": 1.1821110096896503e-05,
      "loss": 0.1133,
      "step": 87100
    },
    {
      "epoch": 2.2926970430390403,
      "grad_norm": 0.7311997413635254,
      "learning_rate": 1.1799167953939054e-05,
      "loss": 0.1157,
      "step": 87150
    },
    {
      "epoch": 2.294012417131432,
      "grad_norm": 0.8719083666801453,
      "learning_rate": 1.1777225810981604e-05,
      "loss": 0.1171,
      "step": 87200
    },
    {
      "epoch": 2.295327791223824,
      "grad_norm": 0.6430301666259766,
      "learning_rate": 1.1755283668024154e-05,
      "loss": 0.1142,
      "step": 87250
    },
    {
      "epoch": 2.296643165316216,
      "grad_norm": 0.6220434308052063,
      "learning_rate": 1.1733341525066705e-05,
      "loss": 0.1135,
      "step": 87300
    },
    {
      "epoch": 2.297958539408608,
      "grad_norm": 0.7336249947547913,
      "learning_rate": 1.1711399382109254e-05,
      "loss": 0.117,
      "step": 87350
    },
    {
      "epoch": 2.2992739135009996,
      "grad_norm": 0.8654099106788635,
      "learning_rate": 1.1689457239151805e-05,
      "loss": 0.1147,
      "step": 87400
    },
    {
      "epoch": 2.3005892875933913,
      "grad_norm": 0.689082145690918,
      "learning_rate": 1.1667515096194354e-05,
      "loss": 0.1151,
      "step": 87450
    },
    {
      "epoch": 2.3019046616857834,
      "grad_norm": 0.6261812448501587,
      "learning_rate": 1.1645572953236905e-05,
      "loss": 0.1136,
      "step": 87500
    },
    {
      "epoch": 2.303220035778175,
      "grad_norm": 0.6314072608947754,
      "learning_rate": 1.1623630810279455e-05,
      "loss": 0.1135,
      "step": 87550
    },
    {
      "epoch": 2.3045354098705673,
      "grad_norm": 0.8292147517204285,
      "learning_rate": 1.1601688667322005e-05,
      "loss": 0.1153,
      "step": 87600
    },
    {
      "epoch": 2.305850783962959,
      "grad_norm": 0.6747227907180786,
      "learning_rate": 1.1579746524364556e-05,
      "loss": 0.1142,
      "step": 87650
    },
    {
      "epoch": 2.307166158055351,
      "grad_norm": 0.722652792930603,
      "learning_rate": 1.1557804381407105e-05,
      "loss": 0.1139,
      "step": 87700
    },
    {
      "epoch": 2.3084815321477428,
      "grad_norm": 0.7915562987327576,
      "learning_rate": 1.1535862238449656e-05,
      "loss": 0.1131,
      "step": 87750
    },
    {
      "epoch": 2.309796906240135,
      "grad_norm": 0.7179797291755676,
      "learning_rate": 1.1513920095492205e-05,
      "loss": 0.1145,
      "step": 87800
    },
    {
      "epoch": 2.3111122803325266,
      "grad_norm": 0.7913851141929626,
      "learning_rate": 1.1491977952534756e-05,
      "loss": 0.1124,
      "step": 87850
    },
    {
      "epoch": 2.3124276544249183,
      "grad_norm": 0.7520480751991272,
      "learning_rate": 1.1470035809577307e-05,
      "loss": 0.1121,
      "step": 87900
    },
    {
      "epoch": 2.3137430285173104,
      "grad_norm": 0.6128472685813904,
      "learning_rate": 1.1448093666619858e-05,
      "loss": 0.1144,
      "step": 87950
    },
    {
      "epoch": 2.315058402609702,
      "grad_norm": 0.8100541234016418,
      "learning_rate": 1.1426151523662407e-05,
      "loss": 0.1125,
      "step": 88000
    },
    {
      "epoch": 2.316373776702094,
      "grad_norm": 0.6614614725112915,
      "learning_rate": 1.1404209380704958e-05,
      "loss": 0.1168,
      "step": 88050
    },
    {
      "epoch": 2.317689150794486,
      "grad_norm": 0.6883108615875244,
      "learning_rate": 1.1382267237747509e-05,
      "loss": 0.1155,
      "step": 88100
    },
    {
      "epoch": 2.3190045248868776,
      "grad_norm": 0.8061444163322449,
      "learning_rate": 1.1360325094790058e-05,
      "loss": 0.1134,
      "step": 88150
    },
    {
      "epoch": 2.3203198989792697,
      "grad_norm": 0.7362558841705322,
      "learning_rate": 1.1338382951832609e-05,
      "loss": 0.1159,
      "step": 88200
    },
    {
      "epoch": 2.3216352730716614,
      "grad_norm": 0.7922254800796509,
      "learning_rate": 1.1316440808875158e-05,
      "loss": 0.1146,
      "step": 88250
    },
    {
      "epoch": 2.3229506471640535,
      "grad_norm": 0.7739031910896301,
      "learning_rate": 1.1294498665917709e-05,
      "loss": 0.1119,
      "step": 88300
    },
    {
      "epoch": 2.324266021256445,
      "grad_norm": 0.6971380114555359,
      "learning_rate": 1.127255652296026e-05,
      "loss": 0.1154,
      "step": 88350
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 0.5885463356971741,
      "learning_rate": 1.125061438000281e-05,
      "loss": 0.1089,
      "step": 88400
    },
    {
      "epoch": 2.326896769441229,
      "grad_norm": 0.4879136383533478,
      "learning_rate": 1.122867223704536e-05,
      "loss": 0.1127,
      "step": 88450
    },
    {
      "epoch": 2.328212143533621,
      "grad_norm": 0.6738616228103638,
      "learning_rate": 1.120673009408791e-05,
      "loss": 0.1134,
      "step": 88500
    },
    {
      "epoch": 2.329527517626013,
      "grad_norm": 0.5717836618423462,
      "learning_rate": 1.118478795113046e-05,
      "loss": 0.1159,
      "step": 88550
    },
    {
      "epoch": 2.3308428917184045,
      "grad_norm": 0.5739544034004211,
      "learning_rate": 1.116284580817301e-05,
      "loss": 0.1137,
      "step": 88600
    },
    {
      "epoch": 2.3321582658107967,
      "grad_norm": 0.6414133310317993,
      "learning_rate": 1.114090366521556e-05,
      "loss": 0.1191,
      "step": 88650
    },
    {
      "epoch": 2.3334736399031883,
      "grad_norm": 0.7388787865638733,
      "learning_rate": 1.1118961522258111e-05,
      "loss": 0.1171,
      "step": 88700
    },
    {
      "epoch": 2.3347890139955805,
      "grad_norm": 0.5593908429145813,
      "learning_rate": 1.109701937930066e-05,
      "loss": 0.1142,
      "step": 88750
    },
    {
      "epoch": 2.336104388087972,
      "grad_norm": 0.7462307214736938,
      "learning_rate": 1.1075077236343211e-05,
      "loss": 0.1135,
      "step": 88800
    },
    {
      "epoch": 2.337419762180364,
      "grad_norm": 0.9104514122009277,
      "learning_rate": 1.105313509338576e-05,
      "loss": 0.1118,
      "step": 88850
    },
    {
      "epoch": 2.338735136272756,
      "grad_norm": 0.6311781406402588,
      "learning_rate": 1.1031192950428311e-05,
      "loss": 0.1127,
      "step": 88900
    },
    {
      "epoch": 2.3400505103651477,
      "grad_norm": 0.7710772752761841,
      "learning_rate": 1.1009250807470862e-05,
      "loss": 0.1127,
      "step": 88950
    },
    {
      "epoch": 2.34136588445754,
      "grad_norm": 0.7458611130714417,
      "learning_rate": 1.0987308664513411e-05,
      "loss": 0.1129,
      "step": 89000
    },
    {
      "epoch": 2.3426812585499315,
      "grad_norm": 0.6052608489990234,
      "learning_rate": 1.0965366521555962e-05,
      "loss": 0.1161,
      "step": 89050
    },
    {
      "epoch": 2.3439966326423236,
      "grad_norm": 0.6404485106468201,
      "learning_rate": 1.0943424378598511e-05,
      "loss": 0.1144,
      "step": 89100
    },
    {
      "epoch": 2.3453120067347153,
      "grad_norm": 0.6059409976005554,
      "learning_rate": 1.0921482235641062e-05,
      "loss": 0.113,
      "step": 89150
    },
    {
      "epoch": 2.3466273808271074,
      "grad_norm": 0.7920482754707336,
      "learning_rate": 1.0899540092683611e-05,
      "loss": 0.1131,
      "step": 89200
    },
    {
      "epoch": 2.347942754919499,
      "grad_norm": 0.7452194094657898,
      "learning_rate": 1.0877597949726162e-05,
      "loss": 0.1125,
      "step": 89250
    },
    {
      "epoch": 2.349258129011891,
      "grad_norm": 0.8062757253646851,
      "learning_rate": 1.0855655806768713e-05,
      "loss": 0.1133,
      "step": 89300
    },
    {
      "epoch": 2.350573503104283,
      "grad_norm": 0.4746024012565613,
      "learning_rate": 1.0833713663811262e-05,
      "loss": 0.1137,
      "step": 89350
    },
    {
      "epoch": 2.3518888771966746,
      "grad_norm": 0.7517062425613403,
      "learning_rate": 1.0811771520853813e-05,
      "loss": 0.115,
      "step": 89400
    },
    {
      "epoch": 2.3532042512890667,
      "grad_norm": 0.6600834131240845,
      "learning_rate": 1.0789829377896362e-05,
      "loss": 0.1145,
      "step": 89450
    },
    {
      "epoch": 2.3545196253814584,
      "grad_norm": 0.7392928600311279,
      "learning_rate": 1.0767887234938915e-05,
      "loss": 0.1122,
      "step": 89500
    },
    {
      "epoch": 2.3558349994738506,
      "grad_norm": 0.722697913646698,
      "learning_rate": 1.0745945091981464e-05,
      "loss": 0.1157,
      "step": 89550
    },
    {
      "epoch": 2.3571503735662422,
      "grad_norm": 0.7224410772323608,
      "learning_rate": 1.0724002949024015e-05,
      "loss": 0.1145,
      "step": 89600
    },
    {
      "epoch": 2.358465747658634,
      "grad_norm": 0.7236426472663879,
      "learning_rate": 1.0702060806066564e-05,
      "loss": 0.1124,
      "step": 89650
    },
    {
      "epoch": 2.359781121751026,
      "grad_norm": 0.6014525294303894,
      "learning_rate": 1.0680118663109115e-05,
      "loss": 0.1131,
      "step": 89700
    },
    {
      "epoch": 2.3610964958434177,
      "grad_norm": 0.6542444229125977,
      "learning_rate": 1.0658176520151666e-05,
      "loss": 0.115,
      "step": 89750
    },
    {
      "epoch": 2.36241186993581,
      "grad_norm": 0.6606737971305847,
      "learning_rate": 1.0636234377194215e-05,
      "loss": 0.114,
      "step": 89800
    },
    {
      "epoch": 2.3637272440282016,
      "grad_norm": 0.6824236512184143,
      "learning_rate": 1.0614292234236766e-05,
      "loss": 0.1184,
      "step": 89850
    },
    {
      "epoch": 2.3650426181205937,
      "grad_norm": 0.774711012840271,
      "learning_rate": 1.0592350091279315e-05,
      "loss": 0.1137,
      "step": 89900
    },
    {
      "epoch": 2.3663579922129854,
      "grad_norm": 0.8270300030708313,
      "learning_rate": 1.0570407948321866e-05,
      "loss": 0.1115,
      "step": 89950
    },
    {
      "epoch": 2.367673366305377,
      "grad_norm": 0.6745705008506775,
      "learning_rate": 1.0548465805364417e-05,
      "loss": 0.1116,
      "step": 90000
    },
    {
      "epoch": 2.368988740397769,
      "grad_norm": 0.7293895483016968,
      "learning_rate": 1.0526523662406966e-05,
      "loss": 0.1138,
      "step": 90050
    },
    {
      "epoch": 2.370304114490161,
      "grad_norm": 0.5521993041038513,
      "learning_rate": 1.0504581519449517e-05,
      "loss": 0.1166,
      "step": 90100
    },
    {
      "epoch": 2.371619488582553,
      "grad_norm": 0.7290650606155396,
      "learning_rate": 1.0482639376492066e-05,
      "loss": 0.116,
      "step": 90150
    },
    {
      "epoch": 2.3729348626749447,
      "grad_norm": 0.7781174182891846,
      "learning_rate": 1.0460697233534617e-05,
      "loss": 0.1167,
      "step": 90200
    },
    {
      "epoch": 2.374250236767337,
      "grad_norm": 0.7917898297309875,
      "learning_rate": 1.0438755090577166e-05,
      "loss": 0.1109,
      "step": 90250
    },
    {
      "epoch": 2.3755656108597285,
      "grad_norm": 0.5941661596298218,
      "learning_rate": 1.0416812947619717e-05,
      "loss": 0.1122,
      "step": 90300
    },
    {
      "epoch": 2.37688098495212,
      "grad_norm": 0.7809158563613892,
      "learning_rate": 1.0394870804662268e-05,
      "loss": 0.113,
      "step": 90350
    },
    {
      "epoch": 2.3781963590445123,
      "grad_norm": 0.680653989315033,
      "learning_rate": 1.0372928661704817e-05,
      "loss": 0.1134,
      "step": 90400
    },
    {
      "epoch": 2.379511733136904,
      "grad_norm": 0.7785906195640564,
      "learning_rate": 1.0350986518747368e-05,
      "loss": 0.1127,
      "step": 90450
    },
    {
      "epoch": 2.380827107229296,
      "grad_norm": 0.9004829525947571,
      "learning_rate": 1.0329044375789917e-05,
      "loss": 0.1123,
      "step": 90500
    },
    {
      "epoch": 2.382142481321688,
      "grad_norm": 0.5377029776573181,
      "learning_rate": 1.0307102232832468e-05,
      "loss": 0.1126,
      "step": 90550
    },
    {
      "epoch": 2.38345785541408,
      "grad_norm": 0.6854557394981384,
      "learning_rate": 1.0285160089875017e-05,
      "loss": 0.1154,
      "step": 90600
    },
    {
      "epoch": 2.3847732295064716,
      "grad_norm": 0.7029417157173157,
      "learning_rate": 1.0263217946917568e-05,
      "loss": 0.1151,
      "step": 90650
    },
    {
      "epoch": 2.3860886035988633,
      "grad_norm": 0.8236413598060608,
      "learning_rate": 1.0241275803960119e-05,
      "loss": 0.1149,
      "step": 90700
    },
    {
      "epoch": 2.3874039776912555,
      "grad_norm": 0.7728734016418457,
      "learning_rate": 1.0219333661002668e-05,
      "loss": 0.1132,
      "step": 90750
    },
    {
      "epoch": 2.388719351783647,
      "grad_norm": 0.5869624018669128,
      "learning_rate": 1.0197391518045219e-05,
      "loss": 0.1129,
      "step": 90800
    },
    {
      "epoch": 2.3900347258760393,
      "grad_norm": 0.654535174369812,
      "learning_rate": 1.0175449375087768e-05,
      "loss": 0.1119,
      "step": 90850
    },
    {
      "epoch": 2.391350099968431,
      "grad_norm": 0.7681087851524353,
      "learning_rate": 1.0153507232130319e-05,
      "loss": 0.1134,
      "step": 90900
    },
    {
      "epoch": 2.392665474060823,
      "grad_norm": 0.7501047849655151,
      "learning_rate": 1.013156508917287e-05,
      "loss": 0.1121,
      "step": 90950
    },
    {
      "epoch": 2.3939808481532148,
      "grad_norm": 0.7919572591781616,
      "learning_rate": 1.0109622946215419e-05,
      "loss": 0.1121,
      "step": 91000
    },
    {
      "epoch": 2.395296222245607,
      "grad_norm": 0.7320232391357422,
      "learning_rate": 1.008768080325797e-05,
      "loss": 0.1159,
      "step": 91050
    },
    {
      "epoch": 2.3966115963379986,
      "grad_norm": 0.6621981859207153,
      "learning_rate": 1.006573866030052e-05,
      "loss": 0.1127,
      "step": 91100
    },
    {
      "epoch": 2.3979269704303903,
      "grad_norm": 0.5181030035018921,
      "learning_rate": 1.0043796517343071e-05,
      "loss": 0.1139,
      "step": 91150
    },
    {
      "epoch": 2.3992423445227824,
      "grad_norm": 0.5759830474853516,
      "learning_rate": 1.002185437438562e-05,
      "loss": 0.1139,
      "step": 91200
    },
    {
      "epoch": 2.400557718615174,
      "grad_norm": 0.6559774875640869,
      "learning_rate": 9.999912231428172e-06,
      "loss": 0.1109,
      "step": 91250
    },
    {
      "epoch": 2.401873092707566,
      "grad_norm": 0.6629454493522644,
      "learning_rate": 9.97797008847072e-06,
      "loss": 0.1099,
      "step": 91300
    },
    {
      "epoch": 2.403188466799958,
      "grad_norm": 0.8011283278465271,
      "learning_rate": 9.956027945513272e-06,
      "loss": 0.1109,
      "step": 91350
    },
    {
      "epoch": 2.4045038408923496,
      "grad_norm": 0.6454499363899231,
      "learning_rate": 9.934085802555822e-06,
      "loss": 0.1114,
      "step": 91400
    },
    {
      "epoch": 2.4058192149847417,
      "grad_norm": 0.7067204713821411,
      "learning_rate": 9.912143659598372e-06,
      "loss": 0.113,
      "step": 91450
    },
    {
      "epoch": 2.4071345890771334,
      "grad_norm": 0.6793055534362793,
      "learning_rate": 9.890201516640922e-06,
      "loss": 0.1137,
      "step": 91500
    },
    {
      "epoch": 2.4084499631695255,
      "grad_norm": 0.6602415442466736,
      "learning_rate": 9.868259373683472e-06,
      "loss": 0.1134,
      "step": 91550
    },
    {
      "epoch": 2.409765337261917,
      "grad_norm": 0.6738387942314148,
      "learning_rate": 9.846317230726023e-06,
      "loss": 0.1143,
      "step": 91600
    },
    {
      "epoch": 2.4110807113543093,
      "grad_norm": 0.7155839204788208,
      "learning_rate": 9.824375087768572e-06,
      "loss": 0.115,
      "step": 91650
    },
    {
      "epoch": 2.412396085446701,
      "grad_norm": 0.5702306032180786,
      "learning_rate": 9.802432944811123e-06,
      "loss": 0.1143,
      "step": 91700
    },
    {
      "epoch": 2.413711459539093,
      "grad_norm": 0.8467562794685364,
      "learning_rate": 9.780490801853673e-06,
      "loss": 0.1144,
      "step": 91750
    },
    {
      "epoch": 2.415026833631485,
      "grad_norm": 0.7951098084449768,
      "learning_rate": 9.758548658896223e-06,
      "loss": 0.1175,
      "step": 91800
    },
    {
      "epoch": 2.4163422077238765,
      "grad_norm": 0.7295325994491577,
      "learning_rate": 9.736606515938774e-06,
      "loss": 0.1149,
      "step": 91850
    },
    {
      "epoch": 2.4176575818162687,
      "grad_norm": 0.6183794736862183,
      "learning_rate": 9.714664372981323e-06,
      "loss": 0.1139,
      "step": 91900
    },
    {
      "epoch": 2.4189729559086603,
      "grad_norm": 0.7305231094360352,
      "learning_rate": 9.692722230023874e-06,
      "loss": 0.1141,
      "step": 91950
    },
    {
      "epoch": 2.4202883300010525,
      "grad_norm": 0.6575157046318054,
      "learning_rate": 9.670780087066424e-06,
      "loss": 0.1109,
      "step": 92000
    },
    {
      "epoch": 2.421603704093444,
      "grad_norm": 0.5779622793197632,
      "learning_rate": 9.648837944108974e-06,
      "loss": 0.1128,
      "step": 92050
    },
    {
      "epoch": 2.422919078185836,
      "grad_norm": 0.5833436250686646,
      "learning_rate": 9.626895801151524e-06,
      "loss": 0.1148,
      "step": 92100
    },
    {
      "epoch": 2.424234452278228,
      "grad_norm": 0.727561891078949,
      "learning_rate": 9.604953658194074e-06,
      "loss": 0.1134,
      "step": 92150
    },
    {
      "epoch": 2.4255498263706197,
      "grad_norm": 0.6040701866149902,
      "learning_rate": 9.583011515236625e-06,
      "loss": 0.1112,
      "step": 92200
    },
    {
      "epoch": 2.426865200463012,
      "grad_norm": 0.5842161774635315,
      "learning_rate": 9.561069372279174e-06,
      "loss": 0.1146,
      "step": 92250
    },
    {
      "epoch": 2.4281805745554035,
      "grad_norm": 0.8693997263908386,
      "learning_rate": 9.539127229321725e-06,
      "loss": 0.1131,
      "step": 92300
    },
    {
      "epoch": 2.4294959486477956,
      "grad_norm": 0.7083768248558044,
      "learning_rate": 9.517185086364275e-06,
      "loss": 0.1126,
      "step": 92350
    },
    {
      "epoch": 2.4308113227401873,
      "grad_norm": 0.6758661866188049,
      "learning_rate": 9.495242943406825e-06,
      "loss": 0.1119,
      "step": 92400
    },
    {
      "epoch": 2.4321266968325794,
      "grad_norm": 0.6866936087608337,
      "learning_rate": 9.473300800449375e-06,
      "loss": 0.1125,
      "step": 92450
    },
    {
      "epoch": 2.433442070924971,
      "grad_norm": 0.6632773280143738,
      "learning_rate": 9.451358657491925e-06,
      "loss": 0.1131,
      "step": 92500
    },
    {
      "epoch": 2.434757445017363,
      "grad_norm": 0.6929035186767578,
      "learning_rate": 9.429416514534476e-06,
      "loss": 0.1116,
      "step": 92550
    },
    {
      "epoch": 2.436072819109755,
      "grad_norm": 0.6633296012878418,
      "learning_rate": 9.407474371577025e-06,
      "loss": 0.1126,
      "step": 92600
    },
    {
      "epoch": 2.4373881932021466,
      "grad_norm": 0.9244080185890198,
      "learning_rate": 9.385532228619576e-06,
      "loss": 0.1123,
      "step": 92650
    },
    {
      "epoch": 2.4387035672945387,
      "grad_norm": 0.7984448671340942,
      "learning_rate": 9.363590085662126e-06,
      "loss": 0.1144,
      "step": 92700
    },
    {
      "epoch": 2.4400189413869304,
      "grad_norm": 0.7249777913093567,
      "learning_rate": 9.341647942704677e-06,
      "loss": 0.1134,
      "step": 92750
    },
    {
      "epoch": 2.441334315479322,
      "grad_norm": 0.694089412689209,
      "learning_rate": 9.319705799747228e-06,
      "loss": 0.112,
      "step": 92800
    },
    {
      "epoch": 2.4426496895717142,
      "grad_norm": 0.8089920282363892,
      "learning_rate": 9.297763656789777e-06,
      "loss": 0.1142,
      "step": 92850
    },
    {
      "epoch": 2.443965063664106,
      "grad_norm": 0.6426153182983398,
      "learning_rate": 9.275821513832328e-06,
      "loss": 0.1143,
      "step": 92900
    },
    {
      "epoch": 2.445280437756498,
      "grad_norm": 0.6456488966941833,
      "learning_rate": 9.253879370874877e-06,
      "loss": 0.1114,
      "step": 92950
    },
    {
      "epoch": 2.4465958118488897,
      "grad_norm": 0.5758194923400879,
      "learning_rate": 9.231937227917428e-06,
      "loss": 0.1117,
      "step": 93000
    },
    {
      "epoch": 2.447911185941282,
      "grad_norm": 0.6795640587806702,
      "learning_rate": 9.209995084959979e-06,
      "loss": 0.1109,
      "step": 93050
    },
    {
      "epoch": 2.4492265600336736,
      "grad_norm": 0.6248614192008972,
      "learning_rate": 9.188052942002528e-06,
      "loss": 0.1105,
      "step": 93100
    },
    {
      "epoch": 2.4505419341260657,
      "grad_norm": 0.5142817497253418,
      "learning_rate": 9.16611079904508e-06,
      "loss": 0.1124,
      "step": 93150
    },
    {
      "epoch": 2.4518573082184574,
      "grad_norm": 0.7796757817268372,
      "learning_rate": 9.144168656087628e-06,
      "loss": 0.1147,
      "step": 93200
    },
    {
      "epoch": 2.453172682310849,
      "grad_norm": 0.5361292362213135,
      "learning_rate": 9.12222651313018e-06,
      "loss": 0.1137,
      "step": 93250
    },
    {
      "epoch": 2.454488056403241,
      "grad_norm": 0.708003580570221,
      "learning_rate": 9.100284370172728e-06,
      "loss": 0.1161,
      "step": 93300
    },
    {
      "epoch": 2.455803430495633,
      "grad_norm": 0.5882454514503479,
      "learning_rate": 9.07834222721528e-06,
      "loss": 0.1116,
      "step": 93350
    },
    {
      "epoch": 2.457118804588025,
      "grad_norm": 0.747698962688446,
      "learning_rate": 9.05640008425783e-06,
      "loss": 0.1141,
      "step": 93400
    },
    {
      "epoch": 2.4584341786804167,
      "grad_norm": 0.6876479387283325,
      "learning_rate": 9.03445794130038e-06,
      "loss": 0.1135,
      "step": 93450
    },
    {
      "epoch": 2.4597495527728084,
      "grad_norm": 0.667370080947876,
      "learning_rate": 9.01251579834293e-06,
      "loss": 0.1134,
      "step": 93500
    },
    {
      "epoch": 2.4610649268652005,
      "grad_norm": 0.6892321109771729,
      "learning_rate": 8.99057365538548e-06,
      "loss": 0.1137,
      "step": 93550
    },
    {
      "epoch": 2.462380300957592,
      "grad_norm": 0.6410191059112549,
      "learning_rate": 8.96863151242803e-06,
      "loss": 0.1125,
      "step": 93600
    },
    {
      "epoch": 2.4636956750499843,
      "grad_norm": 0.8189589381217957,
      "learning_rate": 8.946689369470581e-06,
      "loss": 0.1105,
      "step": 93650
    },
    {
      "epoch": 2.465011049142376,
      "grad_norm": 0.5964072942733765,
      "learning_rate": 8.92474722651313e-06,
      "loss": 0.1139,
      "step": 93700
    },
    {
      "epoch": 2.466326423234768,
      "grad_norm": 0.8619793653488159,
      "learning_rate": 8.902805083555681e-06,
      "loss": 0.1121,
      "step": 93750
    },
    {
      "epoch": 2.46764179732716,
      "grad_norm": 0.744900107383728,
      "learning_rate": 8.88086294059823e-06,
      "loss": 0.1141,
      "step": 93800
    },
    {
      "epoch": 2.468957171419552,
      "grad_norm": 0.6334542632102966,
      "learning_rate": 8.858920797640781e-06,
      "loss": 0.1117,
      "step": 93850
    },
    {
      "epoch": 2.4702725455119436,
      "grad_norm": 0.6299904584884644,
      "learning_rate": 8.83697865468333e-06,
      "loss": 0.1127,
      "step": 93900
    },
    {
      "epoch": 2.4715879196043353,
      "grad_norm": 0.6664081811904907,
      "learning_rate": 8.815036511725881e-06,
      "loss": 0.1133,
      "step": 93950
    },
    {
      "epoch": 2.4729032936967275,
      "grad_norm": 0.6531686186790466,
      "learning_rate": 8.793094368768432e-06,
      "loss": 0.1125,
      "step": 94000
    },
    {
      "epoch": 2.474218667789119,
      "grad_norm": 0.661646842956543,
      "learning_rate": 8.771152225810981e-06,
      "loss": 0.1137,
      "step": 94050
    },
    {
      "epoch": 2.4755340418815113,
      "grad_norm": 0.5420511364936829,
      "learning_rate": 8.749210082853532e-06,
      "loss": 0.1127,
      "step": 94100
    },
    {
      "epoch": 2.476849415973903,
      "grad_norm": 0.6451237201690674,
      "learning_rate": 8.727267939896081e-06,
      "loss": 0.1149,
      "step": 94150
    },
    {
      "epoch": 2.4781647900662946,
      "grad_norm": 0.6777368783950806,
      "learning_rate": 8.705325796938632e-06,
      "loss": 0.1107,
      "step": 94200
    },
    {
      "epoch": 2.4794801641586868,
      "grad_norm": 0.620084822177887,
      "learning_rate": 8.683383653981181e-06,
      "loss": 0.1155,
      "step": 94250
    },
    {
      "epoch": 2.4807955382510785,
      "grad_norm": 0.5945659279823303,
      "learning_rate": 8.661441511023732e-06,
      "loss": 0.1101,
      "step": 94300
    },
    {
      "epoch": 2.4821109123434706,
      "grad_norm": 0.7577589154243469,
      "learning_rate": 8.639499368066283e-06,
      "loss": 0.1123,
      "step": 94350
    },
    {
      "epoch": 2.4834262864358623,
      "grad_norm": 0.6254926323890686,
      "learning_rate": 8.617557225108834e-06,
      "loss": 0.1142,
      "step": 94400
    },
    {
      "epoch": 2.4847416605282544,
      "grad_norm": 0.7583210468292236,
      "learning_rate": 8.595615082151385e-06,
      "loss": 0.1135,
      "step": 94450
    },
    {
      "epoch": 2.486057034620646,
      "grad_norm": 0.7616118788719177,
      "learning_rate": 8.573672939193934e-06,
      "loss": 0.1133,
      "step": 94500
    },
    {
      "epoch": 2.487372408713038,
      "grad_norm": 0.8188735246658325,
      "learning_rate": 8.551730796236485e-06,
      "loss": 0.1148,
      "step": 94550
    },
    {
      "epoch": 2.48868778280543,
      "grad_norm": 0.8392993807792664,
      "learning_rate": 8.529788653279034e-06,
      "loss": 0.1113,
      "step": 94600
    },
    {
      "epoch": 2.4900031568978216,
      "grad_norm": 0.8009821176528931,
      "learning_rate": 8.507846510321585e-06,
      "loss": 0.1145,
      "step": 94650
    },
    {
      "epoch": 2.4913185309902137,
      "grad_norm": 0.5673845410346985,
      "learning_rate": 8.485904367364136e-06,
      "loss": 0.1127,
      "step": 94700
    },
    {
      "epoch": 2.4926339050826054,
      "grad_norm": 0.6611909866333008,
      "learning_rate": 8.463962224406685e-06,
      "loss": 0.1129,
      "step": 94750
    },
    {
      "epoch": 2.4939492791749975,
      "grad_norm": 0.741844117641449,
      "learning_rate": 8.442020081449236e-06,
      "loss": 0.1119,
      "step": 94800
    },
    {
      "epoch": 2.495264653267389,
      "grad_norm": 0.5488494038581848,
      "learning_rate": 8.420077938491785e-06,
      "loss": 0.1137,
      "step": 94850
    },
    {
      "epoch": 2.496580027359781,
      "grad_norm": 0.9103758335113525,
      "learning_rate": 8.398135795534336e-06,
      "loss": 0.1111,
      "step": 94900
    },
    {
      "epoch": 2.497895401452173,
      "grad_norm": 0.7724025249481201,
      "learning_rate": 8.376193652576885e-06,
      "loss": 0.1115,
      "step": 94950
    },
    {
      "epoch": 2.4992107755445647,
      "grad_norm": 0.6397333741188049,
      "learning_rate": 8.354251509619436e-06,
      "loss": 0.1082,
      "step": 95000
    },
    {
      "epoch": 2.500526149636957,
      "grad_norm": 0.549047589302063,
      "learning_rate": 8.332309366661987e-06,
      "loss": 0.1122,
      "step": 95050
    },
    {
      "epoch": 2.5018415237293485,
      "grad_norm": 0.6118707060813904,
      "learning_rate": 8.310367223704536e-06,
      "loss": 0.1122,
      "step": 95100
    },
    {
      "epoch": 2.5031568978217407,
      "grad_norm": 0.786320686340332,
      "learning_rate": 8.288425080747087e-06,
      "loss": 0.1107,
      "step": 95150
    },
    {
      "epoch": 2.5044722719141324,
      "grad_norm": 0.6568306684494019,
      "learning_rate": 8.266482937789636e-06,
      "loss": 0.1137,
      "step": 95200
    },
    {
      "epoch": 2.5057876460065245,
      "grad_norm": 0.7275413274765015,
      "learning_rate": 8.244540794832187e-06,
      "loss": 0.112,
      "step": 95250
    },
    {
      "epoch": 2.507103020098916,
      "grad_norm": 0.938764214515686,
      "learning_rate": 8.222598651874736e-06,
      "loss": 0.1143,
      "step": 95300
    },
    {
      "epoch": 2.508418394191308,
      "grad_norm": 0.6002436280250549,
      "learning_rate": 8.200656508917287e-06,
      "loss": 0.1106,
      "step": 95350
    },
    {
      "epoch": 2.5097337682837,
      "grad_norm": 0.7687743306159973,
      "learning_rate": 8.178714365959838e-06,
      "loss": 0.1095,
      "step": 95400
    },
    {
      "epoch": 2.5110491423760917,
      "grad_norm": 0.6368406414985657,
      "learning_rate": 8.156772223002387e-06,
      "loss": 0.1111,
      "step": 95450
    },
    {
      "epoch": 2.512364516468484,
      "grad_norm": 0.5831901431083679,
      "learning_rate": 8.134830080044938e-06,
      "loss": 0.1122,
      "step": 95500
    },
    {
      "epoch": 2.5136798905608755,
      "grad_norm": 0.7173163294792175,
      "learning_rate": 8.112887937087487e-06,
      "loss": 0.1152,
      "step": 95550
    },
    {
      "epoch": 2.514995264653267,
      "grad_norm": 0.6297255158424377,
      "learning_rate": 8.090945794130038e-06,
      "loss": 0.1106,
      "step": 95600
    },
    {
      "epoch": 2.5163106387456593,
      "grad_norm": 0.6390992403030396,
      "learning_rate": 8.069003651172589e-06,
      "loss": 0.1087,
      "step": 95650
    },
    {
      "epoch": 2.517626012838051,
      "grad_norm": 0.7930635213851929,
      "learning_rate": 8.047061508215138e-06,
      "loss": 0.1113,
      "step": 95700
    },
    {
      "epoch": 2.518941386930443,
      "grad_norm": 0.7025007009506226,
      "learning_rate": 8.025119365257689e-06,
      "loss": 0.1136,
      "step": 95750
    },
    {
      "epoch": 2.520256761022835,
      "grad_norm": 0.7427119016647339,
      "learning_rate": 8.003177222300238e-06,
      "loss": 0.1133,
      "step": 95800
    },
    {
      "epoch": 2.521572135115227,
      "grad_norm": 0.6957640051841736,
      "learning_rate": 7.981235079342789e-06,
      "loss": 0.1119,
      "step": 95850
    },
    {
      "epoch": 2.5228875092076186,
      "grad_norm": 0.7898126244544983,
      "learning_rate": 7.959292936385338e-06,
      "loss": 0.1097,
      "step": 95900
    },
    {
      "epoch": 2.5242028833000107,
      "grad_norm": 0.5311514139175415,
      "learning_rate": 7.93735079342789e-06,
      "loss": 0.1099,
      "step": 95950
    },
    {
      "epoch": 2.5255182573924024,
      "grad_norm": 0.6691520810127258,
      "learning_rate": 7.91540865047044e-06,
      "loss": 0.1122,
      "step": 96000
    },
    {
      "epoch": 2.526833631484794,
      "grad_norm": 0.8203704953193665,
      "learning_rate": 7.89346650751299e-06,
      "loss": 0.1107,
      "step": 96050
    },
    {
      "epoch": 2.5281490055771862,
      "grad_norm": 0.790056586265564,
      "learning_rate": 7.871524364555542e-06,
      "loss": 0.1137,
      "step": 96100
    },
    {
      "epoch": 2.529464379669578,
      "grad_norm": 0.5815684795379639,
      "learning_rate": 7.84958222159809e-06,
      "loss": 0.1135,
      "step": 96150
    },
    {
      "epoch": 2.53077975376197,
      "grad_norm": 0.5847342610359192,
      "learning_rate": 7.827640078640642e-06,
      "loss": 0.1093,
      "step": 96200
    },
    {
      "epoch": 2.5320951278543617,
      "grad_norm": 0.8632861375808716,
      "learning_rate": 7.80569793568319e-06,
      "loss": 0.112,
      "step": 96250
    },
    {
      "epoch": 2.5334105019467534,
      "grad_norm": 0.7443811893463135,
      "learning_rate": 7.783755792725742e-06,
      "loss": 0.1114,
      "step": 96300
    },
    {
      "epoch": 2.5347258760391456,
      "grad_norm": 0.7654384970664978,
      "learning_rate": 7.761813649768291e-06,
      "loss": 0.1146,
      "step": 96350
    },
    {
      "epoch": 2.5360412501315373,
      "grad_norm": 0.6308911442756653,
      "learning_rate": 7.739871506810842e-06,
      "loss": 0.1099,
      "step": 96400
    },
    {
      "epoch": 2.5373566242239294,
      "grad_norm": 0.5953712463378906,
      "learning_rate": 7.717929363853393e-06,
      "loss": 0.1106,
      "step": 96450
    },
    {
      "epoch": 2.538671998316321,
      "grad_norm": 0.8014000058174133,
      "learning_rate": 7.695987220895942e-06,
      "loss": 0.1126,
      "step": 96500
    },
    {
      "epoch": 2.539987372408713,
      "grad_norm": 0.7028965950012207,
      "learning_rate": 7.674045077938493e-06,
      "loss": 0.1109,
      "step": 96550
    },
    {
      "epoch": 2.541302746501105,
      "grad_norm": 0.6816357374191284,
      "learning_rate": 7.652102934981042e-06,
      "loss": 0.1106,
      "step": 96600
    },
    {
      "epoch": 2.542618120593497,
      "grad_norm": 0.9601250290870667,
      "learning_rate": 7.630160792023593e-06,
      "loss": 0.1113,
      "step": 96650
    },
    {
      "epoch": 2.5439334946858887,
      "grad_norm": 0.5970848202705383,
      "learning_rate": 7.608218649066143e-06,
      "loss": 0.11,
      "step": 96700
    },
    {
      "epoch": 2.5452488687782804,
      "grad_norm": 0.6316353678703308,
      "learning_rate": 7.586276506108693e-06,
      "loss": 0.113,
      "step": 96750
    },
    {
      "epoch": 2.5465642428706725,
      "grad_norm": 0.7975719571113586,
      "learning_rate": 7.564334363151243e-06,
      "loss": 0.1074,
      "step": 96800
    },
    {
      "epoch": 2.547879616963064,
      "grad_norm": 0.6086372137069702,
      "learning_rate": 7.542392220193794e-06,
      "loss": 0.1124,
      "step": 96850
    },
    {
      "epoch": 2.5491949910554563,
      "grad_norm": 0.7978201508522034,
      "learning_rate": 7.520450077236344e-06,
      "loss": 0.1119,
      "step": 96900
    },
    {
      "epoch": 2.550510365147848,
      "grad_norm": 0.7270067930221558,
      "learning_rate": 7.498507934278894e-06,
      "loss": 0.1088,
      "step": 96950
    },
    {
      "epoch": 2.5518257392402397,
      "grad_norm": 1.0002390146255493,
      "learning_rate": 7.476565791321444e-06,
      "loss": 0.1112,
      "step": 97000
    },
    {
      "epoch": 2.553141113332632,
      "grad_norm": 0.6559646725654602,
      "learning_rate": 7.454623648363994e-06,
      "loss": 0.113,
      "step": 97050
    },
    {
      "epoch": 2.5544564874250235,
      "grad_norm": 0.5641931891441345,
      "learning_rate": 7.432681505406544e-06,
      "loss": 0.1097,
      "step": 97100
    },
    {
      "epoch": 2.5557718615174156,
      "grad_norm": 0.666749119758606,
      "learning_rate": 7.410739362449095e-06,
      "loss": 0.1091,
      "step": 97150
    },
    {
      "epoch": 2.5570872356098073,
      "grad_norm": 0.6070526242256165,
      "learning_rate": 7.388797219491645e-06,
      "loss": 0.1114,
      "step": 97200
    },
    {
      "epoch": 2.5584026097021995,
      "grad_norm": 0.6362326145172119,
      "learning_rate": 7.366855076534195e-06,
      "loss": 0.1123,
      "step": 97250
    },
    {
      "epoch": 2.559717983794591,
      "grad_norm": 0.6282683610916138,
      "learning_rate": 7.344912933576745e-06,
      "loss": 0.1104,
      "step": 97300
    },
    {
      "epoch": 2.5610333578869833,
      "grad_norm": 0.717555820941925,
      "learning_rate": 7.322970790619295e-06,
      "loss": 0.1099,
      "step": 97350
    },
    {
      "epoch": 2.562348731979375,
      "grad_norm": 0.7038170099258423,
      "learning_rate": 7.301028647661845e-06,
      "loss": 0.1077,
      "step": 97400
    },
    {
      "epoch": 2.5636641060717666,
      "grad_norm": 0.735291063785553,
      "learning_rate": 7.279086504704395e-06,
      "loss": 0.1135,
      "step": 97450
    },
    {
      "epoch": 2.5649794801641588,
      "grad_norm": 0.5840979218482971,
      "learning_rate": 7.257144361746946e-06,
      "loss": 0.1118,
      "step": 97500
    },
    {
      "epoch": 2.5662948542565505,
      "grad_norm": 0.7390400171279907,
      "learning_rate": 7.2352022187894965e-06,
      "loss": 0.1111,
      "step": 97550
    },
    {
      "epoch": 2.5676102283489426,
      "grad_norm": 0.7697585225105286,
      "learning_rate": 7.213260075832047e-06,
      "loss": 0.116,
      "step": 97600
    },
    {
      "epoch": 2.5689256024413343,
      "grad_norm": 0.5781168937683105,
      "learning_rate": 7.191317932874597e-06,
      "loss": 0.112,
      "step": 97650
    },
    {
      "epoch": 2.570240976533726,
      "grad_norm": 0.6815438866615295,
      "learning_rate": 7.1693757899171474e-06,
      "loss": 0.1086,
      "step": 97700
    },
    {
      "epoch": 2.571556350626118,
      "grad_norm": 0.7668188214302063,
      "learning_rate": 7.1474336469596975e-06,
      "loss": 0.1126,
      "step": 97750
    },
    {
      "epoch": 2.57287172471851,
      "grad_norm": 0.7673197388648987,
      "learning_rate": 7.1254915040022475e-06,
      "loss": 0.1129,
      "step": 97800
    },
    {
      "epoch": 2.574187098810902,
      "grad_norm": 1.14833664894104,
      "learning_rate": 7.1035493610447975e-06,
      "loss": 0.1123,
      "step": 97850
    },
    {
      "epoch": 2.5755024729032936,
      "grad_norm": 0.7053174376487732,
      "learning_rate": 7.081607218087348e-06,
      "loss": 0.1125,
      "step": 97900
    },
    {
      "epoch": 2.5768178469956857,
      "grad_norm": 0.689319908618927,
      "learning_rate": 7.059665075129898e-06,
      "loss": 0.1113,
      "step": 97950
    },
    {
      "epoch": 2.5781332210880774,
      "grad_norm": 0.775290310382843,
      "learning_rate": 7.0377229321724484e-06,
      "loss": 0.1093,
      "step": 98000
    },
    {
      "epoch": 2.5794485951804695,
      "grad_norm": 0.7206493020057678,
      "learning_rate": 7.0157807892149985e-06,
      "loss": 0.1106,
      "step": 98050
    },
    {
      "epoch": 2.5807639692728612,
      "grad_norm": 0.7295710444450378,
      "learning_rate": 6.9938386462575485e-06,
      "loss": 0.1117,
      "step": 98100
    },
    {
      "epoch": 2.582079343365253,
      "grad_norm": 0.556390643119812,
      "learning_rate": 6.9718965033000985e-06,
      "loss": 0.1132,
      "step": 98150
    },
    {
      "epoch": 2.583394717457645,
      "grad_norm": 0.8003914952278137,
      "learning_rate": 6.949954360342649e-06,
      "loss": 0.1102,
      "step": 98200
    },
    {
      "epoch": 2.5847100915500367,
      "grad_norm": 0.6826565265655518,
      "learning_rate": 6.928012217385199e-06,
      "loss": 0.1117,
      "step": 98250
    },
    {
      "epoch": 2.586025465642429,
      "grad_norm": 0.6816352009773254,
      "learning_rate": 6.9060700744277494e-06,
      "loss": 0.1087,
      "step": 98300
    },
    {
      "epoch": 2.5873408397348205,
      "grad_norm": 0.7630543112754822,
      "learning_rate": 6.8841279314702994e-06,
      "loss": 0.1099,
      "step": 98350
    },
    {
      "epoch": 2.5886562138272122,
      "grad_norm": 0.7229303121566772,
      "learning_rate": 6.8621857885128495e-06,
      "loss": 0.111,
      "step": 98400
    },
    {
      "epoch": 2.5899715879196044,
      "grad_norm": 0.7344418168067932,
      "learning_rate": 6.8402436455553995e-06,
      "loss": 0.1093,
      "step": 98450
    },
    {
      "epoch": 2.5912869620119965,
      "grad_norm": 0.6711678504943848,
      "learning_rate": 6.8183015025979495e-06,
      "loss": 0.1122,
      "step": 98500
    },
    {
      "epoch": 2.592602336104388,
      "grad_norm": 0.5147596001625061,
      "learning_rate": 6.7963593596405e-06,
      "loss": 0.1114,
      "step": 98550
    },
    {
      "epoch": 2.59391771019678,
      "grad_norm": 0.688387393951416,
      "learning_rate": 6.77441721668305e-06,
      "loss": 0.1134,
      "step": 98600
    },
    {
      "epoch": 2.595233084289172,
      "grad_norm": 0.6345827579498291,
      "learning_rate": 6.7524750737256004e-06,
      "loss": 0.1128,
      "step": 98650
    },
    {
      "epoch": 2.5965484583815637,
      "grad_norm": 0.8717997670173645,
      "learning_rate": 6.7305329307681505e-06,
      "loss": 0.11,
      "step": 98700
    },
    {
      "epoch": 2.597863832473956,
      "grad_norm": 0.6498268842697144,
      "learning_rate": 6.7085907878107005e-06,
      "loss": 0.1104,
      "step": 98750
    },
    {
      "epoch": 2.5991792065663475,
      "grad_norm": 0.5693814754486084,
      "learning_rate": 6.6866486448532505e-06,
      "loss": 0.1126,
      "step": 98800
    },
    {
      "epoch": 2.600494580658739,
      "grad_norm": 0.7039961814880371,
      "learning_rate": 6.664706501895801e-06,
      "loss": 0.1088,
      "step": 98850
    },
    {
      "epoch": 2.6018099547511313,
      "grad_norm": 0.6268077492713928,
      "learning_rate": 6.642764358938351e-06,
      "loss": 0.1103,
      "step": 98900
    },
    {
      "epoch": 2.603125328843523,
      "grad_norm": 0.4620739221572876,
      "learning_rate": 6.6208222159809014e-06,
      "loss": 0.1107,
      "step": 98950
    },
    {
      "epoch": 2.604440702935915,
      "grad_norm": 0.5650689005851746,
      "learning_rate": 6.5988800730234515e-06,
      "loss": 0.1109,
      "step": 99000
    },
    {
      "epoch": 2.605756077028307,
      "grad_norm": 0.8375065326690674,
      "learning_rate": 6.5769379300660015e-06,
      "loss": 0.1125,
      "step": 99050
    },
    {
      "epoch": 2.6070714511206985,
      "grad_norm": 0.7736782431602478,
      "learning_rate": 6.5549957871085515e-06,
      "loss": 0.1102,
      "step": 99100
    },
    {
      "epoch": 2.6083868252130906,
      "grad_norm": 0.7641937136650085,
      "learning_rate": 6.533053644151102e-06,
      "loss": 0.1117,
      "step": 99150
    },
    {
      "epoch": 2.6097021993054828,
      "grad_norm": 0.5678678750991821,
      "learning_rate": 6.511111501193653e-06,
      "loss": 0.1108,
      "step": 99200
    },
    {
      "epoch": 2.6110175733978744,
      "grad_norm": 0.6592880487442017,
      "learning_rate": 6.489169358236204e-06,
      "loss": 0.1091,
      "step": 99250
    },
    {
      "epoch": 2.612332947490266,
      "grad_norm": 0.6659403443336487,
      "learning_rate": 6.467227215278754e-06,
      "loss": 0.1109,
      "step": 99300
    },
    {
      "epoch": 2.6136483215826583,
      "grad_norm": 0.6557525992393494,
      "learning_rate": 6.445285072321304e-06,
      "loss": 0.1126,
      "step": 99350
    },
    {
      "epoch": 2.61496369567505,
      "grad_norm": 0.6501052975654602,
      "learning_rate": 6.423342929363854e-06,
      "loss": 0.1118,
      "step": 99400
    },
    {
      "epoch": 2.616279069767442,
      "grad_norm": 0.8321661949157715,
      "learning_rate": 6.401400786406404e-06,
      "loss": 0.1086,
      "step": 99450
    },
    {
      "epoch": 2.6175944438598338,
      "grad_norm": 0.9114295840263367,
      "learning_rate": 6.379458643448954e-06,
      "loss": 0.1094,
      "step": 99500
    },
    {
      "epoch": 2.6189098179522254,
      "grad_norm": 0.762673020362854,
      "learning_rate": 6.357516500491504e-06,
      "loss": 0.1118,
      "step": 99550
    },
    {
      "epoch": 2.6202251920446176,
      "grad_norm": 0.7468817234039307,
      "learning_rate": 6.335574357534055e-06,
      "loss": 0.1124,
      "step": 99600
    },
    {
      "epoch": 2.6215405661370093,
      "grad_norm": 0.8421322703361511,
      "learning_rate": 6.313632214576605e-06,
      "loss": 0.1091,
      "step": 99650
    },
    {
      "epoch": 2.6228559402294014,
      "grad_norm": 0.6227521896362305,
      "learning_rate": 6.291690071619155e-06,
      "loss": 0.1107,
      "step": 99700
    },
    {
      "epoch": 2.624171314321793,
      "grad_norm": 0.7117875814437866,
      "learning_rate": 6.269747928661705e-06,
      "loss": 0.1112,
      "step": 99750
    },
    {
      "epoch": 2.6254866884141848,
      "grad_norm": 0.6905636787414551,
      "learning_rate": 6.247805785704255e-06,
      "loss": 0.1114,
      "step": 99800
    },
    {
      "epoch": 2.626802062506577,
      "grad_norm": 0.758354663848877,
      "learning_rate": 6.225863642746805e-06,
      "loss": 0.1115,
      "step": 99850
    },
    {
      "epoch": 2.628117436598969,
      "grad_norm": 0.7553459405899048,
      "learning_rate": 6.203921499789356e-06,
      "loss": 0.1114,
      "step": 99900
    },
    {
      "epoch": 2.6294328106913607,
      "grad_norm": 0.8663942217826843,
      "learning_rate": 6.181979356831906e-06,
      "loss": 0.1122,
      "step": 99950
    },
    {
      "epoch": 2.6307481847837524,
      "grad_norm": 0.6112546324729919,
      "learning_rate": 6.160037213874456e-06,
      "loss": 0.1134,
      "step": 100000
    },
    {
      "epoch": 2.6320635588761445,
      "grad_norm": 0.7440845370292664,
      "learning_rate": 6.138095070917006e-06,
      "loss": 0.1106,
      "step": 100050
    },
    {
      "epoch": 2.633378932968536,
      "grad_norm": 0.684803307056427,
      "learning_rate": 6.116152927959556e-06,
      "loss": 0.1109,
      "step": 100100
    },
    {
      "epoch": 2.6346943070609283,
      "grad_norm": 0.735090970993042,
      "learning_rate": 6.094210785002106e-06,
      "loss": 0.1111,
      "step": 100150
    },
    {
      "epoch": 2.63600968115332,
      "grad_norm": 0.8696717023849487,
      "learning_rate": 6.072268642044657e-06,
      "loss": 0.1132,
      "step": 100200
    },
    {
      "epoch": 2.6373250552457117,
      "grad_norm": 0.6907739043235779,
      "learning_rate": 6.050326499087207e-06,
      "loss": 0.1111,
      "step": 100250
    },
    {
      "epoch": 2.638640429338104,
      "grad_norm": 0.6908179521560669,
      "learning_rate": 6.028384356129757e-06,
      "loss": 0.1107,
      "step": 100300
    },
    {
      "epoch": 2.6399558034304955,
      "grad_norm": 0.715529203414917,
      "learning_rate": 6.006442213172307e-06,
      "loss": 0.1106,
      "step": 100350
    },
    {
      "epoch": 2.6412711775228876,
      "grad_norm": 0.6238545179367065,
      "learning_rate": 5.984500070214858e-06,
      "loss": 0.1076,
      "step": 100400
    },
    {
      "epoch": 2.6425865516152793,
      "grad_norm": 0.6762962341308594,
      "learning_rate": 5.962557927257408e-06,
      "loss": 0.1118,
      "step": 100450
    },
    {
      "epoch": 2.643901925707671,
      "grad_norm": 0.8029648661613464,
      "learning_rate": 5.940615784299958e-06,
      "loss": 0.1125,
      "step": 100500
    },
    {
      "epoch": 2.645217299800063,
      "grad_norm": 0.9178749918937683,
      "learning_rate": 5.918673641342509e-06,
      "loss": 0.1115,
      "step": 100550
    },
    {
      "epoch": 2.6465326738924553,
      "grad_norm": 0.8334824442863464,
      "learning_rate": 5.896731498385059e-06,
      "loss": 0.1144,
      "step": 100600
    },
    {
      "epoch": 2.647848047984847,
      "grad_norm": 0.5517487525939941,
      "learning_rate": 5.874789355427609e-06,
      "loss": 0.1102,
      "step": 100650
    },
    {
      "epoch": 2.6491634220772386,
      "grad_norm": 0.6251438856124878,
      "learning_rate": 5.852847212470159e-06,
      "loss": 0.1115,
      "step": 100700
    },
    {
      "epoch": 2.650478796169631,
      "grad_norm": 0.6218643188476562,
      "learning_rate": 5.830905069512709e-06,
      "loss": 0.1123,
      "step": 100750
    },
    {
      "epoch": 2.6517941702620225,
      "grad_norm": 0.6590116620063782,
      "learning_rate": 5.808962926555259e-06,
      "loss": 0.1102,
      "step": 100800
    },
    {
      "epoch": 2.6531095443544146,
      "grad_norm": 0.4837425649166107,
      "learning_rate": 5.787020783597809e-06,
      "loss": 0.1117,
      "step": 100850
    },
    {
      "epoch": 2.6544249184468063,
      "grad_norm": 0.6025308966636658,
      "learning_rate": 5.76507864064036e-06,
      "loss": 0.1075,
      "step": 100900
    },
    {
      "epoch": 2.655740292539198,
      "grad_norm": 0.5707902312278748,
      "learning_rate": 5.74313649768291e-06,
      "loss": 0.1111,
      "step": 100950
    },
    {
      "epoch": 2.65705566663159,
      "grad_norm": 0.709065854549408,
      "learning_rate": 5.72119435472546e-06,
      "loss": 0.1294,
      "step": 101000
    },
    {
      "epoch": 2.658371040723982,
      "grad_norm": 0.7930921316146851,
      "learning_rate": 5.69925221176801e-06,
      "loss": 0.11,
      "step": 101050
    },
    {
      "epoch": 2.659686414816374,
      "grad_norm": 0.6650475859642029,
      "learning_rate": 5.67731006881056e-06,
      "loss": 0.1097,
      "step": 101100
    },
    {
      "epoch": 2.6610017889087656,
      "grad_norm": 0.4904206097126007,
      "learning_rate": 5.65536792585311e-06,
      "loss": 0.1117,
      "step": 101150
    },
    {
      "epoch": 2.6623171630011573,
      "grad_norm": 0.6122139096260071,
      "learning_rate": 5.633425782895661e-06,
      "loss": 0.1094,
      "step": 101200
    },
    {
      "epoch": 2.6636325370935494,
      "grad_norm": 0.6834551095962524,
      "learning_rate": 5.611483639938212e-06,
      "loss": 0.1116,
      "step": 101250
    },
    {
      "epoch": 2.6649479111859415,
      "grad_norm": 0.7231273055076599,
      "learning_rate": 5.589541496980762e-06,
      "loss": 0.1088,
      "step": 101300
    },
    {
      "epoch": 2.6662632852783332,
      "grad_norm": 0.5100117325782776,
      "learning_rate": 5.567599354023312e-06,
      "loss": 0.1081,
      "step": 101350
    },
    {
      "epoch": 2.667578659370725,
      "grad_norm": 0.5537230372428894,
      "learning_rate": 5.545657211065862e-06,
      "loss": 0.1101,
      "step": 101400
    },
    {
      "epoch": 2.668894033463117,
      "grad_norm": 0.5873758792877197,
      "learning_rate": 5.523715068108412e-06,
      "loss": 0.1133,
      "step": 101450
    },
    {
      "epoch": 2.6702094075555087,
      "grad_norm": 0.6693131327629089,
      "learning_rate": 5.501772925150962e-06,
      "loss": 0.1134,
      "step": 101500
    },
    {
      "epoch": 2.671524781647901,
      "grad_norm": 0.8130019307136536,
      "learning_rate": 5.479830782193513e-06,
      "loss": 0.1092,
      "step": 101550
    },
    {
      "epoch": 2.6728401557402925,
      "grad_norm": 0.6448937058448792,
      "learning_rate": 5.457888639236063e-06,
      "loss": 0.1099,
      "step": 101600
    },
    {
      "epoch": 2.6741555298326842,
      "grad_norm": 0.7511752843856812,
      "learning_rate": 5.435946496278613e-06,
      "loss": 0.1106,
      "step": 101650
    },
    {
      "epoch": 2.6754709039250764,
      "grad_norm": 0.5819903612136841,
      "learning_rate": 5.414004353321163e-06,
      "loss": 0.1093,
      "step": 101700
    },
    {
      "epoch": 2.676786278017468,
      "grad_norm": 0.5380228161811829,
      "learning_rate": 5.392062210363713e-06,
      "loss": 0.1109,
      "step": 101750
    },
    {
      "epoch": 2.67810165210986,
      "grad_norm": 0.9213723540306091,
      "learning_rate": 5.370120067406263e-06,
      "loss": 0.1112,
      "step": 101800
    },
    {
      "epoch": 2.679417026202252,
      "grad_norm": 0.6271557807922363,
      "learning_rate": 5.348177924448813e-06,
      "loss": 0.1109,
      "step": 101850
    },
    {
      "epoch": 2.6807324002946435,
      "grad_norm": 0.8448628187179565,
      "learning_rate": 5.326235781491364e-06,
      "loss": 0.1083,
      "step": 101900
    },
    {
      "epoch": 2.6820477743870357,
      "grad_norm": 0.9133853912353516,
      "learning_rate": 5.304293638533914e-06,
      "loss": 0.1095,
      "step": 101950
    },
    {
      "epoch": 2.683363148479428,
      "grad_norm": 0.6975337266921997,
      "learning_rate": 5.282351495576465e-06,
      "loss": 0.1138,
      "step": 102000
    },
    {
      "epoch": 2.6846785225718195,
      "grad_norm": 0.6173176169395447,
      "learning_rate": 5.260409352619015e-06,
      "loss": 0.1099,
      "step": 102050
    },
    {
      "epoch": 2.685993896664211,
      "grad_norm": 0.5211601853370667,
      "learning_rate": 5.238467209661565e-06,
      "loss": 0.1084,
      "step": 102100
    },
    {
      "epoch": 2.6873092707566033,
      "grad_norm": 0.674098789691925,
      "learning_rate": 5.216525066704115e-06,
      "loss": 0.1089,
      "step": 102150
    },
    {
      "epoch": 2.688624644848995,
      "grad_norm": 0.7832716703414917,
      "learning_rate": 5.194582923746665e-06,
      "loss": 0.1098,
      "step": 102200
    },
    {
      "epoch": 2.689940018941387,
      "grad_norm": 0.6694265007972717,
      "learning_rate": 5.172640780789216e-06,
      "loss": 0.1101,
      "step": 102250
    },
    {
      "epoch": 2.691255393033779,
      "grad_norm": 0.680548369884491,
      "learning_rate": 5.150698637831766e-06,
      "loss": 0.1113,
      "step": 102300
    },
    {
      "epoch": 2.6925707671261705,
      "grad_norm": 0.6666651368141174,
      "learning_rate": 5.128756494874316e-06,
      "loss": 0.1082,
      "step": 102350
    },
    {
      "epoch": 2.6938861412185626,
      "grad_norm": 0.5801301598548889,
      "learning_rate": 5.106814351916866e-06,
      "loss": 0.1107,
      "step": 102400
    },
    {
      "epoch": 2.6952015153109543,
      "grad_norm": 0.5565890669822693,
      "learning_rate": 5.084872208959416e-06,
      "loss": 0.1143,
      "step": 102450
    },
    {
      "epoch": 2.6965168894033464,
      "grad_norm": 0.6543135046958923,
      "learning_rate": 5.062930066001966e-06,
      "loss": 0.111,
      "step": 102500
    },
    {
      "epoch": 2.697832263495738,
      "grad_norm": 0.7931312918663025,
      "learning_rate": 5.040987923044517e-06,
      "loss": 0.1105,
      "step": 102550
    },
    {
      "epoch": 2.69914763758813,
      "grad_norm": 0.6489582061767578,
      "learning_rate": 5.019045780087067e-06,
      "loss": 0.1104,
      "step": 102600
    },
    {
      "epoch": 2.700463011680522,
      "grad_norm": 0.6869903802871704,
      "learning_rate": 4.997103637129617e-06,
      "loss": 0.1071,
      "step": 102650
    },
    {
      "epoch": 2.701778385772914,
      "grad_norm": 0.6872437596321106,
      "learning_rate": 4.975161494172167e-06,
      "loss": 0.1102,
      "step": 102700
    },
    {
      "epoch": 2.7030937598653058,
      "grad_norm": 0.7402700185775757,
      "learning_rate": 4.953219351214717e-06,
      "loss": 0.1123,
      "step": 102750
    },
    {
      "epoch": 2.7044091339576974,
      "grad_norm": 0.5895322561264038,
      "learning_rate": 4.931277208257268e-06,
      "loss": 0.1081,
      "step": 102800
    },
    {
      "epoch": 2.7057245080500896,
      "grad_norm": 0.6456773281097412,
      "learning_rate": 4.909335065299818e-06,
      "loss": 0.1118,
      "step": 102850
    },
    {
      "epoch": 2.7070398821424813,
      "grad_norm": 0.6109488606452942,
      "learning_rate": 4.887392922342368e-06,
      "loss": 0.1103,
      "step": 102900
    },
    {
      "epoch": 2.7083552562348734,
      "grad_norm": 0.5692958235740662,
      "learning_rate": 4.8654507793849186e-06,
      "loss": 0.109,
      "step": 102950
    },
    {
      "epoch": 2.709670630327265,
      "grad_norm": 0.800813615322113,
      "learning_rate": 4.843508636427469e-06,
      "loss": 0.1089,
      "step": 103000
    },
    {
      "epoch": 2.7109860044196568,
      "grad_norm": 0.6385544538497925,
      "learning_rate": 4.821566493470019e-06,
      "loss": 0.1092,
      "step": 103050
    },
    {
      "epoch": 2.712301378512049,
      "grad_norm": 0.737132728099823,
      "learning_rate": 4.799624350512569e-06,
      "loss": 0.1067,
      "step": 103100
    },
    {
      "epoch": 2.7136167526044406,
      "grad_norm": 0.6767241358757019,
      "learning_rate": 4.777682207555119e-06,
      "loss": 0.1119,
      "step": 103150
    },
    {
      "epoch": 2.7149321266968327,
      "grad_norm": 0.5393707156181335,
      "learning_rate": 4.755740064597669e-06,
      "loss": 0.1082,
      "step": 103200
    },
    {
      "epoch": 2.7162475007892244,
      "grad_norm": 0.6661831736564636,
      "learning_rate": 4.7337979216402196e-06,
      "loss": 0.1089,
      "step": 103250
    },
    {
      "epoch": 2.717562874881616,
      "grad_norm": 0.6807050704956055,
      "learning_rate": 4.71185577868277e-06,
      "loss": 0.1075,
      "step": 103300
    },
    {
      "epoch": 2.718878248974008,
      "grad_norm": 0.8383675217628479,
      "learning_rate": 4.68991363572532e-06,
      "loss": 0.1085,
      "step": 103350
    },
    {
      "epoch": 2.7201936230664003,
      "grad_norm": 0.6103496551513672,
      "learning_rate": 4.66797149276787e-06,
      "loss": 0.1092,
      "step": 103400
    },
    {
      "epoch": 2.721508997158792,
      "grad_norm": 0.6898631453514099,
      "learning_rate": 4.64602934981042e-06,
      "loss": 0.1098,
      "step": 103450
    },
    {
      "epoch": 2.7228243712511837,
      "grad_norm": 0.5016293525695801,
      "learning_rate": 4.62408720685297e-06,
      "loss": 0.1066,
      "step": 103500
    },
    {
      "epoch": 2.724139745343576,
      "grad_norm": 0.7673028707504272,
      "learning_rate": 4.6021450638955205e-06,
      "loss": 0.1098,
      "step": 103550
    },
    {
      "epoch": 2.7254551194359675,
      "grad_norm": 0.7184612154960632,
      "learning_rate": 4.580202920938071e-06,
      "loss": 0.1083,
      "step": 103600
    },
    {
      "epoch": 2.7267704935283597,
      "grad_norm": 0.8031755089759827,
      "learning_rate": 4.5582607779806214e-06,
      "loss": 0.1122,
      "step": 103650
    },
    {
      "epoch": 2.7280858676207513,
      "grad_norm": 0.7725159525871277,
      "learning_rate": 4.5363186350231715e-06,
      "loss": 0.1083,
      "step": 103700
    },
    {
      "epoch": 2.729401241713143,
      "grad_norm": 0.6593790650367737,
      "learning_rate": 4.5143764920657215e-06,
      "loss": 0.1115,
      "step": 103750
    },
    {
      "epoch": 2.730716615805535,
      "grad_norm": 0.5272207856178284,
      "learning_rate": 4.4924343491082715e-06,
      "loss": 0.1103,
      "step": 103800
    },
    {
      "epoch": 2.732031989897927,
      "grad_norm": 0.6753913760185242,
      "learning_rate": 4.4704922061508215e-06,
      "loss": 0.1126,
      "step": 103850
    },
    {
      "epoch": 2.733347363990319,
      "grad_norm": 0.745432436466217,
      "learning_rate": 4.448550063193372e-06,
      "loss": 0.1066,
      "step": 103900
    },
    {
      "epoch": 2.7346627380827107,
      "grad_norm": 0.5780144333839417,
      "learning_rate": 4.4266079202359224e-06,
      "loss": 0.1114,
      "step": 103950
    },
    {
      "epoch": 2.7359781121751023,
      "grad_norm": 0.7091657519340515,
      "learning_rate": 4.4046657772784725e-06,
      "loss": 0.1091,
      "step": 104000
    },
    {
      "epoch": 2.7372934862674945,
      "grad_norm": 0.5540810227394104,
      "learning_rate": 4.3827236343210225e-06,
      "loss": 0.1103,
      "step": 104050
    },
    {
      "epoch": 2.7386088603598866,
      "grad_norm": 0.664339005947113,
      "learning_rate": 4.3607814913635725e-06,
      "loss": 0.1099,
      "step": 104100
    },
    {
      "epoch": 2.7399242344522783,
      "grad_norm": 0.6910360455513,
      "learning_rate": 4.3388393484061225e-06,
      "loss": 0.107,
      "step": 104150
    },
    {
      "epoch": 2.74123960854467,
      "grad_norm": 0.8101623058319092,
      "learning_rate": 4.3168972054486725e-06,
      "loss": 0.1111,
      "step": 104200
    },
    {
      "epoch": 2.742554982637062,
      "grad_norm": 0.6354119181632996,
      "learning_rate": 4.294955062491223e-06,
      "loss": 0.1107,
      "step": 104250
    },
    {
      "epoch": 2.743870356729454,
      "grad_norm": 0.6928112506866455,
      "learning_rate": 4.2730129195337734e-06,
      "loss": 0.1077,
      "step": 104300
    },
    {
      "epoch": 2.745185730821846,
      "grad_norm": 0.6415773034095764,
      "learning_rate": 4.2510707765763235e-06,
      "loss": 0.109,
      "step": 104350
    },
    {
      "epoch": 2.7465011049142376,
      "grad_norm": 0.7732570767402649,
      "learning_rate": 4.229128633618874e-06,
      "loss": 0.1091,
      "step": 104400
    },
    {
      "epoch": 2.7478164790066293,
      "grad_norm": 0.6539177298545837,
      "learning_rate": 4.207186490661424e-06,
      "loss": 0.1071,
      "step": 104450
    },
    {
      "epoch": 2.7491318530990214,
      "grad_norm": 0.4488406181335449,
      "learning_rate": 4.185244347703974e-06,
      "loss": 0.1096,
      "step": 104500
    },
    {
      "epoch": 2.750447227191413,
      "grad_norm": 0.5841639041900635,
      "learning_rate": 4.163302204746524e-06,
      "loss": 0.1087,
      "step": 104550
    },
    {
      "epoch": 2.7517626012838052,
      "grad_norm": 0.5775099396705627,
      "learning_rate": 4.141360061789075e-06,
      "loss": 0.1111,
      "step": 104600
    },
    {
      "epoch": 2.753077975376197,
      "grad_norm": 0.6551522612571716,
      "learning_rate": 4.119417918831625e-06,
      "loss": 0.1119,
      "step": 104650
    },
    {
      "epoch": 2.7543933494685886,
      "grad_norm": 0.6305792927742004,
      "learning_rate": 4.097475775874175e-06,
      "loss": 0.1079,
      "step": 104700
    },
    {
      "epoch": 2.7557087235609807,
      "grad_norm": 0.6232518553733826,
      "learning_rate": 4.075533632916725e-06,
      "loss": 0.1109,
      "step": 104750
    },
    {
      "epoch": 2.757024097653373,
      "grad_norm": 0.5076132416725159,
      "learning_rate": 4.053591489959275e-06,
      "loss": 0.1108,
      "step": 104800
    },
    {
      "epoch": 2.7583394717457645,
      "grad_norm": 0.6886308789253235,
      "learning_rate": 4.031649347001825e-06,
      "loss": 0.1105,
      "step": 104850
    },
    {
      "epoch": 2.7596548458381562,
      "grad_norm": 0.6948509216308594,
      "learning_rate": 4.009707204044376e-06,
      "loss": 0.111,
      "step": 104900
    },
    {
      "epoch": 2.7609702199305484,
      "grad_norm": 0.7615038156509399,
      "learning_rate": 3.987765061086926e-06,
      "loss": 0.1073,
      "step": 104950
    },
    {
      "epoch": 2.76228559402294,
      "grad_norm": 0.6274301409721375,
      "learning_rate": 3.965822918129476e-06,
      "loss": 0.1118,
      "step": 105000
    },
    {
      "epoch": 2.763600968115332,
      "grad_norm": 0.5288214087486267,
      "learning_rate": 3.943880775172026e-06,
      "loss": 0.1112,
      "step": 105050
    },
    {
      "epoch": 2.764916342207724,
      "grad_norm": 0.5568817853927612,
      "learning_rate": 3.921938632214576e-06,
      "loss": 0.1105,
      "step": 105100
    },
    {
      "epoch": 2.7662317163001156,
      "grad_norm": 0.5805808901786804,
      "learning_rate": 3.899996489257126e-06,
      "loss": 0.1095,
      "step": 105150
    },
    {
      "epoch": 2.7675470903925077,
      "grad_norm": 0.7205652594566345,
      "learning_rate": 3.878054346299677e-06,
      "loss": 0.1098,
      "step": 105200
    },
    {
      "epoch": 2.7688624644848994,
      "grad_norm": 0.5493394136428833,
      "learning_rate": 3.856112203342227e-06,
      "loss": 0.1097,
      "step": 105250
    },
    {
      "epoch": 2.7701778385772915,
      "grad_norm": 0.6404932737350464,
      "learning_rate": 3.834170060384778e-06,
      "loss": 0.1105,
      "step": 105300
    },
    {
      "epoch": 2.771493212669683,
      "grad_norm": 0.9491873383522034,
      "learning_rate": 3.812227917427328e-06,
      "loss": 0.1115,
      "step": 105350
    },
    {
      "epoch": 2.772808586762075,
      "grad_norm": 0.5939550995826721,
      "learning_rate": 3.790285774469878e-06,
      "loss": 0.1121,
      "step": 105400
    },
    {
      "epoch": 2.774123960854467,
      "grad_norm": 0.6393027305603027,
      "learning_rate": 3.7683436315124282e-06,
      "loss": 0.1084,
      "step": 105450
    },
    {
      "epoch": 2.775439334946859,
      "grad_norm": 0.699668288230896,
      "learning_rate": 3.7464014885549787e-06,
      "loss": 0.1107,
      "step": 105500
    },
    {
      "epoch": 2.776754709039251,
      "grad_norm": 0.5609602928161621,
      "learning_rate": 3.7244593455975287e-06,
      "loss": 0.1093,
      "step": 105550
    },
    {
      "epoch": 2.7780700831316425,
      "grad_norm": 0.7055922150611877,
      "learning_rate": 3.7025172026400787e-06,
      "loss": 0.1082,
      "step": 105600
    },
    {
      "epoch": 2.7793854572240346,
      "grad_norm": 0.9440172910690308,
      "learning_rate": 3.680575059682629e-06,
      "loss": 0.1087,
      "step": 105650
    },
    {
      "epoch": 2.7807008313164263,
      "grad_norm": 0.6142688393592834,
      "learning_rate": 3.658632916725179e-06,
      "loss": 0.1089,
      "step": 105700
    },
    {
      "epoch": 2.7820162054088184,
      "grad_norm": 0.5981488227844238,
      "learning_rate": 3.636690773767729e-06,
      "loss": 0.1103,
      "step": 105750
    },
    {
      "epoch": 2.78333157950121,
      "grad_norm": 0.7060873508453369,
      "learning_rate": 3.6147486308102797e-06,
      "loss": 0.1102,
      "step": 105800
    },
    {
      "epoch": 2.784646953593602,
      "grad_norm": 0.5918682217597961,
      "learning_rate": 3.5928064878528297e-06,
      "loss": 0.1082,
      "step": 105850
    },
    {
      "epoch": 2.785962327685994,
      "grad_norm": 0.7343400120735168,
      "learning_rate": 3.5708643448953797e-06,
      "loss": 0.1097,
      "step": 105900
    },
    {
      "epoch": 2.7872777017783856,
      "grad_norm": 0.49231746792793274,
      "learning_rate": 3.5489222019379297e-06,
      "loss": 0.1085,
      "step": 105950
    },
    {
      "epoch": 2.7885930758707778,
      "grad_norm": 0.6898061633110046,
      "learning_rate": 3.5269800589804806e-06,
      "loss": 0.1086,
      "step": 106000
    },
    {
      "epoch": 2.7899084499631694,
      "grad_norm": 0.6427589058876038,
      "learning_rate": 3.505037916023031e-06,
      "loss": 0.1101,
      "step": 106050
    },
    {
      "epoch": 2.791223824055561,
      "grad_norm": 0.49548959732055664,
      "learning_rate": 3.483095773065581e-06,
      "loss": 0.106,
      "step": 106100
    },
    {
      "epoch": 2.7925391981479533,
      "grad_norm": 0.6752696633338928,
      "learning_rate": 3.461153630108131e-06,
      "loss": 0.1091,
      "step": 106150
    },
    {
      "epoch": 2.7938545722403454,
      "grad_norm": 0.6802115440368652,
      "learning_rate": 3.4392114871506815e-06,
      "loss": 0.1116,
      "step": 106200
    },
    {
      "epoch": 2.795169946332737,
      "grad_norm": 0.6720156073570251,
      "learning_rate": 3.4172693441932316e-06,
      "loss": 0.1105,
      "step": 106250
    },
    {
      "epoch": 2.7964853204251288,
      "grad_norm": 0.6333153247833252,
      "learning_rate": 3.3953272012357816e-06,
      "loss": 0.1071,
      "step": 106300
    },
    {
      "epoch": 2.797800694517521,
      "grad_norm": 0.7999672293663025,
      "learning_rate": 3.373385058278332e-06,
      "loss": 0.1085,
      "step": 106350
    },
    {
      "epoch": 2.7991160686099126,
      "grad_norm": 0.6955130696296692,
      "learning_rate": 3.351442915320882e-06,
      "loss": 0.1119,
      "step": 106400
    },
    {
      "epoch": 2.8004314427023047,
      "grad_norm": 0.6368541717529297,
      "learning_rate": 3.329500772363432e-06,
      "loss": 0.1126,
      "step": 106450
    },
    {
      "epoch": 2.8017468167946964,
      "grad_norm": 0.5618598461151123,
      "learning_rate": 3.3075586294059825e-06,
      "loss": 0.1091,
      "step": 106500
    },
    {
      "epoch": 2.803062190887088,
      "grad_norm": 0.6908213496208191,
      "learning_rate": 3.2856164864485326e-06,
      "loss": 0.1101,
      "step": 106550
    },
    {
      "epoch": 2.80437756497948,
      "grad_norm": 0.5459287166595459,
      "learning_rate": 3.2636743434910826e-06,
      "loss": 0.1073,
      "step": 106600
    },
    {
      "epoch": 2.805692939071872,
      "grad_norm": 0.6415290832519531,
      "learning_rate": 3.241732200533633e-06,
      "loss": 0.111,
      "step": 106650
    },
    {
      "epoch": 2.807008313164264,
      "grad_norm": 0.7736102342605591,
      "learning_rate": 3.219790057576183e-06,
      "loss": 0.1086,
      "step": 106700
    },
    {
      "epoch": 2.8083236872566557,
      "grad_norm": 0.5779851675033569,
      "learning_rate": 3.197847914618733e-06,
      "loss": 0.1103,
      "step": 106750
    },
    {
      "epoch": 2.8096390613490474,
      "grad_norm": 0.586138904094696,
      "learning_rate": 3.1759057716612835e-06,
      "loss": 0.1094,
      "step": 106800
    },
    {
      "epoch": 2.8109544354414395,
      "grad_norm": 0.6772788166999817,
      "learning_rate": 3.1539636287038344e-06,
      "loss": 0.1132,
      "step": 106850
    },
    {
      "epoch": 2.8122698095338317,
      "grad_norm": 0.6038080453872681,
      "learning_rate": 3.1320214857463844e-06,
      "loss": 0.1092,
      "step": 106900
    },
    {
      "epoch": 2.8135851836262233,
      "grad_norm": 0.6591735482215881,
      "learning_rate": 3.110079342788934e-06,
      "loss": 0.1089,
      "step": 106950
    },
    {
      "epoch": 2.814900557718615,
      "grad_norm": 0.6775897741317749,
      "learning_rate": 3.0881371998314845e-06,
      "loss": 0.1106,
      "step": 107000
    },
    {
      "epoch": 2.816215931811007,
      "grad_norm": 0.6160348653793335,
      "learning_rate": 3.066195056874035e-06,
      "loss": 0.1104,
      "step": 107050
    },
    {
      "epoch": 2.817531305903399,
      "grad_norm": 0.7139286994934082,
      "learning_rate": 3.044252913916585e-06,
      "loss": 0.1081,
      "step": 107100
    },
    {
      "epoch": 2.818846679995791,
      "grad_norm": 0.7648331522941589,
      "learning_rate": 3.022310770959135e-06,
      "loss": 0.1095,
      "step": 107150
    },
    {
      "epoch": 2.8201620540881827,
      "grad_norm": 0.5830832123756409,
      "learning_rate": 3.0003686280016854e-06,
      "loss": 0.1114,
      "step": 107200
    },
    {
      "epoch": 2.8214774281805743,
      "grad_norm": 0.5896202921867371,
      "learning_rate": 2.9784264850442354e-06,
      "loss": 0.1104,
      "step": 107250
    },
    {
      "epoch": 2.8227928022729665,
      "grad_norm": 0.7558555006980896,
      "learning_rate": 2.9564843420867854e-06,
      "loss": 0.1084,
      "step": 107300
    },
    {
      "epoch": 2.824108176365358,
      "grad_norm": 0.6470119953155518,
      "learning_rate": 2.934542199129336e-06,
      "loss": 0.1104,
      "step": 107350
    },
    {
      "epoch": 2.8254235504577503,
      "grad_norm": 0.6199785470962524,
      "learning_rate": 2.912600056171886e-06,
      "loss": 0.1081,
      "step": 107400
    },
    {
      "epoch": 2.826738924550142,
      "grad_norm": 0.5988832116127014,
      "learning_rate": 2.8906579132144364e-06,
      "loss": 0.1084,
      "step": 107450
    },
    {
      "epoch": 2.8280542986425337,
      "grad_norm": 0.5845043063163757,
      "learning_rate": 2.868715770256987e-06,
      "loss": 0.1096,
      "step": 107500
    },
    {
      "epoch": 2.829369672734926,
      "grad_norm": 0.7239261269569397,
      "learning_rate": 2.846773627299537e-06,
      "loss": 0.1112,
      "step": 107550
    },
    {
      "epoch": 2.830685046827318,
      "grad_norm": 0.5725290179252625,
      "learning_rate": 2.824831484342087e-06,
      "loss": 0.1075,
      "step": 107600
    },
    {
      "epoch": 2.8320004209197096,
      "grad_norm": 0.5699501037597656,
      "learning_rate": 2.802889341384637e-06,
      "loss": 0.1077,
      "step": 107650
    },
    {
      "epoch": 2.8333157950121013,
      "grad_norm": 0.6746653914451599,
      "learning_rate": 2.7809471984271873e-06,
      "loss": 0.1098,
      "step": 107700
    },
    {
      "epoch": 2.8346311691044934,
      "grad_norm": 0.6248035430908203,
      "learning_rate": 2.7590050554697374e-06,
      "loss": 0.1085,
      "step": 107750
    },
    {
      "epoch": 2.835946543196885,
      "grad_norm": 0.5468340516090393,
      "learning_rate": 2.7370629125122874e-06,
      "loss": 0.1075,
      "step": 107800
    },
    {
      "epoch": 2.8372619172892772,
      "grad_norm": 0.6099515557289124,
      "learning_rate": 2.7151207695548383e-06,
      "loss": 0.1068,
      "step": 107850
    },
    {
      "epoch": 2.838577291381669,
      "grad_norm": 0.52647465467453,
      "learning_rate": 2.6931786265973883e-06,
      "loss": 0.108,
      "step": 107900
    },
    {
      "epoch": 2.8398926654740606,
      "grad_norm": 0.6591196060180664,
      "learning_rate": 2.6712364836399383e-06,
      "loss": 0.108,
      "step": 107950
    },
    {
      "epoch": 2.8412080395664527,
      "grad_norm": 0.7134721875190735,
      "learning_rate": 2.6492943406824887e-06,
      "loss": 0.1078,
      "step": 108000
    },
    {
      "epoch": 2.8425234136588444,
      "grad_norm": 0.7051162123680115,
      "learning_rate": 2.6273521977250388e-06,
      "loss": 0.1092,
      "step": 108050
    },
    {
      "epoch": 2.8438387877512366,
      "grad_norm": 0.5957369208335876,
      "learning_rate": 2.605410054767589e-06,
      "loss": 0.1078,
      "step": 108100
    },
    {
      "epoch": 2.8451541618436282,
      "grad_norm": 0.7713906764984131,
      "learning_rate": 2.5834679118101392e-06,
      "loss": 0.1082,
      "step": 108150
    },
    {
      "epoch": 2.8464695359360204,
      "grad_norm": 0.6090092658996582,
      "learning_rate": 2.5615257688526893e-06,
      "loss": 0.1098,
      "step": 108200
    },
    {
      "epoch": 2.847784910028412,
      "grad_norm": 1.10546875,
      "learning_rate": 2.5395836258952397e-06,
      "loss": 0.1096,
      "step": 108250
    },
    {
      "epoch": 2.849100284120804,
      "grad_norm": 0.7471914291381836,
      "learning_rate": 2.5176414829377897e-06,
      "loss": 0.1078,
      "step": 108300
    },
    {
      "epoch": 2.850415658213196,
      "grad_norm": 0.7439724802970886,
      "learning_rate": 2.49569933998034e-06,
      "loss": 0.1076,
      "step": 108350
    },
    {
      "epoch": 2.8517310323055876,
      "grad_norm": 0.6659611463546753,
      "learning_rate": 2.47375719702289e-06,
      "loss": 0.1089,
      "step": 108400
    },
    {
      "epoch": 2.8530464063979797,
      "grad_norm": 0.7709032893180847,
      "learning_rate": 2.4518150540654402e-06,
      "loss": 0.1066,
      "step": 108450
    },
    {
      "epoch": 2.8543617804903714,
      "grad_norm": 0.734106719493866,
      "learning_rate": 2.4298729111079907e-06,
      "loss": 0.1107,
      "step": 108500
    },
    {
      "epoch": 2.8556771545827635,
      "grad_norm": 0.7280096411705017,
      "learning_rate": 2.4079307681505407e-06,
      "loss": 0.1119,
      "step": 108550
    },
    {
      "epoch": 2.856992528675155,
      "grad_norm": 0.7447311878204346,
      "learning_rate": 2.3859886251930907e-06,
      "loss": 0.1097,
      "step": 108600
    },
    {
      "epoch": 2.858307902767547,
      "grad_norm": 0.6078783273696899,
      "learning_rate": 2.364046482235641e-06,
      "loss": 0.1084,
      "step": 108650
    },
    {
      "epoch": 2.859623276859939,
      "grad_norm": 0.6287152171134949,
      "learning_rate": 2.3421043392781916e-06,
      "loss": 0.1079,
      "step": 108700
    },
    {
      "epoch": 2.8609386509523307,
      "grad_norm": 0.6787227392196655,
      "learning_rate": 2.3201621963207416e-06,
      "loss": 0.1065,
      "step": 108750
    },
    {
      "epoch": 2.862254025044723,
      "grad_norm": 0.6407027840614319,
      "learning_rate": 2.2982200533632917e-06,
      "loss": 0.1118,
      "step": 108800
    },
    {
      "epoch": 2.8635693991371145,
      "grad_norm": 0.5305331945419312,
      "learning_rate": 2.276277910405842e-06,
      "loss": 0.1065,
      "step": 108850
    },
    {
      "epoch": 2.8648847732295066,
      "grad_norm": 0.532824695110321,
      "learning_rate": 2.254335767448392e-06,
      "loss": 0.1079,
      "step": 108900
    },
    {
      "epoch": 2.8662001473218983,
      "grad_norm": 0.7527357339859009,
      "learning_rate": 2.232393624490942e-06,
      "loss": 0.1065,
      "step": 108950
    },
    {
      "epoch": 2.8675155214142904,
      "grad_norm": 0.7464268803596497,
      "learning_rate": 2.2104514815334926e-06,
      "loss": 0.1127,
      "step": 109000
    },
    {
      "epoch": 2.868830895506682,
      "grad_norm": 0.5076807141304016,
      "learning_rate": 2.188509338576043e-06,
      "loss": 0.1077,
      "step": 109050
    },
    {
      "epoch": 2.870146269599074,
      "grad_norm": 0.7275604605674744,
      "learning_rate": 2.166567195618593e-06,
      "loss": 0.109,
      "step": 109100
    },
    {
      "epoch": 2.871461643691466,
      "grad_norm": 0.5025694370269775,
      "learning_rate": 2.144625052661143e-06,
      "loss": 0.107,
      "step": 109150
    },
    {
      "epoch": 2.8727770177838576,
      "grad_norm": 0.5449432134628296,
      "learning_rate": 2.1226829097036935e-06,
      "loss": 0.1076,
      "step": 109200
    },
    {
      "epoch": 2.8740923918762498,
      "grad_norm": 0.5953382253646851,
      "learning_rate": 2.1007407667462436e-06,
      "loss": 0.1076,
      "step": 109250
    },
    {
      "epoch": 2.8754077659686414,
      "grad_norm": 0.5748148560523987,
      "learning_rate": 2.0787986237887936e-06,
      "loss": 0.1066,
      "step": 109300
    },
    {
      "epoch": 2.876723140061033,
      "grad_norm": 0.5557501912117004,
      "learning_rate": 2.056856480831344e-06,
      "loss": 0.1092,
      "step": 109350
    },
    {
      "epoch": 2.8780385141534253,
      "grad_norm": 0.5396139025688171,
      "learning_rate": 2.034914337873894e-06,
      "loss": 0.1095,
      "step": 109400
    },
    {
      "epoch": 2.879353888245817,
      "grad_norm": 0.5172497034072876,
      "learning_rate": 2.0129721949164445e-06,
      "loss": 0.1119,
      "step": 109450
    },
    {
      "epoch": 2.880669262338209,
      "grad_norm": 0.7920684814453125,
      "learning_rate": 1.9910300519589945e-06,
      "loss": 0.1108,
      "step": 109500
    },
    {
      "epoch": 2.8819846364306008,
      "grad_norm": 0.9126168489456177,
      "learning_rate": 1.969087909001545e-06,
      "loss": 0.1055,
      "step": 109550
    },
    {
      "epoch": 2.883300010522993,
      "grad_norm": 0.5935273766517639,
      "learning_rate": 1.947145766044095e-06,
      "loss": 0.1082,
      "step": 109600
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 0.6138017177581787,
      "learning_rate": 1.925203623086645e-06,
      "loss": 0.1071,
      "step": 109650
    },
    {
      "epoch": 2.8859307587077767,
      "grad_norm": 0.6209075450897217,
      "learning_rate": 1.9032614801291953e-06,
      "loss": 0.1077,
      "step": 109700
    },
    {
      "epoch": 2.8872461328001684,
      "grad_norm": 0.5852552056312561,
      "learning_rate": 1.8813193371717455e-06,
      "loss": 0.1067,
      "step": 109750
    },
    {
      "epoch": 2.88856150689256,
      "grad_norm": 0.5956401228904724,
      "learning_rate": 1.8593771942142957e-06,
      "loss": 0.1113,
      "step": 109800
    },
    {
      "epoch": 2.889876880984952,
      "grad_norm": 0.6870418787002563,
      "learning_rate": 1.8374350512568462e-06,
      "loss": 0.1095,
      "step": 109850
    },
    {
      "epoch": 2.891192255077344,
      "grad_norm": 0.7501283288002014,
      "learning_rate": 1.8154929082993964e-06,
      "loss": 0.1075,
      "step": 109900
    },
    {
      "epoch": 2.892507629169736,
      "grad_norm": 0.6192700266838074,
      "learning_rate": 1.7935507653419464e-06,
      "loss": 0.1082,
      "step": 109950
    },
    {
      "epoch": 2.8938230032621277,
      "grad_norm": 0.6107919812202454,
      "learning_rate": 1.7716086223844967e-06,
      "loss": 0.1108,
      "step": 110000
    },
    {
      "epoch": 2.8951383773545194,
      "grad_norm": 0.5953870415687561,
      "learning_rate": 1.749666479427047e-06,
      "loss": 0.1072,
      "step": 110050
    },
    {
      "epoch": 2.8964537514469115,
      "grad_norm": 0.6979575157165527,
      "learning_rate": 1.727724336469597e-06,
      "loss": 0.1093,
      "step": 110100
    },
    {
      "epoch": 2.897769125539303,
      "grad_norm": 0.6537718772888184,
      "learning_rate": 1.7057821935121472e-06,
      "loss": 0.1087,
      "step": 110150
    },
    {
      "epoch": 2.8990844996316953,
      "grad_norm": 0.8076794743537903,
      "learning_rate": 1.6838400505546972e-06,
      "loss": 0.1096,
      "step": 110200
    },
    {
      "epoch": 2.900399873724087,
      "grad_norm": 0.6919479966163635,
      "learning_rate": 1.6618979075972479e-06,
      "loss": 0.1092,
      "step": 110250
    },
    {
      "epoch": 2.901715247816479,
      "grad_norm": 0.6898746490478516,
      "learning_rate": 1.6399557646397979e-06,
      "loss": 0.1092,
      "step": 110300
    },
    {
      "epoch": 2.903030621908871,
      "grad_norm": 0.5977805852890015,
      "learning_rate": 1.6180136216823481e-06,
      "loss": 0.1074,
      "step": 110350
    },
    {
      "epoch": 2.904345996001263,
      "grad_norm": 0.5708779692649841,
      "learning_rate": 1.5960714787248984e-06,
      "loss": 0.1068,
      "step": 110400
    },
    {
      "epoch": 2.9056613700936547,
      "grad_norm": 0.6257635354995728,
      "learning_rate": 1.5741293357674484e-06,
      "loss": 0.1098,
      "step": 110450
    },
    {
      "epoch": 2.9069767441860463,
      "grad_norm": 0.5435256958007812,
      "learning_rate": 1.5521871928099986e-06,
      "loss": 0.1118,
      "step": 110500
    },
    {
      "epoch": 2.9082921182784385,
      "grad_norm": 0.7269354462623596,
      "learning_rate": 1.5302450498525488e-06,
      "loss": 0.1098,
      "step": 110550
    },
    {
      "epoch": 2.90960749237083,
      "grad_norm": 0.6066432595252991,
      "learning_rate": 1.508302906895099e-06,
      "loss": 0.1074,
      "step": 110600
    },
    {
      "epoch": 2.9109228664632223,
      "grad_norm": 0.550155520439148,
      "learning_rate": 1.4863607639376493e-06,
      "loss": 0.109,
      "step": 110650
    },
    {
      "epoch": 2.912238240555614,
      "grad_norm": 0.6886844038963318,
      "learning_rate": 1.4644186209801993e-06,
      "loss": 0.1107,
      "step": 110700
    },
    {
      "epoch": 2.9135536146480057,
      "grad_norm": 0.6420326828956604,
      "learning_rate": 1.4424764780227498e-06,
      "loss": 0.1086,
      "step": 110750
    },
    {
      "epoch": 2.914868988740398,
      "grad_norm": 0.8015910983085632,
      "learning_rate": 1.4205343350652998e-06,
      "loss": 0.1092,
      "step": 110800
    },
    {
      "epoch": 2.91618436283279,
      "grad_norm": 0.5215149521827698,
      "learning_rate": 1.39859219210785e-06,
      "loss": 0.1079,
      "step": 110850
    },
    {
      "epoch": 2.9174997369251816,
      "grad_norm": 0.6584375500679016,
      "learning_rate": 1.3766500491504003e-06,
      "loss": 0.1115,
      "step": 110900
    },
    {
      "epoch": 2.9188151110175733,
      "grad_norm": 0.531626284122467,
      "learning_rate": 1.3547079061929505e-06,
      "loss": 0.1096,
      "step": 110950
    },
    {
      "epoch": 2.9201304851099654,
      "grad_norm": 0.5514513850212097,
      "learning_rate": 1.3327657632355008e-06,
      "loss": 0.1101,
      "step": 111000
    },
    {
      "epoch": 2.921445859202357,
      "grad_norm": 0.8356837034225464,
      "learning_rate": 1.3108236202780508e-06,
      "loss": 0.113,
      "step": 111050
    },
    {
      "epoch": 2.9227612332947492,
      "grad_norm": 0.846099317073822,
      "learning_rate": 1.288881477320601e-06,
      "loss": 0.1134,
      "step": 111100
    },
    {
      "epoch": 2.924076607387141,
      "grad_norm": 0.6324441432952881,
      "learning_rate": 1.2669393343631515e-06,
      "loss": 0.1086,
      "step": 111150
    },
    {
      "epoch": 2.9253919814795326,
      "grad_norm": 0.6465566754341125,
      "learning_rate": 1.2449971914057015e-06,
      "loss": 0.1087,
      "step": 111200
    },
    {
      "epoch": 2.9267073555719247,
      "grad_norm": 0.6919271945953369,
      "learning_rate": 1.2230550484482517e-06,
      "loss": 0.1084,
      "step": 111250
    },
    {
      "epoch": 2.9280227296643164,
      "grad_norm": 0.654618501663208,
      "learning_rate": 1.201112905490802e-06,
      "loss": 0.1098,
      "step": 111300
    },
    {
      "epoch": 2.9293381037567086,
      "grad_norm": 0.6315198540687561,
      "learning_rate": 1.1791707625333522e-06,
      "loss": 0.108,
      "step": 111350
    },
    {
      "epoch": 2.9306534778491002,
      "grad_norm": 0.6135445833206177,
      "learning_rate": 1.1572286195759024e-06,
      "loss": 0.1084,
      "step": 111400
    },
    {
      "epoch": 2.931968851941492,
      "grad_norm": 0.7339276671409607,
      "learning_rate": 1.1352864766184524e-06,
      "loss": 0.1094,
      "step": 111450
    },
    {
      "epoch": 2.933284226033884,
      "grad_norm": 0.8001260757446289,
      "learning_rate": 1.1133443336610027e-06,
      "loss": 0.1069,
      "step": 111500
    },
    {
      "epoch": 2.934599600126276,
      "grad_norm": 0.7604901194572449,
      "learning_rate": 1.091402190703553e-06,
      "loss": 0.1122,
      "step": 111550
    },
    {
      "epoch": 2.935914974218668,
      "grad_norm": 0.691521406173706,
      "learning_rate": 1.0694600477461032e-06,
      "loss": 0.1082,
      "step": 111600
    },
    {
      "epoch": 2.9372303483110596,
      "grad_norm": 0.6051870584487915,
      "learning_rate": 1.0475179047886534e-06,
      "loss": 0.1077,
      "step": 111650
    },
    {
      "epoch": 2.9385457224034517,
      "grad_norm": 0.7807480692863464,
      "learning_rate": 1.0255757618312034e-06,
      "loss": 0.1093,
      "step": 111700
    },
    {
      "epoch": 2.9398610964958434,
      "grad_norm": 0.5801665782928467,
      "learning_rate": 1.0036336188737539e-06,
      "loss": 0.1104,
      "step": 111750
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.7080227732658386,
      "learning_rate": 9.816914759163039e-07,
      "loss": 0.1081,
      "step": 111800
    },
    {
      "epoch": 2.942491844680627,
      "grad_norm": 0.7325963973999023,
      "learning_rate": 9.597493329588541e-07,
      "loss": 0.1098,
      "step": 111850
    },
    {
      "epoch": 2.943807218773019,
      "grad_norm": 0.8028221130371094,
      "learning_rate": 9.378071900014043e-07,
      "loss": 0.1085,
      "step": 111900
    },
    {
      "epoch": 2.945122592865411,
      "grad_norm": 0.7665888071060181,
      "learning_rate": 9.158650470439546e-07,
      "loss": 0.1072,
      "step": 111950
    },
    {
      "epoch": 2.9464379669578027,
      "grad_norm": 0.6745333671569824,
      "learning_rate": 8.939229040865048e-07,
      "loss": 0.1094,
      "step": 112000
    },
    {
      "epoch": 2.947753341050195,
      "grad_norm": 0.7190483212471008,
      "learning_rate": 8.71980761129055e-07,
      "loss": 0.1091,
      "step": 112050
    },
    {
      "epoch": 2.9490687151425865,
      "grad_norm": 0.7317195534706116,
      "learning_rate": 8.500386181716051e-07,
      "loss": 0.1107,
      "step": 112100
    },
    {
      "epoch": 2.950384089234978,
      "grad_norm": 0.6127888560295105,
      "learning_rate": 8.280964752141554e-07,
      "loss": 0.1087,
      "step": 112150
    },
    {
      "epoch": 2.9516994633273703,
      "grad_norm": 0.6963362097740173,
      "learning_rate": 8.061543322567056e-07,
      "loss": 0.1069,
      "step": 112200
    },
    {
      "epoch": 2.9530148374197625,
      "grad_norm": 0.6570850610733032,
      "learning_rate": 7.842121892992558e-07,
      "loss": 0.11,
      "step": 112250
    },
    {
      "epoch": 2.954330211512154,
      "grad_norm": 0.6500661373138428,
      "learning_rate": 7.62270046341806e-07,
      "loss": 0.1092,
      "step": 112300
    },
    {
      "epoch": 2.955645585604546,
      "grad_norm": 0.566485583782196,
      "learning_rate": 7.403279033843562e-07,
      "loss": 0.1083,
      "step": 112350
    },
    {
      "epoch": 2.956960959696938,
      "grad_norm": 0.5898134112358093,
      "learning_rate": 7.183857604269064e-07,
      "loss": 0.1086,
      "step": 112400
    },
    {
      "epoch": 2.9582763337893296,
      "grad_norm": 0.8000770807266235,
      "learning_rate": 6.964436174694565e-07,
      "loss": 0.108,
      "step": 112450
    },
    {
      "epoch": 2.9595917078817218,
      "grad_norm": 0.6335461735725403,
      "learning_rate": 6.745014745120068e-07,
      "loss": 0.1083,
      "step": 112500
    },
    {
      "epoch": 2.9609070819741135,
      "grad_norm": 0.492026686668396,
      "learning_rate": 6.52559331554557e-07,
      "loss": 0.1079,
      "step": 112550
    },
    {
      "epoch": 2.962222456066505,
      "grad_norm": 0.5849253535270691,
      "learning_rate": 6.306171885971072e-07,
      "loss": 0.1059,
      "step": 112600
    },
    {
      "epoch": 2.9635378301588973,
      "grad_norm": 0.826652467250824,
      "learning_rate": 6.086750456396574e-07,
      "loss": 0.1086,
      "step": 112650
    },
    {
      "epoch": 2.964853204251289,
      "grad_norm": 0.7139552235603333,
      "learning_rate": 5.867329026822076e-07,
      "loss": 0.1064,
      "step": 112700
    },
    {
      "epoch": 2.966168578343681,
      "grad_norm": 0.6242037415504456,
      "learning_rate": 5.647907597247578e-07,
      "loss": 0.1065,
      "step": 112750
    },
    {
      "epoch": 2.9674839524360728,
      "grad_norm": 0.6444329619407654,
      "learning_rate": 5.428486167673081e-07,
      "loss": 0.1066,
      "step": 112800
    },
    {
      "epoch": 2.9687993265284645,
      "grad_norm": 0.6448022127151489,
      "learning_rate": 5.209064738098582e-07,
      "loss": 0.1095,
      "step": 112850
    },
    {
      "epoch": 2.9701147006208566,
      "grad_norm": 0.6117974519729614,
      "learning_rate": 4.989643308524084e-07,
      "loss": 0.1078,
      "step": 112900
    },
    {
      "epoch": 2.9714300747132487,
      "grad_norm": 0.7482273578643799,
      "learning_rate": 4.770221878949586e-07,
      "loss": 0.108,
      "step": 112950
    },
    {
      "epoch": 2.9727454488056404,
      "grad_norm": 0.6368117928504944,
      "learning_rate": 4.5508004493750885e-07,
      "loss": 0.1059,
      "step": 113000
    },
    {
      "epoch": 2.974060822898032,
      "grad_norm": 0.5727770328521729,
      "learning_rate": 4.33137901980059e-07,
      "loss": 0.1082,
      "step": 113050
    },
    {
      "epoch": 2.975376196990424,
      "grad_norm": 0.7741722464561462,
      "learning_rate": 4.1119575902260927e-07,
      "loss": 0.109,
      "step": 113100
    },
    {
      "epoch": 2.976691571082816,
      "grad_norm": 0.7420594096183777,
      "learning_rate": 3.892536160651594e-07,
      "loss": 0.1093,
      "step": 113150
    },
    {
      "epoch": 2.978006945175208,
      "grad_norm": 0.6360284090042114,
      "learning_rate": 3.6731147310770963e-07,
      "loss": 0.11,
      "step": 113200
    },
    {
      "epoch": 2.9793223192675997,
      "grad_norm": 0.5452293157577515,
      "learning_rate": 3.453693301502598e-07,
      "loss": 0.1074,
      "step": 113250
    },
    {
      "epoch": 2.9806376933599914,
      "grad_norm": 0.7517447471618652,
      "learning_rate": 3.2342718719281e-07,
      "loss": 0.1087,
      "step": 113300
    },
    {
      "epoch": 2.9819530674523835,
      "grad_norm": 0.7796921730041504,
      "learning_rate": 3.0148504423536023e-07,
      "loss": 0.1105,
      "step": 113350
    },
    {
      "epoch": 2.983268441544775,
      "grad_norm": 0.6836687326431274,
      "learning_rate": 2.795429012779104e-07,
      "loss": 0.107,
      "step": 113400
    },
    {
      "epoch": 2.9845838156371673,
      "grad_norm": 0.725919783115387,
      "learning_rate": 2.576007583204606e-07,
      "loss": 0.1074,
      "step": 113450
    },
    {
      "epoch": 2.985899189729559,
      "grad_norm": 0.6824118494987488,
      "learning_rate": 2.3565861536301083e-07,
      "loss": 0.1097,
      "step": 113500
    },
    {
      "epoch": 2.9872145638219507,
      "grad_norm": 0.5530880689620972,
      "learning_rate": 2.1371647240556101e-07,
      "loss": 0.1073,
      "step": 113550
    },
    {
      "epoch": 2.988529937914343,
      "grad_norm": 0.6761253476142883,
      "learning_rate": 1.9177432944811122e-07,
      "loss": 0.1073,
      "step": 113600
    },
    {
      "epoch": 2.989845312006735,
      "grad_norm": 0.6800892353057861,
      "learning_rate": 1.6983218649066143e-07,
      "loss": 0.11,
      "step": 113650
    },
    {
      "epoch": 2.9911606860991267,
      "grad_norm": 0.8245846629142761,
      "learning_rate": 1.4789004353321164e-07,
      "loss": 0.1119,
      "step": 113700
    },
    {
      "epoch": 2.9924760601915183,
      "grad_norm": 0.6131333112716675,
      "learning_rate": 1.2594790057576185e-07,
      "loss": 0.1084,
      "step": 113750
    },
    {
      "epoch": 2.9937914342839105,
      "grad_norm": 0.6541995406150818,
      "learning_rate": 1.0400575761831205e-07,
      "loss": 0.1074,
      "step": 113800
    },
    {
      "epoch": 2.995106808376302,
      "grad_norm": 0.507765531539917,
      "learning_rate": 8.206361466086224e-08,
      "loss": 0.1071,
      "step": 113850
    },
    {
      "epoch": 2.9964221824686943,
      "grad_norm": 0.6227861046791077,
      "learning_rate": 6.012147170341245e-08,
      "loss": 0.1089,
      "step": 113900
    },
    {
      "epoch": 2.997737556561086,
      "grad_norm": 0.5655164122581482,
      "learning_rate": 3.817932874596265e-08,
      "loss": 0.1092,
      "step": 113950
    },
    {
      "epoch": 2.9990529306534777,
      "grad_norm": 0.7063503265380859,
      "learning_rate": 1.6237185788512848e-08,
      "loss": 0.1101,
      "step": 114000
    },
    {
      "epoch": 3.0,
      "eval_loss": 7.996799468994141,
      "eval_runtime": 257.4252,
      "eval_samples_per_second": 130.815,
      "eval_steps_per_second": 16.354,
      "step": 114036
    }
  ],
  "logging_steps": 50,
  "max_steps": 114036,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.9593004384256e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
